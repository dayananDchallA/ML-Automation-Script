At Step: colIdentification 
Sequence executed:


At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Feature Reduction 
Sequence executed:
Null Handling with mean,  Feature Reduction with pearson,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Feature Reduction with pearson,  Outlier Handling with capping,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Feature Reduction with pearson,  Outlier Handling with capping,  Encoding with one-hot,

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Feature Reduction with pearson,  Outlier Handling with capping,  Encoding with one-hot,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestRegressor'>, 'param': {'criterion': 'mse', 'max_depth': 6, 'max_features': 1, 'n_estimators': 14}}, 'score': 974.115296733125, 'residual': <module 'matplotlib.pyplot' from 'C:\\Users\\SindhuKarnati\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py'>, 'pickle_file': RandomForestRegressor(max_depth=6, max_features=1, n_estimators=14), 'y_pred': array([ 279.78812178,  279.78812178, 2139.22987191, 1448.66564621,
        977.17869777, 1697.07479202, 1661.61176378, 1171.05808314,
        556.23330277,  299.26827653, 1906.6188031 ,  427.92471692,
        949.50290729,  452.4299437 , 1059.33653905,  778.4689399 ,
       1765.02987377,  551.75844375,  661.17693564, 1015.04349488,
       1852.99208405, 1208.30114325,  760.88746323,  681.66508619,
        964.56233783, 1425.82728988,  709.97316067,  985.19461893,
        626.82647727, 1375.40953695, 1824.30637238,  620.38842556,
        662.74437131, 1197.0074052 ,  381.03343772,  507.78722226,
        560.92782197,  165.5238859 , 1931.67696322, 2139.22987191,
        560.92782197, 1068.72556888,  164.67882034, 1754.7547698 ,
        367.20329616, 1227.35808488,  759.72079657,  400.91648703,
       1428.33869445,  870.73390919, 1902.41130838, 2098.43535103,
       1938.24018873,  681.66508619,  949.50290729, 1914.29971755,
       1279.51172332, 1009.10467352, 2084.66834434,  341.28361715,
       1870.22752367, 1784.19253322,  623.56520568,  895.8397594 ,
       1567.80374019, 2104.5006616 , 1177.90261361,  599.82433106,
       1571.33862391, 1278.51883525, 1754.7547698 , 1299.97117019,
       1211.77068799, 1030.62125663,  623.56520568, 2038.95902244,
       1643.49536287,  584.79161074, 1879.87251267, 1971.45193684,
        919.01630856,  964.56233783, 1197.0074052 ,  678.52081927,
        164.67882034, 1201.55702767,  236.49865973, 1466.95868902,
        352.93663149,  511.29930482,  760.88746323, 1852.99208405,
        987.31883662, 1230.00075649, 1644.90679144,  282.88330595,
       1848.92373671, 1691.68723533,  511.29930482, 2183.4096369 ,
       1518.56525178,  701.09805344, 1201.55702767, 1883.97045493,
        215.87209745, 1115.84456895, 1469.47150953,  703.09820133,
        599.82433106, 1313.01567696, 2040.49711768,  410.11045423,
        400.91648703, 1611.2242772 , 1807.73234792,  507.03007287,
       1012.09827471,  408.08605121,  236.49865973, 1754.7547698 ,
        478.34794282, 1520.64652376, 1068.72556888,  989.55976632,
        949.50290729, 2216.36180825, 1971.45193684, 1059.33653905,
        897.42633948, 1968.41006184, 1324.19761745,  278.04475443,
       1161.79136053,  166.66971924, 1914.29971755, 1657.70411967,
        478.34794282,  452.4299437 ,  705.95044222, 1715.33096251,
        926.94387713,  945.56689538, 1115.84456895, 1520.02669659,
       1313.01567696, 1275.65375589,  312.65960984, 2038.95902244,
       1999.3482825 , 1449.92915161, 1197.0074052 ,  197.02962749,
        320.22330345,  236.49865973,  623.56520568,  212.92445506,
        570.40087446, 1757.19308782, 1859.4112968 , 1577.35926752,
       1586.29614065, 1516.85477559,  759.72079657,  303.69669915,
       1852.99208405, 1611.2242772 ,  891.89113291, 1208.30114325,
       1899.9341713 ,  623.56520568, 1765.02987377, 1920.81214652,
       1289.8372294 , 2217.9860669 , 1928.35571395, 2081.98896733,
       1227.35808488, 1999.3482825 , 2190.68652259, 1691.68723533,
        935.97077182, 2120.91457265, 2208.27431964, 2193.33832342,
       1715.33096251, 1073.36911284, 2131.81341754,  408.08605121,
        299.26827653, 1571.33862391, 1765.02987377, 1792.74489644,
        208.40870053,  357.94662072,  214.66138316, 1824.30637238,
        357.94662072,  212.92445506,  864.7340561 ,  584.79161074,
       1588.91509168, 1043.98682529,  874.16570268, 2084.66834434,
        166.66971924, 1754.7547698 ,  530.83139123, 1773.93924373,
        623.56520568,  949.50290729, 2026.70098445,  874.16570268,
        864.7340561 , 1161.79136053, 1886.03364863, 1774.83720292,
       1588.91509168, 2139.22987191, 1009.10467352, 1466.95868902,
        212.92445506, 1889.86606573, 1430.395471  , 1313.01567696,
        397.33919361,  338.90119957, 1983.16343616, 1774.83720292,
       1199.32513919,  847.21130819, 1951.3692394 , 1387.64227247,
        506.59549294,  478.34794282,  807.94793326,  513.66605152,
       1792.74489644,  236.49865973, 2217.9860669 ,  847.21130819,
        198.73244134, 1257.91409671, 1279.51172332,  427.92471692,
       1931.67696322,  584.79161074, 1207.04624597,  397.33919361,
        556.23330277,  452.4299437 ,  949.50290729, 1774.83720292,
       2217.9860669 ,  372.9531113 ,  506.4528996 , 1636.94736698,
        891.89113291, 1870.22752367,  705.95044222,  584.79161074,
        312.65960984, 1643.49536287, 1314.09059932, 1709.40337801,
        945.56689538, 1448.66564621,  400.91648703, 1774.83720292,
        408.08605121, 1203.03249664,  807.94793326,  352.93663149,
       1889.86606573, 1879.87251267, 1197.0074052 ,  845.12583604,
       1999.3482825 , 1266.02800309,  351.13113429, 1279.51172332,
       1981.04340815,  354.33799204,  844.97321295,  452.4299437 ,
       2081.98896733, 1257.91409671,  312.65960984,  236.49865973,
       2081.64372923, 1522.12753692,  584.79161074,  845.12583604,
        666.21167656,  556.23330277, 1466.95868902,  197.02962749,
       1577.35926752,  513.66605152, 2216.36180825, 2104.5006616 ,
        845.12583604, 1350.57768819, 1471.67961393, 1478.53353515,
       1607.2226308 , 1657.70411967,  989.55976632, 1807.73234792,
       1999.3482825 , 1316.45558531, 2051.18465433, 2083.14372923,
       1378.46645087,  889.8316091 ,  199.73424509, 2140.60994652,
       1266.02800309,  559.44482877,  579.67905122,  623.56520568,
       1940.2664613 , 1920.81214652, 1573.94973502, 1324.19761745,
       1699.98304325, 1971.45193684,  760.88746323, 1774.83720292,
       2099.85085057, 1324.19761745, 2120.91457265, 1657.70411967,
        301.40160987, 1278.51883525, 1938.24018873, 1115.84456895,
       1018.08894943, 1287.62764102,  681.66508619,  164.67882034,
       1043.98682529, 1338.4936593 ,  372.9531113 ,  506.59549294,
       1177.90261361, 1260.13714811,  937.26362897, 1059.33653905,
       1792.74489644, 1914.29971755, 1694.71943487,  560.92782197,
        559.44482877, 1644.90679144,  279.78812178, 1115.84456895,
       1514.41071046, 2042.51260219,  759.72079657,  312.65960984,
       2190.68652259,  491.0589258 , 1324.19761745, 1879.87251267,
        664.80884255, 1375.40953695,  897.42633948, 2188.67661942,
       1477.19911956,  844.97321295, 1313.01567696, 1754.7547698 ,
        164.67882034, 1852.99208405,  197.02962749,  534.96164333,
       1100.54683872,  897.42633948,  864.7340561 ,  989.55976632,
       1462.10486347, 1938.24018873, 1571.33862391, 1264.22264595,
        953.50869017, 1279.51172332, 2216.36180825,  312.65960984,
       1520.64652376, 1277.47518446,  579.67905122, 1553.63764005,
        709.97316067,  701.09805344,  534.96164333,  559.44482877,
       2049.67787778,  579.67905122, 1657.70411967,  402.40999352,
       1115.84456895, 2147.62405393, 1518.56525178,  974.52667621,
        559.01588256, 1197.0074052 ,  681.66508619, 1940.2664613 ,
       1944.93973136, 1577.35926752, 1338.4936593 ,  705.95044222,
       1522.12753692, 1483.08183447, 2178.49591261,  352.93663149,
       2217.9860669 , 2046.89960142,  427.92471692, 1059.33653905,
       2180.13911196,  709.97316067, 1754.7547698 ])}

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Feature Reduction with pearson,  Outlier Handling with capping,  Encoding with one-hot,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._base.LinearRegression'>, 'param': {'normalize': 'True'}}, 'score': 864.4519147529426, 'residual': <module 'matplotlib.pyplot' from 'C:\\Users\\SindhuKarnati\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py'>, 'pickle_file': LinearRegression(normalize='False'), 'y_pred': array([ 264.57350587,  266.57390381, 2141.94697012, 1453.81007965,
        985.7169623 , 1692.85763317, 1677.85464864, 1166.75297564,
        534.62722742,  295.5796739 , 1904.89981454,  420.60454499,
        937.7074118 ,  453.61111095, 1077.73526742,  785.67716856,
       1754.86996923,  530.62643154,  654.65110366, 1017.7233293 ,
       1836.88628467, 1212.7621282 ,  768.67378609,  679.65607788,
        957.71139118, 1410.801524  ,  722.66463353,  986.71716127,
        646.64951191, 1370.79356525, 1826.88429498,  610.64234904,
        656.6515016 , 1185.75675604,  384.59738211,  501.62066145,
        553.63100782,  164.553609  , 1934.9057836 , 2137.94617425,
        551.63060989, 1083.73646123,  160.66283501, 1751.86937233,
        373.59519346, 1225.76471479,  758.67179641,  394.5993718 ,
       1418.80311575,  869.69388193, 1900.89901866, 2088.93642478,
       1944.90777329,  677.65567994,  939.70780974, 1909.90080938,
       1279.7754591 , 1003.72054374, 2081.935032  ,  337.58803058,
       1857.89046301, 1777.87454551,  627.64573151,  900.70004996,
       1549.82918065, 2100.9388124 , 1171.75397048,  606.64155316,
       1552.82977756, 1270.77366838, 1732.86559192, 1302.78003538,
       1214.76252613, 1020.72392621,  611.64254801, 2029.92468563,
       1648.84887855,  585.63737482, 1869.89285063, 1969.9127475 ,
        914.70283552,  964.71278396, 1182.75615914,  674.65508304,
        160.66283501, 1199.7595416 ,  240.56873062, 1467.81286522,
        354.59141305,  497.61986558,  773.67478094, 1837.88648364,
        991.71815611, 1227.76511273, 1652.84967443,  282.5770873 ,
       1829.88489189, 1683.85584246,  496.61966661, 2188.95632165,
       1512.82181881,  691.6584655 , 1198.75934264, 1877.89444238,
        233.56733784, 1117.74322617, 1475.81445697,  698.65985828,
        601.64055832, 1304.78043332, 2036.92607841,  407.60195839,
        398.60016767, 1619.84310846, 1804.87991767,  519.62424289,
       1007.72133961,  402.60096355,  239.56853165, 1738.86678573,
        473.61509033, 1538.82699199, 1078.73546639,  996.71915096,
        944.70880459, 2222.96308659, 1977.91433925, 1072.73427258,
        911.70223862, 1962.91135472, 1326.78481063,  279.5764904 ,
       1158.75138389,  177.55619559, 1911.90120732, 1671.85345483,
        478.61608517,  466.61369755,  702.66065416, 1716.86240842,
        918.7036314 ,  935.70701387, 1101.74004267, 1515.82241571,
       1306.78083126, 1263.7722756 ,  314.5834543 , 2022.92329285,
       2001.9191145 , 1446.80868687, 1184.75655707,  198.56037393,
        326.58584193,  254.57151618,  616.64354285,  215.5637564 ,
        567.63379338, 1752.8695713 , 1848.88867229, 1568.83296106,
       1572.83375693, 1504.82022706,  765.67318919,  301.58086771,
       1833.88568776, 1617.84271052,  897.69945306, 1211.76192923,
       1894.89782485,  620.64433873, 1755.8701682 , 1917.90240113,
       1299.77943847, 2229.85445748, 1922.90339598, 2079.93463406,
       1223.76431685, 2011.92110419, 2196.9579134 , 1686.85643936,
        921.70422831, 2108.94040415, 2216.96189277, 2202.95910721,
       1710.86121461, 1084.7366602 , 2129.9445825 ,  401.60076458,
        299.58046977, 1555.83037446, 1753.86977026, 1785.87613726,
        207.56216465,  363.59320377,  218.56435331, 1822.88349911,
        361.59280583,  214.56355743,  859.69189225,  590.63836966,
       1590.83733837, 1040.72790558,  877.69547368, 2083.93542994,
        178.55639456, 1748.86877542,  525.6254367 , 1766.87235686,
        628.64593048,  950.7099984 , 2021.92309388,  875.69507574,
        861.69229018, 1155.75078698, 1887.89643207, 1771.8733517 ,
       1587.83674146, 2136.94597528, 1006.72114064, 1463.81206934,
        213.56335846, 1892.89742691, 1426.8047075 , 1310.78162713,
        389.59837696,  335.58763265, 1993.91752275, 1773.87374964,
       1197.75914367,  836.68731597, 1961.91115575, 1403.80013122,
        507.62185526,  480.61648311,  809.68194381,  491.61867176,
       1779.87494345,  236.56793474, 2229.85445748,  838.6877139 ,
        201.56097084, 1242.76809726, 1285.77665291,  421.60474395,
       1931.90518669,  584.63717585, 1204.76053645,  388.59817799,
        535.62742639,  446.60971817,  938.70761077, 1775.87414758,
       2229.85445748,  376.59579036,  487.61787589, 1627.84470021,
        895.69905512, 1858.89066198,  708.66184797,  580.63637998,
        311.5828574 , 1637.8466899 , 1318.78321888, 1700.85922492,
        933.70661593, 1452.80988069,  397.59996871, 1769.87295376,
        400.60056561, 1201.75993954,  810.68214278,  347.59002027,
       1891.89722795, 1871.89324857, 1186.75695501,  833.68671906,
       2013.92150213, 1259.77147973,  342.58902543, 1275.77466323,
       1981.91513513,  357.59200996,  847.68950462,  451.61071302,
       2077.93423612, 1243.76829623,  308.58226049,  247.5701234 ,
       2068.93244541, 1518.82301262,  582.63677792,  834.68691803,
        669.65408819,  536.62762536, 1465.81246728,  196.559976  ,
       1567.83276209,  493.6190697 , 2223.96328555, 2093.93741962,
        830.68612215, 1357.79097866, 1477.8148549 , 1482.81584975,
       1612.84171568, 1675.85425071,  993.71855405, 1805.88011664,
       2010.92090522, 1325.78461166, 2048.92846603, 2071.93304231,
       1378.795157  ,  887.69746337,  204.56156775, 2144.94756703,
       1257.77108179,  559.63220164,  573.6349872 ,  614.64314491,
       1958.91055885, 1915.90200319, 1556.83057343, 1329.78540754,
       1695.85823008, 1970.91294647,  770.67418403, 1767.87255583,
       2092.93722065, 1334.78640238, 2107.94020519, 1672.8536538 ,
        292.57907699, 1269.77346941, 1941.90717638, 1113.7424303 ,
       1015.72293136, 1296.77884157,  689.65806757,  160.66283501,
       1037.72730867, 1345.78859103,  375.59559139,  506.62165629,
       1169.75357254, 1245.76869416,  927.70542212, 1069.73367567,
       1782.87554036, 1910.90100835, 1687.85663833,  554.63120679,
        564.63319648, 1656.8504703 ,  275.57569452, 1111.74203236,
       1495.81843634, 2039.92667531,  759.67199538,  310.58265843,
       2199.95851031,  486.61767692, 1333.78620341, 1873.89364651,
        664.65309335, 1366.79276938,  912.70243759, 2191.95691856,
       1480.81545181,  853.69069843, 1307.78103022, 1744.86797955,
        160.66283501, 1841.88727951,  200.56077187,  527.62583464,
       1092.73825195,  904.70084584,  858.69169328,  995.71895199,
       1459.81127347, 1945.90797226, 1554.83017549, 1254.77048488,
        951.71019737, 1284.77645394, 2225.96368349,  318.58425018,
       1536.82659406, 1264.77247457,  579.63618101, 1544.82818581,
        721.66443456,  696.65946035,  526.62563567,  563.63299751,
       2052.92926191,  575.63538513, 1674.85405174,  399.60036664,
       1110.74183339, 2157.95015362, 1514.82221675,  983.71656436,
        545.62941607, 1181.75596017,  680.65627685, 1955.90996194,
       1959.91075782, 1565.83236415, 1344.78839207,  711.66244488,
       1528.82500231, 1487.81684459, 2170.95274021,  351.59081615,
       2229.85445748, 2043.92747119,  425.60553983, 1066.73307877,
       2176.95393403,  717.66363869, 1750.86917336])}

At Step: Outlier Handling 
Sequence executed:
  Outlier Handling with removing,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with one-hot,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with one-hot,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 15, 'max_features': 4, 'n_estimators': 7}}, 'score': 0.8142857142857143, 'conf_matrix': array([[93, 22],
       [ 4, 21]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=15, max_features=4,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=7,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,
       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with one-hot,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.667056343401222, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.8357142857142857, 'conf_matrix': array([[88, 14],
       [ 9, 29]], dtype=int64), 'pickle_file': LogisticRegression(C=0.5845645325229636, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,
       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,
       0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0], dtype=int64)}

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 18, 'max_features': 4, 'n_estimators': 6}}, 'score': 0.8228855721393035, 'conf_matrix': array([[ 78,  19,   5],
       [ 50, 247,  11],
       [ 45,  48, 502]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=18, max_features=4,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=6,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([2, 0, 2, ..., 0, 1, 2])}

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.12139771911352203, 'penalty': 'l2', 'solver': 'saga'}}, 'score': 0.9522388059701492, 'conf_matrix': array([[159,  13,   7],
       [ 13, 294,   7],
       [  1,   7, 504]], dtype=int64), 'pickle_file': LogisticRegression(C=0.12037178940976204, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='sag', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 2, ..., 0, 1, 2])}

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with imputezero,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 11, 'max_features': 4, 'n_estimators': 10}}, 'score': 0.8357142857142857, 'conf_matrix': array([[72, 14],
       [ 9, 45]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=7, max_features=4,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=6,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,
       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,
       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,
       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1,
       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,
       1, 0, 0, 1, 1, 1, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.16371719274487778, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.7571428571428571, 'conf_matrix': array([[71, 24],
       [10, 35]], dtype=int64), 'pickle_file': LogisticRegression(C=0.1427264135444902, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,
       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,
       0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,
       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,
       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 1, 1, 0, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with imputezero,

At Step: Outlier Handling 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 17, 'max_features': 1, 'n_estimators': 19}}, 'score': 0.8580645161290322, 'conf_matrix': array([[98, 17],
       [ 5, 35]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=17, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=19,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,
       1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,
       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,
       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.7439780936876438, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.8387096774193549, 'conf_matrix': array([[96, 18],
       [ 7, 34]], dtype=int64), 'pickle_file': LogisticRegression(C=0.7812831260282708, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,
       1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,
       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,
       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,
       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,
       1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with imputezero,

At Step: Outlier Handling 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 4, 'max_features': 1, 'n_estimators': 13}}, 'score': 0.8202247191011236, 'conf_matrix': array([[101,  24],
       [  8,  45]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=5, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=18,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,
       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,
       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,
       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,
       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.05310701205369617, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.797752808988764, 'conf_matrix': array([[99, 26],
       [10, 43]], dtype=int64), 'pickle_file': LogisticRegression(C=0.04568340229264816, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,
       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0,
       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,
       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,
       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,
       0, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 8, 'max_features': 2, 'n_estimators': 18}}, 'score': 0.8214285714285714, 'conf_matrix': array([[76, 18],
       [ 7, 39]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=11, max_features=2,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=13,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,
       1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,
       1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 1, 1, 1, 1, 0, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 4.76251276844848, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.8285714285714286, 'conf_matrix': array([[74, 15],
       [ 9, 42]], dtype=int64), 'pickle_file': LogisticRegression(C=862.0083615988101, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,
       1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,
       1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 1, 1, 0, 1, 1, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 6, 'max_features': 2, 'n_estimators': 6}}, 'score': 0.8642857142857143, 'conf_matrix': array([[83, 14],
       [ 5, 38]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=6, max_features=2,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=6,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,
       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,
       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.6006745619646621, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.7857142857142857, 'conf_matrix': array([[77, 19],
       [11, 33]], dtype=int64), 'pickle_file': LogisticRegression(C=0.9898739712140293, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,
       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,
       1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,
       1, 0, 0, 0, 1, 0, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 6, 'max_features': 3, 'n_estimators': 15}}, 'score': 0.8642857142857143, 'conf_matrix': array([[90, 10],
       [ 9, 31]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=8, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=12,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,
       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,
       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 1, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.32402968937815524, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.8142857142857143, 'conf_matrix': array([[85, 12],
       [14, 29]], dtype=int64), 'pickle_file': LogisticRegression(C=0.27681755290541615, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,
       1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,
       1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,
       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,
       1, 0, 1, 0, 1, 0, 1, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 13, 'max_features': 2, 'n_estimators': 11}}, 'score': 0.8571428571428571, 'conf_matrix': array([[87, 17],
       [ 3, 33]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=13, max_features=2,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=11,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.7388060400741512, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.8071428571428572, 'conf_matrix': array([[81, 18],
       [ 9, 32]], dtype=int64), 'pickle_file': LogisticRegression(C=0.5663179306332855, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,
       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,
       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 3, 'max_features': 7, 'n_estimators': 18}}, 'score': 0.8472222222222222, 'conf_matrix': array([[90, 16],
       [ 6, 32]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=3, max_features=7,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=18,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,
       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,
       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,
       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 1.1060602887314528, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.8194444444444444, 'conf_matrix': array([[85, 15],
       [11, 33]], dtype=int64), 'pickle_file': LogisticRegression(C=1.1060602887314528, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,
       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,
       1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,
       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,
       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 8, 'max_features': 5, 'n_estimators': 13}}, 'score': 0.875, 'conf_matrix': array([[95, 14],
       [ 4, 31]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=8, max_features=5,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=13,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,
       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,
       0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 68.93881076118305, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.8263888888888888, 'conf_matrix': array([[85, 11],
       [14, 34]], dtype=int64), 'pickle_file': LogisticRegression(C=68.93881076118305, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,
       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,
       0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,
       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,
       1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with imputezero,

At Step: Outlier Handling 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 6, 'max_features': 4, 'n_estimators': 8}}, 'score': 0.8709677419354839, 'conf_matrix': array([[94,  9],
       [11, 41]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=6, max_features=4,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=8,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0,
       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,
       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,
       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,
       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,
       1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,
       1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.572502815465443, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.8129032258064516, 'conf_matrix': array([[92, 16],
       [13, 34]], dtype=int64), 'pickle_file': LogisticRegression(C=0.3024003814110007, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='sag', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,
       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1,
       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,
       1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with imputezero,

At Step: Outlier Handling 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 5, 'max_features': 4, 'n_estimators': 14}}, 'score': 0.7935483870967742, 'conf_matrix': array([[94, 26],
       [ 6, 29]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=5, max_features=4,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=14,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,
       1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,
       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 2.6851847764576413, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.7870967741935484, 'conf_matrix': array([[92, 25],
       [ 8, 30]], dtype=int64), 'pickle_file': LogisticRegression(C=23.096137870719573, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,
       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,
       1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1,
       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,
       0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 10, 'max_features': 1, 'n_estimators': 16}}, 'score': 0.8516129032258064, 'conf_matrix': array([[95, 14],
       [ 9, 37]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=8, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=15,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,
       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,
       1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.08839942402396557, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.8129032258064516, 'conf_matrix': array([[94, 19],
       [10, 32]], dtype=int64), 'pickle_file': LogisticRegression(C=0.08633268164649702, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,
       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,
       1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1,
       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,
       0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'n_estimators': 7}}, 'score': 0.8071428571428572, 'conf_matrix': array([[82,  9],
       [18, 31]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=4, max_features=2,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=7,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,
       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,
       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,
       0, 0, 1, 0, 1, 0, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.13059658047092124, 'penalty': 'l2', 'solver': 'sag'}}, 'score': 0.8071428571428572, 'conf_matrix': array([[88, 15],
       [12, 25]], dtype=int64), 'pickle_file': LogisticRegression(C=0.12699370216498726, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='sag', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,
       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,
       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 6, 'max_features': 4, 'n_estimators': 17}}, 'score': 0.8451612903225807, 'conf_matrix': array([[83, 13],
       [11, 48]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=6, max_features=4,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=17,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0,
       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,
       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,
       0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 1.6162366086415738, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.7806451612903226, 'conf_matrix': array([[79, 19],
       [15, 42]], dtype=int64), 'pickle_file': LogisticRegression(C=43.2482553543789, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,
       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,
       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,
       1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 5, 'max_features': 3, 'n_estimators': 3}}, 'score': 0.85, 'conf_matrix': array([[88, 16],
       [ 5, 31]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=5, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=3,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,
       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,
       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.4625210830514644, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.7642857142857142, 'conf_matrix': array([[77, 17],
       [16, 30]], dtype=int64), 'pickle_file': LogisticRegression(C=0.3639800534386642, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 11, 'max_features': 1, 'n_estimators': 19}}, 'score': 0.8357142857142857, 'conf_matrix': array([[89, 14],
       [ 9, 28]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=11, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=19,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       1, 0, 1, 1, 0, 0, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.06431055002480249, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.7928571428571428, 'conf_matrix': array([[87, 18],
       [11, 24]], dtype=int64), 'pickle_file': LogisticRegression(C=0.1390384882504391, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='sag', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,
       1, 0, 1, 1, 0, 0, 0, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 13, 'max_features': 3, 'n_estimators': 18}}, 'score': 0.8571428571428571, 'conf_matrix': array([[86, 10],
       [10, 34]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=13, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=18,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,
       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,
       1, 1, 0, 1, 1, 1, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 4.829715123425421, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.7571428571428571, 'conf_matrix': array([[77, 15],
       [19, 29]], dtype=int64), 'pickle_file': LogisticRegression(C=1668419.5792257932, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,
       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,
       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,
       1, 1, 0, 1, 1, 1, 1, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 15, 'max_features': 4, 'n_estimators': 19}}, 'score': 0.8541666666666666, 'conf_matrix': array([[81, 15],
       [ 6, 42]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=15, max_features=4,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=19,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,
       1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,
       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,
       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,
       1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 1.4689214041806864, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.75, 'conf_matrix': array([[73, 22],
       [14, 35]], dtype=int64), 'pickle_file': LogisticRegression(C=0.8755333326198143, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,
       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0,
       0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,
       1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 18, 'max_features': 3, 'n_estimators': 14}}, 'score': 0.8541666666666666, 'conf_matrix': array([[92, 13],
       [ 8, 31]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=18, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=14,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,
       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,
       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.45854041413392393, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.75, 'conf_matrix': array([[82, 18],
       [18, 26]], dtype=int64), 'pickle_file': LogisticRegression(C=89.19840350444775, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1,
       0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,
       1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,
       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 17, 'max_features': 3, 'n_estimators': 7}}, 'score': 0.8428571428571429, 'conf_matrix': array([[86, 16],
       [ 6, 32]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=18, max_features=2,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=14,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,
       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,
       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,
       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 1, 1, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.656156556615793, 'penalty': 'l2', 'solver': 'saga'}}, 'score': 0.7714285714285715, 'conf_matrix': array([[86, 26],
       [ 6, 22]], dtype=int64), 'pickle_file': LogisticRegression(C=2125282.2330909884, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='saga', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,
       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,
       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 6, 'max_features': 3, 'n_estimators': 7}}, 'score': 0.7928571428571428, 'conf_matrix': array([[84, 16],
       [13, 27]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=6, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=7,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 1, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 6.478270565284335, 'penalty': 'l2', 'solver': 'saga'}}, 'score': 0.7714285714285715, 'conf_matrix': array([[86, 21],
       [11, 22]], dtype=int64), 'pickle_file': LogisticRegression(C=1.096164911625252, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='saga', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,
       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 1, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 6, 'max_features': 2, 'n_estimators': 14}}, 'score': 0.8363636363636363, 'conf_matrix': array([[95, 20],
       [ 7, 43]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=2,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,
       1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,
       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,
       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,
       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,
       0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,
       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.6477440213661931, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.8242424242424242, 'conf_matrix': array([[93, 20],
       [ 9, 43]], dtype=int64), 'pickle_file': LogisticRegression(C=211.31366863155682, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,
       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,
       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0,
       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,
       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,
       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 5, 'max_features': 1, 'n_estimators': 9}}, 'score': 0.8064516129032258, 'conf_matrix': array([[91, 20],
       [10, 34]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=5, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=9,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,
       1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,
       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,
       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,
       1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.06089890624635348, 'penalty': 'l2', 'solver': 'sag'}}, 'score': 0.7806451612903226, 'conf_matrix': array([[97, 30],
       [ 4, 24]], dtype=int64), 'pickle_file': LogisticRegression(C=0.022145160633250054, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,
       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,
       1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 6, 'max_features': 2, 'n_estimators': 3}}, 'score': 0.8194444444444444, 'conf_matrix': array([[85, 12],
       [14, 33]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=6, max_features=2,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=3,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,
       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,
       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,
       0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 1.2508470958140614, 'penalty': 'l2', 'solver': 'sag'}}, 'score': 0.7777777777777778, 'conf_matrix': array([[79, 12],
       [20, 33]], dtype=int64), 'pickle_file': LogisticRegression(C=1.313225865825919, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='sag', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,
       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,
       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,
       0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 8, 'max_features': 3, 'n_estimators': 12}}, 'score': 0.8333333333333334, 'conf_matrix': array([[82,  9],
       [15, 38]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=8, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=12,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1,
       0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 1.1748697827226486, 'penalty': 'l2', 'solver': 'sag'}}, 'score': 0.7777777777777778, 'conf_matrix': array([[81, 16],
       [16, 31]], dtype=int64), 'pickle_file': LogisticRegression(C=1.1748697827226486, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='sag', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,
       0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 8, 'max_features': 3, 'n_estimators': 19}}, 'score': 0.7785714285714286, 'conf_matrix': array([[82, 21],
       [10, 27]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=5, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=8,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,
       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.8037938906082899, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.7642857142857142, 'conf_matrix': array([[75, 16],
       [17, 32]], dtype=int64), 'pickle_file': LogisticRegression(C=0.21750243693129861, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,
       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0,
       1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,
       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,
       0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,
       0, 0, 1, 0, 1, 0, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 5, 'max_features': 3, 'n_estimators': 11}}, 'score': 0.8071428571428572, 'conf_matrix': array([[81, 14],
       [13, 32]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=4, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=15,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1,
       0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,
       0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.25589204393317194, 'penalty': 'l2', 'solver': 'saga'}}, 'score': 0.7928571428571428, 'conf_matrix': array([[88, 23],
       [ 6, 23]], dtype=int64), 'pickle_file': LogisticRegression(C=0.8696834314807411, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='saga', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,
       0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 7, 'max_features': 1, 'n_estimators': 18}}, 'score': 0.8451612903225807, 'conf_matrix': array([[96, 15],
       [ 9, 35]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=7, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=18,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,
       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,
       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,
       0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 2.1086558500091135, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.7870967741935484, 'conf_matrix': array([[89, 17],
       [16, 33]], dtype=int64), 'pickle_file': LogisticRegression(C=14839.33237045672, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,
       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,
       1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,
       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0,
       0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 15, 'max_features': 3, 'n_estimators': 8}}, 'score': 0.7777777777777778, 'conf_matrix': array([[78, 11],
       [21, 34]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=15, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=8,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,
       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,
       0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,
       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,
       1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 2.001919523190494, 'penalty': 'l2', 'solver': 'sag'}}, 'score': 0.7083333333333334, 'conf_matrix': array([[70, 13],
       [29, 32]], dtype=int64), 'pickle_file': LogisticRegression(C=6.894578333453981, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='sag', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0,
       0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,
       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,
       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,
       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,
       1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 13, 'max_features': 4, 'n_estimators': 12}}, 'score': 0.7857142857142857, 'conf_matrix': array([[80, 21],
       [ 9, 30]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=19, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=14,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,
       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,
       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,
       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.11833312921383206, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.7428571428571429, 'conf_matrix': array([[78, 25],
       [11, 26]], dtype=int64), 'pickle_file': LogisticRegression(C=0.11526424970091752, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,
       0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,
       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1,
       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1], dtype=int64)}

At Step: textProcessing 
Sequence executed:
  Text Processing with BOW,

At Step: Modelling classification 
Sequence executed:
  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 18, 'max_features': 335, 'n_estimators': 13}}, 'score': 0.9333333333333333, 'conf_matrix': array([[136,  20,  16],
       [ 12, 295,  12],
       [  5,   2, 507]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=18, max_features=335,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=13,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array(['british', 'cajun_creole', 'cajun_creole', ..., 'cajun_creole',
       'chinese', 'chinese'], dtype=object)}

At Step: Modelling classification 
Sequence executed:
  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 3.207927032798479, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.9522388059701492, 'conf_matrix': array([[142,  13,  12],
       [ 11, 301,   9],
       [  0,   3, 514]], dtype=int64), 'pickle_file': LogisticRegression(C=3.568804154625533, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array(['british', 'cajun_creole', 'cajun_creole', ..., 'cajun_creole',
       'chinese', 'chinese'], dtype=object)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 14, 'max_features': 1, 'n_estimators': 17}}, 'score': 0.8181818181818182, 'conf_matrix': array([[78, 13],
       [17, 57]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=2, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=14,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,
       1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,
       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,
       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1,
       0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,
       1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,
       1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,
       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.07418116181919353, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.8242424242424242, 'conf_matrix': array([[79, 13],
       [16, 57]], dtype=int64), 'pickle_file': LogisticRegression(C=0.057128729150974306, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,
       1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,
       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,
       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1,
       0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,
       1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,
       1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,
       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 19, 'max_features': 3, 'n_estimators': 14}}, 'score': 0.8181818181818182, 'conf_matrix': array([[85, 23],
       [ 7, 50]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=19, max_features=3, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=14, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,
       1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,
       0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,
       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 0.45736414663848546, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.8, 'conf_matrix': array([[80, 21],
       [12, 52]], dtype=int64), 'pickle_file': LogisticRegression(C=1.8870234127010779, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,
       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,
       0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,
       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,
       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0], dtype=int64)}

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 18, 'max_features': 981, 'n_estimators': 7}}, 'score': 0.9353233830845771, 'conf_matrix': array([[134,  15,  13],
       [ 15, 280,   6],
       [  8,   8, 526]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=18, max_features=981, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=7, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([2, 2, 2, ..., 2, 1, 2])}

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 1.963185803517896, 'penalty': 'l2', 'solver': 'saga'}}, 'score': 0.9482587064676616, 'conf_matrix': array([[141,  11,   6],
       [ 12, 285,  12],
       [  4,   7, 527]], dtype=int64), 'pickle_file': LogisticRegression(C=1.8409484134097454, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='saga', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([2, 2, 2, ..., 2, 1, 2])}

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 16, 'max_features': 933, 'n_estimators': 18}}, 'score': 0.9263681592039801, 'conf_matrix': array([[131,  22,  13],
       [ 17, 278,   5],
       [  8,   9, 522]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=16, max_features=933, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=18, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([2, 2, 1, ..., 2, 2, 1])}

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 1.8800401720249413, 'penalty': 'l2', 'solver': 'sag'}}, 'score': 0.9502487562189055, 'conf_matrix': array([[140,  11,   7],
       [ 11, 289,   7],
       [  5,   9, 526]], dtype=int64), 'pickle_file': LogisticRegression(C=1.8621455041673936, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([2, 2, 1, ..., 2, 2, 2])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 8, 'max_features': 1, 'n_estimators': 10}}, 'score': 0.8194444444444444, 'conf_matrix': array([[87, 16],
       [10, 31]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=5, max_features=2, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,
       1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,
       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,
       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,
       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 0.20195899766622874, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.7847222222222222, 'conf_matrix': array([[88, 22],
       [ 9, 25]], dtype=int64), 'pickle_file': LogisticRegression(C=0.14364822507532055, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='newton-cg', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,
       1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0], dtype=int64)}

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 18, 'max_features': 1238, 'n_estimators': 9}}, 'score': 0.9412935323383085, 'conf_matrix': array([[157,  21,  12],
       [ 12, 262,   6],
       [  3,   5, 527]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=18, max_features=1238, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=9, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([1, 2, 2, ..., 1, 1, 0])}

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 0.3588229809089297, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.9572139303482587, 'conf_matrix': array([[160,  11,   7],
       [ 10, 268,   4],
       [  2,   9, 534]], dtype=int64), 'pickle_file': LogisticRegression(C=0.3266886935451164, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='newton-cg', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([1, 2, 2, ..., 1, 1, 0])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 15, 'max_features': 1, 'n_estimators': 5}}, 'score': 0.8156424581005587, 'conf_matrix': array([[100,  22],
       [ 11,  46]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=8, max_features=2, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=1, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1,
       0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,
       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0,
       0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,
       0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 3.3791394969891226, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.7932960893854749, 'conf_matrix': array([[94, 20],
       [17, 48]], dtype=int64), 'pickle_file': LogisticRegression(C=0.9024834796478255, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='newton-cg', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1,
       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1,
       0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,
       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0,
       0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,
       0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0], dtype=int64)}

At Step: Encoding 
Sequence executed:
  Encoding with one-hot,

At Step: Outlier Handling 
Sequence executed:
  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
  Outlier Handling with removing,  Encoding with one-hot,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 14, 'max_features': 688, 'n_estimators': 11}}, 'score': 0.9395348837209302, 'conf_matrix': array([[84,  5,  3,  0],
       [ 1, 47,  2,  0],
       [ 1,  1, 62,  0],
       [ 0,  0,  0,  9]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=18, max_features=573, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=8, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([2, 0, 0, 2, 0, 2, 2, 1, 0, 0, 0, 1, 0, 2, 0, 3, 1, 0, 2, 0, 0, 2,
       1, 2, 1, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 2, 1, 1, 0,
       2, 2, 1, 2, 0, 2, 0, 1, 1, 3, 0, 2, 1, 3, 0, 0, 2, 1, 2, 1, 2, 0,
       1, 2, 2, 2, 0, 0, 0, 1, 1, 1, 1, 0, 2, 2, 0, 1, 2, 2, 2, 2, 0, 0,
       2, 1, 0, 1, 1, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0,
       0, 0, 1, 2, 0, 2, 2, 2, 1, 0, 2, 2, 0, 3, 1, 1, 1, 0, 1, 2, 0, 0,
       2, 0, 1, 0, 1, 2, 0, 1, 2, 3, 0, 0, 2, 0, 0, 2, 1, 1, 1, 2, 2, 2,
       0, 0, 2, 0, 0, 3, 0, 2, 0, 2, 3, 0, 2, 0, 2, 0, 1, 1, 1, 1, 1, 2,
       0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 1, 3, 2, 2, 1, 0, 0, 0, 2, 1, 0, 0,
       2, 2, 0, 0, 0, 0, 1, 0, 2, 0, 3, 0, 1, 0, 0, 0, 0])}

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 0.711255149527642, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.9255813953488372, 'conf_matrix': array([[83,  6,  5,  0],
       [ 3, 45,  0,  0],
       [ 0,  2, 62,  0],
       [ 0,  0,  0,  9]], dtype=int64), 'pickle_file': LogisticRegression(C=1.1257141187883049, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([2, 0, 2, 0, 0, 2, 2, 1, 0, 0, 0, 1, 0, 0, 0, 3, 1, 0, 2, 0, 0, 2,
       1, 2, 0, 2, 1, 1, 1, 0, 1, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 1, 1, 0,
       2, 2, 0, 2, 0, 2, 0, 1, 1, 3, 0, 2, 1, 3, 0, 0, 2, 1, 2, 1, 2, 0,
       1, 2, 2, 2, 0, 0, 0, 1, 1, 1, 1, 0, 2, 2, 0, 1, 2, 2, 2, 2, 0, 0,
       2, 1, 0, 1, 1, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0,
       0, 0, 1, 2, 0, 2, 2, 2, 1, 0, 2, 2, 0, 3, 1, 1, 1, 0, 1, 2, 0, 0,
       2, 0, 1, 0, 1, 2, 0, 1, 2, 3, 0, 0, 2, 0, 1, 2, 1, 1, 1, 2, 2, 2,
       0, 0, 2, 0, 0, 3, 0, 2, 0, 2, 3, 0, 2, 0, 2, 0, 1, 1, 1, 1, 0, 2,
       0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 1, 3, 2, 2, 1, 0, 0, 0, 2, 1, 2, 0,
       2, 2, 0, 0, 0, 0, 2, 0, 2, 1, 3, 0, 1, 0, 0, 0, 0])}

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 18, 'max_features': 65, 'n_estimators': 19}}, 'score': 0.9255813953488372, 'conf_matrix': array([[87,  9,  3,  0],
       [ 1, 38,  1,  0],
       [ 2,  0, 65,  0],
       [ 0,  0,  0,  9]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=18, max_features=65, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=19, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([2, 2, 0, 2, 2, 2, 2, 0, 1, 2, 0, 1, 2, 2, 3, 2, 1, 1, 0, 0, 2, 2,
       3, 0, 2, 0, 1, 1, 0, 0, 2, 0, 1, 2, 2, 2, 0, 0, 0, 1, 2, 0, 3, 0,
       2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 0, 0, 3, 0, 0, 0, 2, 0, 2, 2, 0, 0,
       0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0,
       1, 0, 3, 2, 0, 2, 0, 0, 0, 1, 1, 1, 1, 1, 2, 0, 1, 2, 3, 1, 1, 0,
       0, 1, 1, 0, 2, 0, 0, 1, 0, 0, 0, 1, 3, 0, 0, 0, 0, 2, 2, 2, 0, 0,
       0, 0, 2, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 0, 0, 0, 1, 0, 1, 3, 0, 1,
       1, 2, 0, 2, 2, 2, 0, 0, 3, 0, 1, 2, 2, 0, 1, 0, 1, 0, 0, 0, 1, 0,
       2, 0, 2, 2, 0, 2, 2, 2, 0, 0, 2, 0, 1, 2, 0, 2, 1, 1, 1, 1, 0, 2,
       1, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 2])}

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 3.2019246007862354, 'penalty': 'l2', 'solver': 'sag'}}, 'score': 0.9162790697674419, 'conf_matrix': array([[85, 10,  3,  0],
       [ 5, 37,  0,  0],
       [ 0,  0, 66,  0],
       [ 0,  0,  0,  9]], dtype=int64), 'pickle_file': LogisticRegression(C=807.9150608519338, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([2, 2, 0, 2, 2, 2, 2, 0, 1, 2, 0, 1, 2, 2, 3, 2, 0, 1, 0, 0, 2, 2,
       3, 0, 2, 1, 1, 1, 1, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 1, 2, 0, 3, 0,
       2, 2, 2, 2, 2, 1, 1, 2, 0, 1, 0, 0, 3, 0, 0, 0, 2, 0, 2, 2, 0, 0,
       0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 2, 0, 0, 2, 0,
       1, 0, 3, 2, 0, 2, 0, 0, 0, 1, 1, 1, 1, 1, 2, 0, 1, 2, 3, 1, 1, 0,
       0, 1, 1, 0, 2, 0, 1, 1, 0, 0, 0, 1, 3, 0, 0, 0, 0, 2, 2, 2, 0, 0,
       1, 0, 2, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 3, 0, 1,
       1, 2, 0, 2, 2, 2, 0, 0, 3, 0, 1, 2, 2, 0, 1, 0, 1, 0, 0, 0, 1, 2,
       2, 0, 2, 2, 0, 2, 2, 2, 0, 0, 2, 0, 1, 2, 0, 0, 1, 1, 1, 1, 0, 2,
       1, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 2])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 13, 'max_features': 3, 'n_estimators': 9}}, 'score': 0.8263888888888888, 'conf_matrix': array([[91, 14],
       [11, 28]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=13, max_features=3, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=9, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1,
       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,
       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,
       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0])}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 0.15558991836824737, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.7847222222222222, 'conf_matrix': array([[89, 18],
       [13, 24]], dtype=int64), 'pickle_file': LogisticRegression(C=0.2946583626120247, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1,
       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,
       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,
       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'param': {'criterion': 'mae', 'max_depth': 6, 'max_features': 2, 'n_estimators': 10}}, 'score': 931.0789955041542, 'residual': <matplotlib.axes._subplots.AxesSubplot object at 0x000001CAA1737F48>, 'pickle_file': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=6,
           max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=10, n_jobs=None, oob_score=False,
           random_state=None, verbose=0, warm_start=False), 'y_pred': array([1200.06785221,  347.5744365 ,  366.85142166,  203.60196694,
       1510.85967334, 2204.56318828, 1649.67942061, 1606.27744163,
       1161.97389731, 1316.79994439,  584.19855068, 1989.70055166,
       1376.16420291, 2151.93278545,  287.35718117, 1422.71546676,
       2127.25994526, 1037.36471035,  627.36900269,  759.27311813,
        512.67889499, 1347.69803451, 1121.21660767, 1252.39346893,
       1989.70055166,  384.79346426, 1816.21253932,  704.08463819,
        760.75553571,  969.79959533,  946.66943894,  504.39636132,
       2161.69103848,  864.20521639,  759.27311813,  453.42475502,
       1989.70055166, 1197.50685221, 1933.50014529,  848.63161447,
       1989.70055166,  757.74139179,  512.67889499,  969.79959533,
       1373.82694801,  584.19855068, 1933.50014529, 1516.72389293,
       2043.59673755, 1393.90164633,  549.94314518,  317.45694176,
       1373.82694801,  351.89524989,  969.79959533,  734.31912179,
       1121.21660767, 1848.56163566,  199.59159657,  960.91500037,
        966.25472354, 1447.54058451, 2036.21104196, 1878.92196243,
       1670.08055208, 1315.37267166,  388.96779582, 1878.92196243,
       1139.77378004,  317.45694176, 1670.08055208,  629.87519089,
        206.31440713,  843.31247572,  663.02378318, 1549.30871487,
        989.77471509, 1447.54058451, 1652.23358727, 1742.50663821,
       1011.35353216,  963.39395965, 2135.77562666,  808.91393862,
       1349.02542379, 1848.56163566, 1599.8252112 , 2135.77562666,
       1254.3635988 , 2045.56989772,  518.04427961,  518.04427961,
       1315.37267166,  704.08463819,  305.61987806, 1121.21660767,
        317.45694176, 1185.92952302, 2127.25994526, 2043.59673755,
       2139.49261383,  243.83440919, 1987.81897046,  326.85305608,
        629.47566936, 1989.70055166,  636.68739868, 1644.92374809,
        969.79959533,  584.19855068, 1568.04605894,  748.35708998,
       1220.45616158,  206.31440713,  502.41719465,  206.31440713,
        251.42104713, 1276.92096768, 1933.50014529, 1194.56411028,
       2131.36073891,  347.5744365 , 1632.89151686,  760.75553571,
       1933.50014529, 1132.6645721 , 2139.49261383,  751.41542332,
       1276.92096768, 1606.27744163,  439.86481748, 1021.51781787,
       2131.36073891,  287.35718117, 2204.56318828, 1077.62347557,
       1925.36252383, 1777.3992082 ,  808.65938262,  851.76532488,
       2080.0464257 , 1537.43847788,  897.26683308, 2091.19422053,
       1987.81897046, 1227.65430261, 1816.21253932,  577.08805698,
       1280.95213651, 2036.21104196, 1390.86769407,  160.58282248,
        703.63092873, 1777.3992082 ,  140.52383185, 1925.36252383,
        282.85483634, 1593.35008044,  629.47566936, 1220.45616158,
       1422.71546676, 1152.85020046,  848.63161447,  748.35708998,
        936.58769392, 2204.56318828, 1813.6661625 , 2244.45715075,
       1514.92250162, 1606.27744163, 1041.64693707,  663.02378318,
       2194.86181465, 1997.24621947, 1315.37267166,  627.67942369,
        156.85637803,  577.08805698, 1813.6661625 , 1813.6661625 ,
       1041.64693707,  759.27311813, 1194.56411028,  552.99540999,
        234.76051131, 1037.36471035, 1985.03563713, 1738.28825623,
       1373.82694801,  707.27497635, 1238.5823625 ,  287.35718117,
       1347.69803451, 1692.19223578, 2102.00229413,  812.49177113,
       2168.15103848, 1742.50663821, 1065.74823666, 1276.92096768,
       1881.827766  ,  347.5744365 , 2135.77562666, 1549.30871487,
        689.46016122,  480.41335997, 1688.39315532, 1777.3992082 ,
       1640.89419285, 1045.78811354, 2093.00240235, 1413.30856388,
        455.6113465 ,  704.08463819, 1460.08851607, 1121.21660767,
        812.49177113, 1224.00949492,  584.19855068,  584.19855068,
       1514.92250162, 1390.86769407,  943.70450388,  679.27250016,
       1989.70055166, 2225.40944587, 1599.8252112 , 2093.00240235,
       1390.86769407, 1194.56411028, 1347.69803451,  902.91704953,
        584.19855068,  206.31440713, 1510.85967334,  946.66943894,
       1422.71546676, 1816.21253932, 1989.70055166,  140.52383185,
       1005.0357584 ,  508.67816239, 1129.35010616,  803.75517807,
       1881.827766  ,  956.81265433, 1599.8252112 , 1707.80681862,
       1461.29870869,  629.47566936,  502.41719465, 2046.40740421,
       1373.82694801, 1510.85967334, 1047.51312662,  577.08805698,
       1794.38932919,  512.67889499,  653.03463173,  808.65938262,
        388.96779582, 1373.82694801, 1933.50014529, 1599.8252112 ,
       1347.69803451,  869.07148817, 1077.62347557, 1194.56411028,
       1816.40996651, 1460.08851607, 1252.39346893,  851.76532488,
        384.79346426,  206.31440713,  848.63161447, 1917.26652499,
       1925.36252383, 1537.43847788,  869.07148817,  869.07148817,
        413.01031544, 2023.48065938, 1606.27744163,  663.02378318,
        966.25472354, 1985.03563713, 2139.49261383, 2043.59673755,
        317.45694176, 1858.12294838,  210.63135065, 1276.92096768,
       1373.82694801,  160.58282248,  627.67942369, 2236.126758  ,
       1777.3992082 , 1925.36252383, 1848.56163566,  906.95082731,
       1850.38941344, 1549.30871487,  653.03463173, 1504.43760191,
       2194.86181465,  763.19783077,  366.85142166, 1599.8252112 ,
       1848.56163566, 1495.69580437, 1722.51639517, 1003.29839576,
       1702.71681862,  453.42475502,  932.70838358, 2161.69103848,
       1987.81897046,  932.70838358, 1077.62347557,  359.34698443,
       2043.59673755,  707.27497635,  851.76532488,  632.17216058,
        518.04427961,  808.65938262,  203.60196694, 2184.26416476,
        963.39395965, 1922.57835716, 1037.36471035, 1077.62347557,
       1514.92250162,  703.63092873, 1422.71546676, 1280.95213651,
       1422.71546676, 1077.62347557, 1540.41347788, 1910.17037761,
        206.31440713, 2093.00240235, 2171.4090513 , 2178.4931865 ,
       1939.02102854,  549.94314518, 1848.56163566,  326.85305608,
       2199.79812418, 1447.54058451, 1093.36334865, 1373.82694801,
       2204.56318828, 1315.37267166, 1914.04486037,  966.25472354,
       1644.92374809, 1458.36851607, 1568.04605894,  932.70838358,
       1881.827766  , 1085.15012843, 1802.41440134, 1161.97389731,
       1881.827766  ,  897.26683308, 1180.24350293,  151.34417215,
        927.98252888, 1606.27744163, 1741.03836235, 1044.20496336,
       1194.56411028, 1809.25901965,  273.77666462, 1688.39315532,
        963.39395965,  717.17966137,  206.31440713, 1939.02102854,
        243.83440919,  869.07148817,  619.98807604, 2043.12794283,
       1549.30871487,  391.89171812,  151.34417215, 1933.50014529,
        206.31440713,  704.08463819,  617.01653133,  203.60196694,
       1165.54373858,  549.94314518,  504.39636132,  391.89171812,
        653.03463173, 1121.21660767,  317.45694176,  759.27311813,
       1227.65430261,  824.15613621, 2036.21104196,  663.02378318,
        518.04427961, 2045.56989772, 1427.50713343, 1813.12682503,
       1848.56163566,  206.31440713, 1939.02102854, 1517.96394975,
        881.11864138, 1280.95213651,  966.25472354,  287.35718117,
       1121.21660767,  946.66943894,  549.94314518, 1874.976056  ,
        504.39636132, 1777.3992082 , 1373.82694801])}

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.base.LinearRegression'>, 'param': {'normalize': 'False'}}, 'score': 831.7333284604344, 'residual': <matplotlib.axes._subplots.AxesSubplot object at 0x000001CAA1737F48>, 'pickle_file': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
         normalize='False'), 'y_pred': array([1208.69917778,  342.87344794,  366.89635837,  201.73884921,
       1504.98173966, 2222.66618856, 1652.12206601, 1604.07624516,
       1160.65335693, 1326.81182069,  603.12164419, 1988.44281193,
       1380.86336914, 2155.60223029,  267.80185287, 1418.89964398,
       2108.55736405, 1029.5283042 ,  645.16173743,  773.28392636,
        517.03954851, 1336.8213667 , 1109.60467228, 1250.73927102,
       1985.43994813,  379.90876818, 1802.26525615,  694.20851288,
        747.25910673,  987.48821096,  945.44811772,  496.01950189,
       2161.6079579 ,  863.36984044,  770.28106255,  448.97463564,
       1987.44185733, 1204.69535937, 1943.39985489,  837.34502082,
       1986.44090273,  745.25719753,  520.04241231,  985.48630176,
       1370.85382313,  598.11687119, 1942.39890029, 1527.00274089,
       2054.50581559, 1405.88723417,  536.05768593,  310.84290071,
       1365.84905013,  356.88681236,  986.48725636,  732.24478772,
       1125.6199459 , 1839.30057639,  190.7283486 ,  953.45575453,
        971.47293735, 1443.923509  , 2025.47813217, 1879.33876043,
       1670.13924882, 1310.79654708,  389.91831419, 1877.33685122,
       1148.64190172,  314.84671912, 1673.14211263,  623.14073621,
        222.75889583,  829.33738401,  672.18751166, 1552.02660591,
        998.49871157, 1440.9206452 , 1659.12874821, 1740.20607089,
       1019.5187582 ,  957.45957294, 2129.57741067,  816.3249742 ,
       1357.84141332, 1846.30725859, 1598.07051755, 2128.57645607,
       1255.74404402, 2046.49817879,  521.04336691,  524.04623072,
       1316.80227468,  692.20660368,  295.8285817 , 1103.59894468,
        321.85340132, 1176.66863055, 2107.55640945, 2055.5067702 ,
       2146.59363888,  252.78753386, 1974.42944752,  328.86008353,
        634.15123682, 1990.44472113,  646.16269203, 1649.1192022 ,
        983.48439256,  596.11496199, 1561.03519732,  738.25051532,
       1215.70585998,  205.74266761,  508.0309571 ,  208.74553141,
        257.79230686, 1273.76122684, 1940.39699108, 1191.68294956,
       2114.56309165,  344.87535714, 1624.09533718,  759.27056194,
       1948.40462789, 1141.63521951, 2147.59459348,  744.25624293,
       1286.77363665, 1600.07242676,  426.95363442, 1021.5206674 ,
       2113.56213705,  271.80567127, 2220.66427935, 1075.57221585,
       1926.38362667, 1760.22516291,  798.30779138,  849.35647603,
       2072.52299841, 1545.0199237 ,  889.39466007, 2096.54590883,
       1969.42467451, 1234.7239974 , 1814.27671136,  576.09586997,
       1295.78222806, 2027.48004137, 1396.87864276,  168.70734737,
        715.2285595 , 1789.25284634,  145.68539155, 1924.38171747,
        266.80089827, 1575.04856173,  635.15219142, 1212.70299618,
       1417.89868938, 1149.64285632,  835.34311162,  739.25146992,
        937.44048092, 2217.66141555, 1825.28721197, 2247.69005358,
       1519.99605868, 1616.08770037, 1031.53021341,  663.17892025,
       2200.64518734, 2009.46285855, 1304.79081947,  612.1302356 ,
        160.69971057,  574.09396077, 1822.28434817, 1824.28625737,
       1032.53116801,  769.28010795, 1189.68104036,  564.08441476,
        237.77321484, 1027.526395  , 1975.43040212, 1734.20034329,
       1361.84523173,  702.21614969, 1239.72877041,  282.81617188,
       1341.82613971, 1690.15834084, 2102.55163644,  826.33452021,
       2169.61559471, 1744.20988929, 1054.55216923, 1265.75359003,
       1885.34448803,  350.88108475, 2122.57072846, 1550.02469671,
        690.20469448,  478.00231907, 1680.14879483, 1766.23089052,
       1626.09724638, 1036.53498641, 2082.53254442, 1406.88818877,
        463.98895466,  696.21042208, 1457.93687342, 1127.6218551 ,
        824.33261101, 1226.7163606 ,  592.11114358,  599.11782579,
       1507.98460347, 1395.87768816,  938.44143552,  683.19801227,
       1981.43612972, 2226.67000696, 1588.06097154, 2088.53827203,
       1393.87577896, 1181.67340355, 1338.8232759 ,  911.41566129,
        594.11305278,  221.75794123, 1506.98364887,  944.44716312,
       1425.90632619, 1801.26430155, 1994.44853954,  144.68443695,
       1012.51207599,  515.03763931, 1134.62853731,  809.31829199,
       1881.34066963,  951.45384533, 1586.05906234, 1709.17647826,
       1474.95310163,  637.15410063,  503.0261841 , 2058.509634  ,
       1368.85191393, 1499.97696666, 1044.54262322,  583.10255217,
       1796.25952854,  516.03859391,  651.16746504,  794.30397298,
        387.91640499, 1367.85095933, 1945.40176409, 1593.06574455,
       1339.8242305 ,  875.38129566, 1064.56171524, 1183.67531275,
       1827.28912117, 1461.94069182, 1247.73640722,  854.36124904,
        381.91067738,  211.74839522,  830.33833861, 1908.36644385,
       1922.37980827, 1544.0189691 ,  865.37174965,  882.38797786,
        405.9335878 , 2017.47049536, 1613.08483657,  665.18082945,
        974.47580115, 1979.43422052, 2148.59554809, 2050.50199719,
        324.85626512, 1854.3148954 ,  234.77035104, 1287.77459125,
       1376.85955074,  177.71593878,  617.13500861, 2241.68432597,
       1781.24520953, 1916.37408066, 1840.30153099,  912.41661589,
       1849.3101224 , 1556.03042431,  654.17032884, 1494.97219365,
       2204.64900574,  779.28965396,  372.90208597, 1590.06288075,
       1843.30439479, 1493.97123905, 1715.18220587, 1001.50157538,
       1703.17075066,  438.96508963,  923.4271165 , 2163.6098671 ,
       1972.42753832,  934.43761711, 1083.57985266,  359.88967616,
       2051.50295179,  698.21233129,  853.36029443,  629.14646382,
        527.04909452,  800.30970058,  193.7312124 , 2191.63659593,
        959.46148214, 1915.37312606, 1030.52925881, 1073.57030665,
       1513.99033107,  706.21996809, 1413.89487098, 1299.78604647,
       1412.89391637, 1072.56935205, 1549.02374211, 1900.35880705,
        215.75221362, 2081.53158982, 2170.61654931, 2178.62418611,
       1957.4132193 ,  549.07009574, 1844.30534939,  331.86294733,
       2214.65855175, 1436.9168268 , 1089.58558026, 1360.84427712,
       2218.66237015, 1312.79845628, 1903.36167085,  968.47007355,
       1635.10583779, 1456.93591882, 1566.03997032,  926.42998031,
       1886.34544263, 1084.58080726, 1798.26143775, 1154.64762933,
       1882.34162423,  896.40134228, 1169.66194834,  154.69398296,
        921.4252073 , 1610.08197277, 1747.2127531 , 1041.53975942,
       1185.67722196, 1826.28816657,  263.79803447, 1684.15261324,
        964.46625514,  728.24096931,  218.75507742, 1958.4141739 ,
        248.78371545,  880.38606866,  611.129281  , 2038.49054198,
       1553.02756051,  395.92404179,  156.69589216, 1936.39317268,
        213.75030442,  697.21137668,  610.1283264 ,  194.732167  ,
       1165.65812994,  535.05673133,  491.01472889,  396.92499639,
        652.16841964, 1126.6209005 ,  312.84480991,  771.28201716,
       1233.7230428 ,  828.33642941, 2035.48767818,  664.17987485,
        525.04718532, 2043.49531498, 1426.90728079, 1799.26239235,
       1836.29771258,  220.75698662, 1956.4122647 , 1530.00560469,
        883.38893246, 1296.78318266,  972.47389195,  285.81903569,
       1114.60944529,  946.44907232,  546.06723194, 1864.32444141,
        492.01568349, 1773.23757272, 1366.85000473])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'param': {'criterion': 'mse', 'max_depth': 6, 'max_features': 1, 'n_estimators': 16}}, 'score': 955.2978977108863, 'residual': <matplotlib.axes._subplots.AxesSubplot object at 0x00000247EE3CAB88>, 'pickle_file': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=6,
           max_features=1, max_leaf_nodes=None, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=16, n_jobs=None, oob_score=False,
           random_state=None, verbose=0, warm_start=False), 'y_pred': array([ 503.62369954, 1277.54538692,  216.60554352,  625.68508642,
       1671.84244271, 2009.50232393, 1346.89845334,  505.33165409,
       1841.8806523 , 1517.70185293, 1807.91226393, 1059.17367739,
       1618.83767534, 1776.1694612 , 1664.04052813,  397.13688112,
       1279.77440262, 1012.52308672, 1456.15750391, 1398.6996064 ,
       1358.99502358,  698.04115442, 1433.15788471, 1982.26209792,
        444.70303541, 1987.06655926, 1424.86614942, 1256.98756631,
        767.03413472, 1088.00089252,  940.11964291, 1349.62437234,
       1774.56506559, 1914.54194563, 2009.50232393, 2185.10087896,
       1389.14739511, 1597.48271725,  762.52093738, 1982.26209792,
       1847.15188311, 1437.12595483, 1193.86505471,  444.70303541,
        652.03049522, 2201.75731109,  441.61158445, 1610.57752507,
       1836.32078508,  807.72524624, 1433.61933563,  526.69618233,
       1015.07580137, 2052.41559864, 1561.11217876, 1987.06655926,
       2036.52634049, 1433.61933563, 1841.8806523 , 1836.32078508,
       1696.17742347, 1507.7605061 , 1776.1694612 , 1310.6128181 ,
       1331.97888096,  354.71463489, 1841.8806523 ,  881.97140456,
        857.62514157, 2237.11283729,  762.52093738,  378.38660883,
        583.29576476,  317.82161747, 1562.51405074,  367.7514105 ,
       2098.54743767,  986.44188541,  662.21054771,  236.27495282,
       2100.29817296, 2127.43424684, 2201.75731109,  294.27123025,
       1254.86145149, 1519.54096738, 1696.17742347, 2201.75731109,
       1723.53383374,  556.72529674, 1331.97888096, 1138.67782355,
        854.99619136, 2231.61806089, 1168.75425786, 2100.29817296,
        767.03413472,  236.27495282, 1015.07580137, 1610.57752507,
       1174.23758766, 1664.04052813, 1184.77779812, 2093.51449149,
       1059.17367739, 1812.67357277, 1840.04434278, 1113.38248843,
        441.61158445,  698.04115442,  480.7148323 , 1694.0982568 ,
       1331.97888096, 1059.17367739, 1705.01577103,  623.62210688,
        347.86437372,  284.83482945, 1424.86614942,  807.72524624,
       1517.70185293, 1519.22887996,  355.54873815, 2176.94633674,
        698.04115442,  265.95677597,  546.15961558,  972.67681287,
        180.28219611, 2130.28812213,  608.85866316, 1610.57752507,
       2058.98756069, 1597.48271725,  556.72529674,  288.70514669,
        585.18160067,  577.75103286,  441.61158445, 1776.1694612 ,
        949.57251999, 1063.49187583, 1113.38248843,  397.13688112,
       1641.08819414, 1138.67782355, 1687.9128976 ,  482.49087397,
        978.34794828, 2141.28031549,  413.46606068,  193.88885179,
        216.60554352, 1193.86505471, 1204.25992118, 1946.68274314,
        849.50036323,  148.41916687, 2009.50232393, 1113.38248843,
       1191.88236476, 1776.1694612 ,  484.36140969, 1519.54096738,
       1450.22315785,  216.60554352, 1277.54538692, 1811.75702448,
       2036.52634049, 2031.01988342, 2201.75731109, 1946.68274314,
        216.60554352, 1696.17742347, 1102.35652456, 1812.67357277,
       1774.56506559,  585.18160067,  300.62032471, 1310.6128181 ,
       1256.98756631, 1310.6128181 ,  807.72524624, 1482.87526442,
       1736.24364747, 1189.23064062,  857.62514157, 2224.23335319,
        577.75103286, 1610.57752507,  355.73993251, 1216.1967985 ,
        972.67681287,  444.70303541, 1873.03422816,  972.67681287,
       2034.48494023, 1191.88236476,  767.03413472,  216.60554352,
       2133.57115304, 2145.40268239, 1106.09959687, 1015.07580137,
       1696.17742347, 1089.75875071, 1481.76198317,  902.83794702,
       1059.17367739, 1396.68426113,  972.67681287, 2127.43424684,
       1005.13441374,  441.61158445,  317.82161747,  940.11964291,
        546.15961558,  505.33165409, 1017.22811463, 1366.4891766 ,
       1716.17446625, 1753.20084882,  503.62369954, 1222.69335574,
        762.52093738, 1914.54194563,  603.89713043, 1214.22596517,
       1433.61933563, 1106.09959687,  857.62514157, 1664.04052813,
       1946.68274314,  234.7652306 ,  484.36140969, 1930.80511462,
        216.60554352,  920.93572519,  583.29576476,  207.98486182,
       1391.77626865,  603.89713043,  857.62514157,  972.67681287,
        698.04115442,  625.68508642,  400.58287185,  444.70303541,
       1597.48271725, 1690.88445209, 1610.57752507, 1113.38248843,
        837.53178594,  893.17388281, 1519.54096738,  288.70514669,
       2127.43424684, 2231.61806089,  148.41916687,  236.27495282,
       1426.67586422,  397.13688112, 1736.24364747,  444.70303541,
        952.17647832, 1946.68274314,  585.18160067, 1214.22596517,
       1059.17367739, 1776.1694612 , 1349.62437234,  893.17388281,
       1696.17742347, 1910.52183904,  236.27495282,  284.83482945,
       1922.42502979,  819.79896403,  625.68508642,  503.62369954,
        560.91738743, 1716.17446625, 2176.94633674,  623.62210688,
       1946.68274314,  986.44188541,  857.62514157,  413.46606068,
       1138.67782355,  277.79432019,  972.67681287, 1349.62437234,
       1099.21031921, 2127.43424684,  170.0747622 , 1310.6128181 ,
       2130.28812213,  625.68508642, 1604.64392646, 2231.61806089,
       1433.61933563,  845.72405701, 1113.38248843, 1873.03422816,
       1623.48934299,  347.86437372,  857.62514157, 1610.57752507,
        710.35380903, 1876.38461735,  476.81223203,  875.09333329,
        938.44656599,  298.95157471,  857.62514157,  762.52093738,
        211.74334396, 1433.15788471, 1716.17446625, 1869.42775238,
        174.59738101, 2011.59770792,  940.11964291, 1774.56506559,
       2093.51449149, 1841.8806523 , 1272.35236161, 1059.17367739,
        435.87052081, 1924.77094364,  560.91738743,  767.03413472,
       1847.15188311, 1543.42389627, 1984.53931567,  505.33165409,
       1138.67782355,  698.04115442, 1165.95294564, 1519.54096738,
       1793.52459586, 2001.01981924,  444.70303541,  891.99969023,
       1313.61538453, 2009.50232393, 1433.61933563, 1642.04059799,
       1222.69335574,  399.21556416, 2009.50232393, 1597.48271725,
       2034.98503614, 1366.4891766 , 1329.68295921, 1544.94202127,
        434.14933861,  854.99619136,  698.04115442,  399.21556416,
        311.76155418,  585.18160067, 1378.25884961, 2093.51449149,
       1480.92109775, 1984.53931567, 1036.67419601,  447.34333652,
        193.88885179,  560.91738743, 1774.56506559, 1424.86614942,
       1277.54538692, 2036.52634049, 1546.08711055, 1444.70261338,
       2022.93503033,  447.34333652, 1916.27914801, 1873.03422816,
        655.9623106 , 2130.28812213,  706.27290243,  932.18197372,
        148.41916687, 2105.26510004, 1205.69047674,  940.11964291,
       1723.53383374, 2176.94633674,  625.68508642,  972.67681287,
        366.04309072, 1211.12909017, 1214.22596517, 1435.03123029,
        286.96444901, 1389.14739511,  355.54873815,  441.61158445,
        317.82161747,  857.62514157, 1256.98756631,  444.70303541,
        216.60554352,  612.64898908,  818.86029216, 1717.37591714,
       1370.64334736, 1922.42502979,  845.72405701, 1222.69335574,
       1716.17446625,  577.75103286, 2201.75731109, 1522.89901534,
        399.21556416, 1597.48271725, 1873.03422816,  585.18160067,
        698.04115442, 1426.67586422, 1165.95294564])}

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.base.LinearRegression'>, 'param': {'normalize': 'False'}}, 'score': 858.3295962341517, 'residual': <matplotlib.axes._subplots.AxesSubplot object at 0x00000247EE3CAB88>, 'pickle_file': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
         normalize='False'), 'y_pred': array([ 517.49520864, 1272.91932086,  231.33455156,  639.56374068,
       1675.14513955, 2007.33163658, 1347.96145121,  495.4828504 ,
       1835.23501764, 1508.0513293 , 1802.21648028, 1053.79630023,
       1625.11705265, 1765.19569597, 1672.14345434,  382.419374  ,
       1299.93448779, 1012.77326897, 1467.02829804, 1405.99403202,
       1360.96875381,  697.59632149, 1456.02211892, 1979.31590791,
        451.45813393, 1988.32096356, 1421.00245809, 1246.90471567,
        779.64238401, 1078.81034368,  945.73563252, 1352.9642599 ,
       1787.20805421, 1906.27490104, 2011.33388353, 2185.43162595,
       1378.97886509, 1580.09177444,  758.63058751, 1972.31197575,
       1845.24063502, 1459.02380413, 1192.87438182,  450.45757219,
        653.57160501, 2201.44061376,  424.442967  , 1622.11536743,
       1826.22996199,  800.6541805 , 1444.01537806,  524.49914081,
       1018.7766394 , 2060.36140869, 1558.0794162 , 1990.32208703,
       2021.33950091, 1443.01481633, 1836.23557937, 1827.23052373,
       1689.15300388, 1497.04515018, 1764.19513424, 1317.94459907,
       1338.95639557,  351.40196013, 1830.23220895,  877.69743433,
        852.68339088, 2245.46533023,  764.63395794,  375.41544184,
        587.5345303 ,  322.38566972, 1565.08334837,  372.41375662,
       2095.38106953,  994.76315768,  669.58059282,  243.34129242,
       2101.38443995, 2119.39455124, 2195.43724333,  290.36769411,
       1243.90303046, 1523.05975537, 1695.15637431, 2199.43949028,
       1727.17434993,  552.51486947, 1335.95471036, 1145.84798013,
        844.67889698, 2237.46083633, 1168.8609001 , 2099.38331648,
        783.64463096,  251.34578632, 1019.77720113, 1604.10525615,
       1169.86146184, 1670.14233086, 1179.86707922, 2086.37601388,
       1059.79967066, 1818.22546809, 1828.23108547, 1114.83056625,
        416.4384731 ,  695.59519801,  481.47498607, 1680.14794824,
       1337.95583383, 1062.80135587, 1700.159183  ,  625.55587635,
        337.39409579,  261.3514037 , 1418.00077287,  793.65024834,
       1504.04908235, 1503.04852061,  357.40533055, 2168.4220764 ,
        714.60587103,  257.34915675,  533.50419645,  974.75192292,
        185.30871161, 2125.39792167,  615.55025897, 1617.11255874,
       2066.36477912, 1579.0912127 ,  551.51430773,  282.3632002 ,
        590.53621552,  575.52778945,  419.44015831, 1777.20243683,
        954.74068816, 1069.80528804, 1116.83168972,  384.42049748,
       1644.12772567, 1142.84629491, 1677.14626303,  478.47330086,
        986.75866378, 2139.405786  ,  407.43341746,  198.31601421,
        221.32893418, 1194.87550529, 1204.88112267, 1949.29905577,
        836.67440307,  147.28736557, 1999.32714267, 1106.82607234,
       1186.87101139, 1767.19681945,  475.47161564, 1521.05863189,
       1464.02661282,  215.32556375, 1270.91819738, 1812.22209766,
       2020.33893917, 2016.33669222, 2192.43555812, 1952.30074099,
        222.32949592, 1693.15525083, 1085.81427585, 1820.22659157,
       1786.20749247,  596.53958594,  296.37106453, 1310.9406669 ,
       1255.90977131, 1312.94179038,  791.64912486, 1486.03897106,
       1732.17715862, 1182.86876444,  857.68619957, 2220.45128678,
        578.52947466, 1621.1148057 ,  343.39746622, 1221.89067222,
        970.74967597,  433.44802264, 1865.25186978,  971.75023771,
       2018.3378157 , 1189.8726966 ,  777.64126053,  217.32668723,
       2132.40185383, 2149.41140338, 1095.81989323, 1014.77439244,
       1683.14963345, 1081.81202889, 1488.04009454,  910.71597169,
       1056.79798544, 1400.99122333,  979.75473161, 2109.38893386,
       1003.76821333,  417.43903484,  319.38398451,  942.73394731,
        535.50531992,  494.48228866, 1021.77832461, 1364.97100076,
       1721.1709795 , 1753.18895512,  518.49577038, 1231.8962896 ,
        756.62946403, 1909.27658625,  604.54407985, 1216.88786353,
       1446.01650154, 1097.8210167 ,  854.68451436, 1668.14120738,
       1954.30186446,  238.33848373,  477.47273912, 1932.28950623,
        224.33061939,  915.71878038,  588.53509204,  208.32163159,
       1393.98729116,  610.54745028,  851.68282914,  981.75585509,
        699.59744496,  633.56037025,  400.42948529,  440.45195481,
       1586.09514486, 1679.1473865 , 1610.10862658, 1101.82326365,
        827.66934743,  892.7058604 , 1515.05526146,  283.36376194,
       2113.39118081, 2236.46027459,  160.29466816,  246.34297763,
       1431.00807547,  380.41825053, 1730.17603514,  446.45532524,
        956.74181164, 1956.30298794,  599.54127116, 1214.88674005,
       1054.79686197, 1776.20187509, 1359.96819207,  899.70979257,
       1692.1546891 , 1899.27096887,  256.34859501,  264.35308892,
       1924.28501232,  820.66541527,  626.55643809,  505.48846778,
        563.52104859, 1715.16760907, 2165.42039119,  624.55531461,
       1951.30017925,  995.76371942,  848.68114393,  406.43285572,
       1136.84292449,  258.34971849,  980.75529335, 1355.96594512,
       1084.81371411, 2107.38781038,  174.30253249, 1303.93673474,
       2122.39623645,  632.55980851, 1600.1030092 , 2240.46252154,
       1441.01369285,  831.67159438, 1120.83393668, 1863.2507463 ,
       1627.11817612,  338.39465753,  858.68676131, 1607.10694136,
        728.61373537, 1882.26141932,  472.46993043,  874.69574912,
        936.73057688,  293.36937932,  846.68002045,  767.63564315,
        212.32387854, 1450.01874849, 1718.16929429, 1860.24906109,
        180.30590292, 2012.33444527,  937.73113862, 1788.20861595,
       2085.37545215, 1833.23389416, 1264.91482695, 1061.80079413,
        415.43791136, 1929.28782101,  557.51767816,  780.64294574,
       1848.24232023, 1545.07211361, 1984.3187166 ,  497.48397388,
       1144.84741839,  694.59463627, 1160.8564062 , 1518.05694668,
       1796.21310985, 1997.3260192 ,  448.45644872,  881.69968129,
       1323.9479695 , 2004.32995136, 1445.0159398 , 1640.12547872,
       1225.89291917,  391.42442965, 2001.32826615, 1585.09458313,
       2031.34511829, 1362.96987728, 1331.9524634 , 1548.07379882,
        411.43566441,  842.6777735 ,  712.60474756,  393.42555312,
        303.3749967 ,  592.53733899, 1377.97830335, 2092.37938431,
       1483.03728585, 1981.31703139, 1032.78450373,  464.46543652,
        192.31264378,  560.51936338, 1784.206369  , 1412.99796418,
       1284.92606172, 2019.33837744, 1549.07436056, 1462.02548935,
       2015.33613048,  461.46375131, 1911.27770973, 1867.25299325,
        654.57216675, 2124.39735993,  726.61261189,  920.72158907,
        149.28848904, 2103.38556343, 1206.88224615,  943.73450904,
       1726.17378819, 2172.42432336,  636.56205547,  975.75248466,
        366.4103862 , 1210.8844931 , 1215.88730179, 1457.02268066,
        277.36039151, 1381.9805503 ,  355.40420708,  431.44689917,
        310.37892887,  849.68170567, 1248.90583915,  452.45869567,
        228.33286635,  618.55194418,  818.66429179, 1714.16704733,
       1372.97549466, 1921.28332711,  830.67103265, 1229.89516612,
       1720.17041776,  583.53228335, 2203.44173723, 1536.06705796,
        388.42274443, 1588.09626834, 1870.25467847,  600.5418329 ,
        707.60193887, 1425.00470504, 1157.85472098])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'param': {'criterion': 'mse', 'max_depth': 6, 'max_features': 1, 'n_estimators': 14}}, 'score': 941.3077588719375, 'residual': <matplotlib.axes._subplots.AxesSubplot object at 0x000001F2B5619C48>, 'pickle_file': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=6,
           max_features=1, max_leaf_nodes=None, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=14, n_jobs=None, oob_score=False,
           random_state=None, verbose=0, warm_start=False), 'y_pred': array([1317.9131318 , 1905.7289184 ,  511.48511201, 1965.70439305,
        449.35559155, 1050.4329238 , 1748.93366528,  151.05234958,
        673.24673701, 2175.15118373,  691.55762149, 1845.56492725,
       1664.26373493, 1119.25095812, 2074.9470799 ,  582.73701797,
       2236.51683202,  349.80097915,  355.75834938,  850.61374015,
        355.75834938, 1702.96909913, 1377.6641272 ,  870.98281348,
       1188.21209498, 1188.21209498, 1273.01591483,  936.72450604,
       1980.58651567, 1481.53613174,  716.5896343 ,  574.5241583 ,
        634.45333111,  589.51128267,  852.19492241, 1845.56492725,
       1650.40792461, 1475.3530439 ,  850.61374015, 1133.46680518,
        967.63390168, 1400.22987637,  515.47253198,  252.85198316,
       1599.86323863, 1722.14763174, 1192.62613268,  208.38781383,
        187.00278886, 2117.31688607, 2095.83912238, 2046.16507001,
       1595.01200209,  613.60628747, 1271.63191775, 1192.62613268,
       1228.48657288,  850.61374015,  929.38486432, 1141.21026009,
        808.25492029,  449.35559155, 1845.56492725, 1772.8424682 ,
       1368.58489907, 1650.40792461, 1195.79295468,  969.86052506,
       1931.21269059, 2224.78189206, 1682.722028  , 1188.21209498,
        852.19492241, 1600.42147544,  449.35559155, 1842.28979497,
       1317.9131318 , 2236.51683202, 1748.93366528,  281.00266103,
       1192.62613268, 2095.83912238,  233.42653941, 1772.8424682 ,
       2202.09600574,  694.21635165, 1143.79325329,  929.38486432,
        543.90209736,  690.94563427,  929.38486432,  401.05832633,
        490.09978402, 1566.2536286 , 2236.51683202,  894.56737328,
       1395.24355366, 1435.5989435 , 1344.48647774, 1702.96909913,
        515.47253198, 1117.17493771,  309.45582926,  659.88082665,
       2199.03201765,  212.84787653, 2117.31688607,  852.19492241,
       1591.08255312, 1190.60629141,  483.75823885, 1883.68419482,
       1808.30100812, 1016.86072582,  760.69401821, 1344.48647774,
       1912.71319999, 1722.14763174, 1225.18232118,  412.38123658,
       1271.63191775,  659.88082665, 1772.8424682 ,  670.2022652 ,
       1449.42522374,  608.50558446,  691.55762149, 1277.13694373,
       1157.19229726, 1637.21714779,  967.63390168, 1368.58489907,
       2175.15118373, 1746.45652242, 1395.24355366, 2044.61546683,
       1475.3530439 ,  147.54569475, 1222.25217898,  894.56737328,
       2042.3159318 ,  691.55762149, 2044.61546683, 1342.6096193 ,
       2085.7643227 ,  686.77521302,  147.54569475, 2217.09097936,
       1451.83955015, 1810.74297998, 1435.5989435 , 1557.81658518,
       1882.29038275, 1637.21714779,  929.38486432,  540.19411474,
       1971.94802114,  909.85321904,  522.72844754, 1122.04157507,
        909.85321904,  808.25492029,  233.42653941, 2038.49404535,
        483.75823885,  515.47253198, 2224.78189206, 1746.45652242,
       1117.17493771,  626.37956165,  288.60294368, 1653.69384429,
       1905.7289184 ,  778.98381938, 1655.36628296,  621.47638095,
       2042.3159318 ,  613.60628747,  808.25492029, 2099.56531285,
       1650.40792461, 1424.21790175,  909.85321904,  963.80344533,
       1568.2545061 ,  826.43374503,  801.93112967,  929.38486432,
        281.00266103, 1937.97156444, 2139.30241283, 1042.59885354,
        850.61374015,  781.19300306, 2184.63989435, 1317.9131318 ,
       1518.65571697,  778.98381938,  233.42653941,  929.38486432,
        909.85321904,  270.65164689, 1892.94005486, 1791.30320135,
       1368.58489907, 1428.3757799 ,  314.97577431,  741.94377146,
       1746.45652242, 1600.42147544,  659.88082665,  330.5102322 ,
        870.98281348,  781.19300306, 2139.30241283,  766.79380776,
        951.92432914, 1722.14763174,  449.35559155, 1690.11468426,
        686.77521302, 1883.68419482,  506.33681587, 2139.30241283,
       1451.83955015, 1117.17493771, 1905.7289184 ,  766.79380776,
       1937.97156444,  658.23026764, 1772.8424682 ,  483.75823885,
       1271.63191775, 1225.18232118,  634.45333111, 1141.21026009,
        894.56737328,  957.81563441, 1157.19229726, 1937.97156444,
        778.98381938, 1141.21026009, 2175.15118373,  508.04860408,
       1564.07960263,  760.69401821, 2139.30241283, 1016.86072582,
       1222.25217898,  585.60844654, 1879.08451991,  585.60844654,
        309.45582926,  233.42653941,  147.54569475,  701.99154043,
        967.63390168, 2139.30241283,  550.38056661,  690.94563427,
       1458.65372866,  990.32449128,  457.20243148, 2180.03330594,
        157.73051177, 1650.40792461, 1446.06317732,  394.96826608,
        479.8933579 , 1810.74297998,  355.75834938, 1892.94005486,
       1746.45652242, 2199.03201765,  691.55762149, 1980.58651567,
       1319.30429342,  349.80097915,  355.75834938, 1690.11468426,
       1587.63475092,  511.48511201,  582.73701797, 1924.19875561,
       2236.51683202, 2095.83912238, 1098.2530437 ,  909.85321904,
       1862.61384708, 1323.50608351,  270.65164689,  212.84787653,
        483.75823885, 1323.50608351,  720.40812169,  870.98281348,
       1937.97156444, 1640.71986291, 2224.78189206,  433.65441436,
        171.62170875, 1057.37449909, 1959.34143009, 1042.59885354,
        314.97577431,  449.35559155,  850.61374015, 1746.45652242,
        634.45333111, 1882.29038275, 2074.9470799 , 2115.30498131,
       1971.94802114,  550.38056661, 2006.96480082, 1587.63475092,
       1344.48647774, 1854.47322035, 1344.48647774,  355.75834938,
       1941.40828246,  401.05832633, 1970.29316999,  543.90209736,
       1395.24355366, 1845.56492725,  872.76691659, 1057.37449909,
        781.19300306,  490.09978402,  929.38486432, 1262.84714669,
        858.82130865, 1269.67980736, 2002.08413188, 1772.8424682 ,
        613.60628747,  433.65441436, 1702.96909913, 1475.3530439 ,
       1883.68419482, 2224.78189206,  909.85321904, 2072.46340643,
        203.16683068, 1615.07002586, 1929.49191137, 1812.96107004,
       2042.3159318 , 2188.80247938,  394.96826608,  749.32334512,
       2006.96480082,  355.75834938, 2236.51683202,  688.59664159,
        192.97159505, 1697.26553588,  401.05832633,  707.79276022,
       1057.37449909,  340.82944291, 2116.10077406,  695.76094039,
        596.20309007, 1442.68836628, 2095.83912238,  433.65441436,
        401.05832633, 1098.2530437 ,  212.84787653, 1599.86323863,
        449.35559155,  314.97577431, 1722.14763174,  876.83946237,
        212.84787653,  967.63390168,  449.35559155, 1791.30320135,
       1650.40792461, 2042.3159318 ,  394.96826608, 1264.41020976,
       1650.40792461,  967.63390168, 1941.40828246, 1395.24355366,
       2212.82135969, 2139.30241283, 2006.96480082, 1517.70968522,
        766.79380776, 1155.00450611,  894.56737328,  865.7192397 ,
        585.60844654, 1791.30320135,  781.19300306,  314.97577431,
        574.5241583 , 1225.18232118, 1098.2530437 , 1599.86323863,
        171.62170875,  369.47588649, 1316.46194133, 1477.51538156,
        852.19492241,  159.87353698, 2224.78189206, 2004.89008426,
       1722.14763174, 1395.24355366, 2044.61546683, 1931.21269059,
       1424.21790175, 1057.37449909, 2042.3159318 ,  511.48511201,
        349.80097915, 2118.72406743, 1225.18232118])}

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.base.LinearRegression'>, 'param': {'normalize': 'True'}}, 'score': 858.0843846482097, 'residual': <matplotlib.axes._subplots.AxesSubplot object at 0x000001F2B5619C48>, 'pickle_file': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
         normalize='True'), 'y_pred': array([1322.12902959, 1904.155991  ,  507.09127434, 1961.15863156,
        447.08849481, 1046.11624376, 1752.14894954,  154.07492145,
        679.09924232, 2173.16845255,  715.10091003, 1851.15353576,
       1673.14528982, 1106.11902329, 2075.16391266,  579.09460977,
       2246.17183431,  339.08349166,  356.08427919,  834.10642276,
        357.08432552, 1707.14686489, 1381.13176279,  874.10827578,
       1184.12263667, 1182.12254402, 1283.12722289,  936.11114796,
       1983.15965072, 1488.13671961,  729.10155859,  570.09419284,
        639.0973893 ,  597.09544363,  845.10693234, 1850.15348943,
       1647.14408536, 1476.13616371,  835.10646909, 1135.12036673,
        966.11253772, 1409.1330599 ,  519.09183024,  258.0797393 ,
       1615.14260295, 1718.14737447, 1198.12328523,  213.07765465,
        194.07677447, 2107.16539507, 2093.16474652, 2052.16284717,
       1601.14195439,  613.09618484, 1279.12703759, 1203.12351686,
       1240.1252309 ,  842.10679337,  929.11082368, 1142.12069101,
        806.10512565,  456.08891174, 1846.15330413, 1763.14945912,
       1369.13120688, 1649.14417801, 1206.12365583,  984.11337158,
       1926.15701017, 2235.17132473, 1679.14556778, 1185.122683  ,
        854.10734927, 1609.14232499,  444.08835584, 1832.15265557,
       1325.12916856, 2245.17178799, 1753.14899586,  281.08080479,
       1201.12342421, 2099.16502447,  249.07932237, 1770.14978339,
       2214.1703519 ,  705.10044678, 1144.12078366,  920.11040675,
        533.0924788 ,  693.09989087,  925.11063838,  397.08617854,
        491.09053313, 1564.14024035, 2248.17192696,  891.10906332,
       1389.13213339, 1431.13407906, 1350.1303267 , 1704.14672591,
        517.09173759, 1111.11925492,  292.08131437,  661.09840846,
       2209.17012027,  222.07807158, 2108.1654414 ,  849.10711765,
       1599.14186174, 1194.12309993,  486.0903015 , 1881.15492552,
       1800.15117316, 1018.11494665,  745.1022998 , 1351.13037303,
       1908.15617631, 1717.14732814, 1237.12509192,  406.08659547,
       1275.12685229,  657.09822316, 1768.14969074,  678.09919599,
       1447.13482027,  611.09609219,  714.10086371, 1289.12750085,
       1151.12110793, 1628.14320518,  971.11276935, 1366.13106791,
       2184.16896213, 1745.14862526, 1408.13301358, 2062.16331043,
       1475.13611738,  148.0746435 , 1214.12402644,  892.10910964,
       2032.16192066,  713.10081738, 2057.1630788 , 1348.13023405,
       2080.16414429,  687.09961292,  149.07468982, 2221.17067618,
       1449.13491292, 1803.15131213, 1430.13403274, 1553.13973077,
       1878.15478654, 1626.14311253,  922.1104994 ,  524.09206187,
       1978.15941909,  899.10943392,  522.09196922, 1134.1203204 ,
        902.1095729 ,  808.1052183 ,  244.07909074, 2019.16131843,
        485.09025518,  516.09169127, 2226.1709078 , 1742.14848628,
       1121.11971817,  625.09674074,  287.08108274, 1654.14440964,
       1902.15589835,  775.10368956, 1666.14496555,  621.09655544,
       2033.16196699,  615.09627749,  810.10531095, 2085.16437591,
       1634.14348313, 1417.13343051,  906.1097582 ,  956.11207447,
       1572.14061095,  826.10605216,  797.10470872,  928.11077736,
        276.08057316, 1935.15742709, 2135.16669219, 1026.11531725,
        836.10651541,  789.10433812, 2193.16937906, 1321.12898326,
       1521.13824835,  779.10387486,  247.07922972,  921.11045308,
        905.10971187,  260.07983195, 1892.1554351 , 1785.15047828,
       1363.13092893, 1424.13375478,  325.08284311,  737.10192919,
       1746.14867158, 1607.14223234,  659.09831581,  330.08307473,
        876.10836843,  781.10396751, 2139.16687749,  765.10322631,
        944.11151856, 1719.1474208 ,  458.08900439, 1689.14603103,
        692.09984455, 1888.1552498 ,  494.09067211, 2150.16738707,
       1454.13514455, 1109.11916227, 1905.15603733,  767.10331896,
       1937.15751975,  653.09803786, 1765.14955177,  481.09006988,
       1269.12657434, 1228.12467499,  640.09743562, 1140.12059835,
        887.10887801,  948.11170387, 1155.12129324, 1940.15765872,
        780.10392119, 1136.12041305, 2183.16891581,  504.09113536,
       1568.14042565,  749.1024851 , 2145.16715544, 1011.11462237,
       1225.12453602,  586.09493405, 1862.15404534,  583.09479507,
        298.08159232,  241.07895177,  146.07455085,  719.10109534,
        979.11313996, 2140.16692381,  560.09372959,  700.10021515,
       1465.13565413,  996.11392749,  473.08969927, 2189.16919376,
        165.07543103, 1645.14399271, 1444.13468129,  385.08562263,
        474.0897456 , 1821.15214599,  352.08409389, 1891.15538877,
       1751.14890321, 2205.16993497,  716.10095636, 1988.15988234,
       1309.12842736,  340.08353799,  355.08423287, 1690.14607736,
       1581.14102788,  508.09132066,  580.0946561 , 1917.15659324,
       2243.17169534, 2096.16488549, 1096.11856003,  903.10961922,
       1856.15376738, 1330.12940019,  259.07978563,  232.07853484,
        482.0901162 , 1335.12963182,  730.10160492,  875.10832211,
       1939.1576124 , 1631.14334415, 2225.17086148,  423.087383  ,
        169.07561633, 1061.11693864, 1958.15849258, 1037.11582683,
        312.08224087,  467.08942132,  844.10688602, 1743.14853261,
        642.09752828, 1879.15483287, 2074.16386633, 2115.16576568,
       1975.15928011,  558.09363694, 2000.16043825, 1589.14139849,
       1356.13060465, 1853.15362841, 1353.13046568,  353.08414022,
       1950.15812198,  399.08627119, 1970.15904849,  531.09238615,
       1402.13273562, 1839.15297985,  879.10850741, 1052.11652171,
        785.10415282,  489.09044048,  918.1103141 , 1251.12574048,
        864.10781253, 1267.12648169, 2010.1609015 , 1772.14987604,
        612.09613851,  420.08724402, 1702.14663326, 1483.13648799,
       1880.15487919, 2228.17100045,  909.10989717, 2071.16372736,
        209.07746935, 1624.14301988, 1925.15696384, 1824.15228497,
       2022.16145741, 2197.16956436,  383.08552998,  744.10225347,
       1999.16039192,  358.08437185, 2244.17174166,  683.09942762,
        199.0770061 , 1698.14644796,  395.08608589,  724.10132696,
       1070.11735557,  335.08330636, 2116.165812  ,  702.1003078 ,
        606.09586056, 1437.13435702, 2094.16479284,  431.0877536 ,
        398.08622486, 1095.11851371,  235.07867381, 1620.14283457,
        455.08886542,  309.0821019 , 1721.14751345,  883.10869271,
        217.07783996,  963.11239875,  442.08826318, 1791.15075623,
       1637.14362211, 2034.16201331,  384.08557631, 1255.12592578,
       1638.14366843,  972.11281568, 1945.15789035, 1400.13264297,
       2218.1705372 , 2131.16650688, 2005.16066988, 1533.13880426,
        757.1028557 , 1149.12101528,  884.10873904,  867.1079515 ,
        581.09470242, 1787.15057093,  787.10424547,  307.08200925,
        571.09423917, 1235.12499927, 1098.11865269, 1618.14274192,
        178.07603326,  374.08511305, 1315.12870531, 1470.13588576,
        856.10744192,  167.07552368, 2223.17076883, 2014.16108681,
       1725.14769875, 1401.1326893 , 2060.16321778, 1927.15705649,
       1420.13356948, 1066.11717027, 2021.16141108,  510.09141332,
        336.08335269, 2119.16595098, 1229.12472132])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'param': {'criterion': 'mae', 'max_depth': 6, 'max_features': 2, 'n_estimators': 16}}, 'score': 991.8533150353771, 'residual': <Figure size 640x480 with 1 Axes>, 'pickle_file': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=6,
           max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=16, n_jobs=None, oob_score=False,
           random_state=None, verbose=0, warm_start=False), 'y_pred': array([ 646.27289433,  126.09624892,  699.43079613, 2191.7138955 ,
       2156.20494791, 1704.18942301, 2256.49364898, 1537.25230057,
        810.89298432, 1222.44204634, 2038.58351082,  549.279393  ,
       1527.44346625,  769.62163686,  843.53059039, 1646.35813166,
       2237.22109295, 2131.51537895,  315.83345267, 1923.69766597,
        322.24212003, 1716.72157638, 1288.53526161,  456.22300655,
       1389.15116927, 2204.48507559, 1196.24311015, 1565.87987572,
       1995.2533451 ,  690.13307893, 1917.82459865,  512.43081313,
       1521.03898534, 1871.80390064, 1750.987895  , 1273.71308926,
       2091.60268057, 2145.35256556, 1275.39707364, 1351.17507874,
       1440.77690546, 1786.93962005, 1565.87987572, 2040.25563924,
        355.23721473,  208.69660363, 2200.8236475 , 1117.000545  ,
       1062.2301978 , 2040.04689465,  589.88993576, 1062.2301978 ,
        887.7047587 , 2040.04689465, 1426.80838086, 1122.47653538,
       1521.03898534, 2038.58351082,  973.68132153, 1159.33748427,
        646.27289433, 1659.73454829, 1592.57909772, 1878.98675034,
       2171.99903941,  550.67225014,  883.57127354, 1467.93510508,
        546.5887044 , 1635.88083924, 1426.80838086,  280.70441811,
        457.22647877, 2037.85147258, 1812.07125453,  764.4863348 ,
        764.4863348 ,  427.90415893, 1963.74310872,  700.79481128,
       1525.18390429,  221.02896026, 1151.16281492,  207.03707982,
       2256.49364898, 1044.18979605, 2038.58351082,  810.89298432,
       1118.14711711, 1275.39707364, 1182.71323667, 1521.03898534,
        584.51900779, 1543.1807426 ,  835.92286856, 1949.46373415,
       1351.17507874,  883.45275664, 1949.46373415,  673.98972754,
       1344.3817709 ,  983.91347668,  252.5456746 ,  969.57966923,
       1275.39707364,  881.84290816,  201.98164451, 1312.00904764,
        839.72055286, 1330.12753276,  355.23721473,  584.51900779,
        409.91243157,  843.53059039, 1004.87681863, 1618.74033899,
       2218.42769227,  700.79481128,  280.70441811, 1312.00904764,
        243.58236458, 1457.32541622,  769.62163686, 1834.6817747 ,
        537.4240452 , 2141.90596529, 2005.037212  , 1041.98119215,
        429.35515808,  810.89298432, 1646.35813166, 2171.99903941,
       2141.90596529,  646.27289433, 1028.78001961, 1565.87987572,
       1592.57909772, 1521.03898534, 1796.42515162,  427.90415893,
        247.58248713, 1389.15116927,  932.13589498, 1196.24311015,
       2128.71082209, 1440.77690546,  883.57127354,  971.30410105,
        843.53059039,  460.92481102, 1812.07125453,  350.11982858,
        980.02334425, 2245.78384212, 1389.15116927, 1011.40386111,
       1839.13829943, 1008.00281069, 2073.56650011, 1182.71323667,
        883.45275664,  971.30410105, 1097.9775149 , 1909.92401998,
       1516.88066898, 2200.8236475 ,  932.13589498, 1278.67589858,
        724.67482964, 1494.51863068, 1118.14711711, 1900.29167142,
       1993.3644036 , 2141.90596529, 1836.79187086, 1089.94338738,
       2194.27968498,  427.90415893,  724.67482964, 1163.83972509,
       1159.33748427, 1963.74310872, 1258.59431895, 1316.41442256,
        163.46444232, 1441.87392201, 2089.49665378, 1607.31799154,
       2056.62151477, 1031.82064461,  894.07312361,  504.07903273,
        327.05306966,  622.65304336, 1761.96336379, 1062.2301978 ,
        935.42929314,  507.63407933, 1716.72157638, 2171.99903941,
       1991.04735419,  745.32201791, 1182.71323667,  843.53059039,
       1777.05590156, 1885.08818597, 1713.28058687,  769.62163686,
       1523.21914026,  911.91467984, 2233.85262137, 2131.51537895,
       2145.35256556, 1648.24321608,  810.89298432, 2038.58351082,
        465.81572204, 1836.79187086, 1964.70248372,  765.98735579,
       1338.95596412, 1151.16281492,  208.8617593 ,  765.98735579,
        355.23721473,  429.35515808,  429.35515808,  584.51900779,
       1384.05745196, 1470.85385508,  456.22300655,  247.58248713,
        577.70961443, 1592.57909772,  806.67821835, 2251.92752344,
       2131.51537895, 1949.46373415,  935.42929314, 1220.03162968,
       2094.27410341, 1521.03898534, 1461.85429799, 1646.35813166,
       2249.23645201, 2145.35256556,  163.46444232,  763.14542571,
        544.90908937,  272.8949384 , 1690.09238796,  315.83345267,
       1995.2533451 , 2091.60268057, 1273.71308926,  812.29755421,
       2153.79432198, 1748.944145  ,  153.61915793, 1273.71308926,
       1565.87987572, 1836.79187086,  350.11982858,  160.37700568,
       1062.2301978 ,  504.07903273, 1949.46373415,  429.35515808,
        504.07903273, 1521.03898534, 2005.037212  , 1923.69766597,
       1690.09238796, 2200.8236475 , 1716.72157638,  156.17124127,
        763.14542571, 1646.35813166, 1992.40000143,  795.49071278,
        193.8343592 ,  504.73242325, 1192.18548426, 2171.99903941,
       1252.16516346,  610.65052634,  965.74041816,  247.58248713,
        302.79585934,  883.57127354, 1936.32106418,  839.72055286,
        163.46444232, 1523.21914026, 1869.6504422 ,  673.98972754,
        427.90415893, 1860.82295931, 1375.71395398,  699.43079613,
        615.84710909, 1869.6504422 , 1226.21160109, 1866.34412462,
       1613.19883359,  215.67369841, 1962.41937243,  503.0894494 ,
        806.67821835, 1777.05590156, 1273.71308926, 1523.21914026,
       2038.58351082,  315.83345267, 1441.87392201, 1827.92486039,
       1441.87392201,  207.03707982, 1993.3644036 ,  574.64113499,
       1305.02189304, 1830.16249197,  206.9789468 ,  562.16071988,
        207.03707982, 2256.49364898,  610.65052634,  924.50112828,
       2202.31482397,  550.67225014, 1166.21840156, 1777.05590156,
       1441.87392201, 1926.82270364, 1923.69766597,  843.53059039,
       1871.80390064,  932.13589498, 2089.49665378, 2171.99903941,
       2207.61542707,  843.53059039, 1267.9769477 ,  839.72055286,
       2200.8236475 ,  284.79489575, 1196.24311015, 1062.2301978 ,
       2200.8236475 , 1489.19158651,  315.83345267,  839.72055286,
        340.77930223, 1752.62494565, 1239.47650868, 1264.56622247,
       1031.82064461, 1521.03898534, 1491.40497936, 2040.04689465,
        504.73242325, 2037.85147258, 1196.24311015,  881.84290816,
        758.47607057, 2171.99903941, 1117.000545  ,  932.13589498,
       1222.44204634, 1222.44204634, 1276.39197457, 2052.27857999,
       1157.25597385,  207.03707982, 1543.1807426 , 1936.32106418,
       1009.65281069,  932.13589498, 1031.82064461, 1777.05590156,
        806.67821835,  694.72484802,  280.70441811,  587.14984317,
        907.54975408, 1871.80390064,  504.73242325,  163.46444232,
        207.03707982, 2200.8236475 , 2000.01676112, 1031.82064461,
        162.22483706, 2153.79432198, 2256.49364898, 1351.17507874,
        907.54975408,  350.11982858, 1426.80838086, 1011.40386111,
        971.30410105,  465.81572204, 1878.98675034,  924.50112828,
       1422.0360165 , 1004.87681863, 1062.2301978 , 1182.71323667,
        522.15962326, 1318.46068788, 1182.71323667, 2131.51537895,
        163.46444232,  574.64113499, 1646.35813166,  456.22300655,
        459.54999871, 1607.31799154,  294.15678164, 1537.25230057,
       1118.14711711, 1523.21914026,  709.89549007])}

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.base.LinearRegression'>, 'param': {'normalize': 'True'}}, 'score': 888.5032645177504, 'residual': <Figure size 640x480 with 1 Axes>, 'pickle_file': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
         normalize='False'), 'y_pred': array([ 648.3779349 ,  141.18635034,  697.39645097, 2193.9617577 ,
       2158.94853194, 1697.7743298 , 2247.98216315, 1551.71915949,
        807.43801764, 1216.59257008, 2030.90016345,  552.34165853,
       1543.71613646,  777.42668127,  855.45615582, 1644.75430222,
       2232.97649497, 2118.93341678,  310.25021186, 1909.85444011,
        328.25701368, 1717.78188737, 1294.62204463,  455.30500429,
       1387.65718736, 2213.96931527, 1196.5850125 , 1567.72520555,
       1997.88769345,  687.39267218, 1903.85217284,  516.3280549 ,
       1503.7010213 , 1865.83781344, 1750.79435737, 1270.61297554,
       2091.92321406, 2147.94437527, 1282.61751008, 1356.64547312,
       1436.67570342, 1788.80871677, 1557.72142676, 2061.91187769,
        368.27212883,  235.22187095, 2207.967048  , 1127.55893886,
       1045.5279528 , 2043.90507587,  596.3582852 , 1060.53362098,
        882.46635855, 2051.9080989 , 1410.66587857, 1131.56045038,
       1508.7029107 , 2026.89865193,  982.50414643, 1153.56876371,
        647.37755702, 1665.76223767, 1593.7350304 , 1882.84423738,
       2172.95382224,  556.34317005,  877.46446916, 1473.68968494,
        543.33825763, 1627.74787828, 1421.67003524,  275.2369861 ,
        443.30046974, 2056.9099883 , 1805.81514071,  748.41572279,
        749.41610066,  414.28951126, 1972.87824648,  704.39909612,
       1542.71575858,  238.22300458, 1138.56309553,  232.22073731,
       2246.98178528, 1044.52757492, 2025.89827405,  816.44141855,
       1119.55591583, 1281.6171322 , 1175.57707705, 1497.69875403,
        587.35488429, 1553.71991525,  831.44708673, 1954.87144466,
       1353.64433948,  868.46106825, 1950.86993314,  678.38927127,
       1341.63980493,  995.50905886,  254.22905064,  963.49696673,
       1279.61637645,  874.46333552,  204.2101567 , 1300.6243119 ,
        839.45010976, 1339.63904918,  362.26986156,  591.35639581,
        402.28497671,  845.45237703, 1005.51283765, 1624.74674464,
       2221.9723383 ,  708.40060763,  265.23320731, 1301.62468978,
        243.22489398, 1459.68439464,  778.42705915, 1827.82345405,
        529.33296732, 2137.94059648, 2016.89487314, 1042.52681916,
        423.29291217,  812.43990703, 1646.75505798, 2171.95344436,
       2138.94097436,  651.37906854, 1023.51963946, 1565.72444979,
       1587.73276313, 1500.69988767, 1794.81098404,  408.28724398,
        248.22678337, 1402.66285554,  933.48563037, 1195.58463462,
       2105.92850436, 1437.6760813 ,  880.46560279,  978.50263492,
        850.45426643,  474.31218399, 1814.81854162,  346.2638155 ,
        994.50868098, 2235.97762861, 1386.65680948, 1013.51586068,
       1845.83025586, 1007.5135934 , 2078.91830163, 1180.57896644,
        865.45993461,  965.49772249, 1090.54495735, 1900.8510392 ,
       1493.69724252, 2209.96780376,  932.48525249, 1291.62091099,
        733.4100546 , 1492.69686464, 1103.54986977, 1895.84914981,
       2008.89185011, 2132.93870709, 1838.82761071, 1084.54269007,
       2194.96213558,  416.29026701,  734.41043248, 1163.5725425 ,
       1160.57140886, 1979.88089163, 1249.60504008, 1314.6296022 ,
        164.19504155, 1451.6813716 , 2085.92094678, 1605.73956494,
       2070.9152786 , 1028.52152886,  890.46938158,  492.3189858 ,
        334.25928095,  630.37113308, 1756.79662465, 1062.53437674,
        941.4886534 ,  514.32729914, 1716.78150949, 2174.954578  ,
       1989.88467042,  739.41232188, 1179.57858856,  857.45691158,
       1774.80342647, 1891.84763829, 1700.77546343,  776.42630339,
       1536.71349131,  910.47693916, 2228.97498346, 2124.93568406,
       2144.94324163, 1652.75732525,  815.44104067, 2023.8975183 ,
        484.31596277, 1833.82572132, 1970.87749072,  764.42176885,
       1340.63942705, 1142.56460705,  218.21544701,  765.42214673,
        370.27288459,  421.29215641,  417.29064489,  592.35677369,
       1382.65529797, 1469.68817342,  459.3065158 ,  253.22867276,
        583.35337278, 1576.72860646,  797.43423885, 2239.97914012,
       2122.9349283 , 1956.87220041,  940.48827552, 1211.59068068,
       2095.92472557, 1517.70631161, 1466.68703979, 1642.75354646,
       2237.97838437, 2149.94513103,  178.20033185,  752.4172343 ,
        535.33523459,  257.23018428, 1689.77130677,  317.25285701,
       2000.88882708, 2090.92283618, 1268.61221978,  821.44330794,
       2156.94777618, 1734.78831131,  152.190507  , 1271.61335341,
       1560.7225604 , 1835.82647708,  352.26608277,  159.19315215,
       1048.52908644,  491.31860793, 1955.87182254,  425.29366792,
        494.31974156, 1513.70480009, 2019.89600678, 1911.85519587,
       1690.77168465, 2199.96402497, 1724.78453253,  147.18861761,
        750.41647854, 1635.75090131, 2011.89298375,  790.4315937 ,
        200.20864519,  509.32540975, 1187.58161159, 2168.95231073,
       1242.60239493,  604.36130823,  954.49356583,  251.22791701,
        295.24454368,  878.46484703, 1936.86464284,  834.44822037,
        167.19617518, 1527.7100904 , 1860.83592405,  677.38889339,
        411.28837762, 1853.83327889, 1364.64849615,  694.39531733,
        612.36433126, 1864.83743556, 1231.59823826, 1859.83554617,
       1622.74598888,  237.2226267 , 1966.8759792 ,  495.32011944,
        799.43499461, 1763.7992698 , 1267.6118419 , 1518.70668949,
       2034.90167496,  304.24794458, 1447.67986009, 1824.82232041,
       1446.67948221,  230.21998155, 2009.89222799,  572.34921611,
       1298.62355614, 1826.82307617,  206.21091246,  566.34694884,
        223.2173364 , 2249.98291891,  601.3601746 ,  913.47807279,
       2211.96855952,  559.34430369, 1165.57329826, 1771.80229283,
       1452.68174948, 1921.85897466, 1912.85557375,  849.45388855,
       1875.84159223,  931.48487461, 2088.92208042, 2179.95646739,
       2214.96969315,  844.45199915, 1263.61033038,  840.45048764,
       2198.96364709,  282.23963125, 1198.58576826, 1051.53022007,
       2202.96515861, 1487.69497524,  327.2566358 ,  837.449354  ,
        335.25965883, 1753.79549101, 1236.60012766, 1261.60957463,
       1025.52039522, 1514.70517797, 1488.69535312, 2045.90583163,
        506.32427611, 2052.90847678, 1199.58614614,  871.46220188,
        745.41458915, 2182.95760103, 1126.55856098,  934.48600825,
       1218.59332584, 1214.59181432, 1289.62015523, 2069.91490072,
       1145.56574068,  226.21847004, 1552.71953737, 1937.86502072,
       1012.5154828 ,  927.4833631 , 1032.52304037, 1769.80153707,
        793.43272733,  690.39380581,  273.23623034,  595.35790732,
        900.47316037, 1871.84008071,  505.32389823,  165.19541943,
        222.21695852, 2201.96478073, 2015.89449527, 1029.52190674,
        161.19390791, 2154.94702042, 2245.9814074 , 1355.64509524,
        898.47240461,  342.26230398, 1411.66625645, 1015.51661643,
        964.49734461,  475.31256186, 1884.84499314,  915.47882855,
       1408.66512281, 1003.51208189, 1059.5332431 , 1173.57632129,
        524.33107793, 1321.63224736, 1176.57745493, 2119.93379466,
        168.19655306,  575.35034975, 1648.75581373,  461.30727156,
        473.31180611, 1612.7422101 ,  288.24189852, 1550.71878161,
       1109.55213704, 1526.70971252,  715.40325278])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 16, 'max_features': 6, 'n_estimators': 11}}, 'score': 0.8055555555555556, 'conf_matrix': array([[85, 17],
       [11, 31]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=16, max_features=6, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,
       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,
       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,
       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0])}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 3.9072079188596525, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.7361111111111112, 'conf_matrix': array([[77, 19],
       [19, 29]], dtype=int64), 'pickle_file': LogisticRegression(C=3.9072079188596525, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,
       1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,
       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,
       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,
       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0])}

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 19, 'max_features': 102, 'n_estimators': 18}}, 'score': 0.9323383084577115, 'conf_matrix': array([[137,  16,  16],
       [ 10, 282,   8],
       [  9,   9, 518]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=19, max_features=102, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=18, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([1, 2, 0, ..., 2, 0, 2])}

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 0.43118727730463, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.9522388059701492, 'conf_matrix': array([[142,  16,   6],
       [ 10, 286,   7],
       [  4,   5, 529]], dtype=int64), 'pickle_file': LogisticRegression(C=0.3697815358218506, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='newton-cg', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([1, 2, 0, ..., 2, 0, 2])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'param': {'criterion': 'mae', 'max_depth': 6, 'max_features': 4, 'n_estimators': 10}}, 'score': 13.780285960976313, 'residual': <Figure size 640x480 with 1 Axes>, 'pickle_file': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=6,
           max_features=4, max_leaf_nodes=None, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=10, n_jobs=None, oob_score=False,
           random_state=None, verbose=0, warm_start=False), 'y_pred': array([3.57276852, 0.97186987, 1.10358855, 2.40727352, 1.8105798 ,
       1.57465359, 0.95853371, 4.38802132, 4.00708238, 1.02637887,
       2.24575977, 4.37911085, 0.90990806, 1.81699959, 2.96217316,
       1.33785991, 3.42846649, 3.84085738, 0.48439172, 2.21917478,
       1.77404467, 1.56385475, 1.24202995, 2.664784  , 2.54490173,
       4.09062094, 3.39504304, 1.11050758, 2.79127652, 3.78673064,
       3.39504304, 0.85182482, 4.04731956, 3.01252453, 1.75960734,
       2.20725913, 1.11589227, 2.3690394 , 2.06720461, 7.78197917,
       3.78496428, 1.948378  , 2.22030417, 2.80623477, 4.82837502,
       1.19939793, 2.30724753, 3.27703105, 1.90508621, 3.70888768,
       3.85399659, 1.96070248, 2.12134273, 2.16568671, 2.5179639 ,
       3.37484188, 2.8701508 , 1.83628331, 1.55576455, 1.10531217,
       1.51115247, 2.06438994, 1.26278822, 0.74521526, 2.23340998,
       2.10763057, 4.39741369, 3.37430092, 3.55603532, 2.1115955 ,
       6.80820733, 1.79934087, 0.99875109, 4.1842796 , 3.21302406,
       6.46811474, 4.26555096, 1.87006465, 1.95504602])}

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.base.LinearRegression'>, 'param': {'normalize': 'False'}}, 'score': 16.844885259934898, 'residual': <Figure size 640x480 with 1 Axes>, 'pickle_file': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
         normalize='False'), 'y_pred': array([ 1.68362003,  2.66584861,  2.62586962,  1.58735442,  3.00229652,
        1.65352404,  0.65155062,  2.66389099,  2.05815951,  1.90252305,
        2.62989658,  2.35454074,  2.60200743,  1.87788929,  1.84534808,
        0.44743561,  2.52622775,  1.7317954 ,  1.25431651,  3.13905046,
        2.53366097,  1.44924426,  1.69341392,  3.15348912,  1.57949693,
       -0.01007998,  1.70578249,  1.70940413,  2.88194886,  2.80079695,
        1.70578249,  2.37314768,  1.83846671,  2.07532304,  1.79277685,
        2.44881021,  2.90179054,  3.12457981,  2.35265037,  3.50661931,
        2.87633888,  3.48380457,  2.59784557,  2.23018293,  2.40870555,
        1.11036379,  2.39392731,  2.95219557,  1.77431335,  2.60562165,
        1.67254077,  3.426766  ,  2.43620571,  2.55414275,  2.82356216,
        1.22463986,  3.2996872 ,  1.91031381,  2.49032622,  1.71972075,
        1.49280858,  2.31893818,  1.92890635,  1.52272871,  3.11949408,
        1.51795395,  2.02699126,  3.20413353,  2.9343063 ,  1.3008862 ,
        3.75993906,  2.31858753,  1.86583074,  1.84146141,  2.89772526,
        1.36280953,  3.97167108,  2.7937757 ,  3.05501777])}

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 18, 'max_features': 115, 'n_estimators': 15}}, 'score': 0.9395348837209302, 'conf_matrix': array([[76,  7,  5,  0],
       [ 0, 44,  1,  0],
       [ 0,  0, 74,  0],
       [ 0,  0,  0,  8]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=18, max_features=115, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([0, 1, 0, 3, 0, 0, 0, 0, 3, 2, 0, 0, 2, 0, 2, 1, 3, 3, 2, 2, 0, 0,
       0, 2, 2, 1, 2, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 3, 1, 0, 0, 1,
       0, 0, 2, 0, 2, 1, 0, 1, 2, 2, 1, 2, 0, 0, 1, 0, 2, 0, 2, 1, 0, 2,
       0, 0, 2, 2, 2, 0, 2, 1, 1, 2, 2, 3, 0, 0, 0, 0, 2, 2, 1, 2, 2, 0,
       0, 1, 2, 1, 0, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 0, 0, 0, 0,
       0, 0, 0, 2, 2, 1, 2, 1, 2, 0, 0, 1, 2, 0, 2, 2, 0, 1, 0, 0, 0, 1,
       2, 1, 1, 1, 0, 0, 0, 2, 2, 0, 0, 1, 2, 0, 1, 1, 2, 0, 1, 1, 1, 2,
       0, 2, 0, 0, 0, 1, 0, 3, 0, 1, 0, 0, 1, 0, 3, 0, 1, 2, 0, 2, 1, 2,
       0, 2, 0, 0, 2, 0, 1, 0, 2, 1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2,
       2, 2, 2, 2, 0, 1, 0, 1, 2, 0, 2, 0, 0, 0, 1, 2, 1])}

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 4.129873887998049, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.9534883720930233, 'conf_matrix': array([[74,  5,  2,  0],
       [ 2, 45,  0,  0],
       [ 0,  1, 78,  0],
       [ 0,  0,  0,  8]], dtype=int64), 'pickle_file': LogisticRegression(C=6.099432351418684, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([0, 1, 0, 3, 0, 2, 0, 0, 3, 2, 0, 0, 2, 0, 2, 1, 3, 3, 2, 2, 0, 0,
       1, 2, 2, 1, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 3, 1, 0, 0, 1,
       0, 0, 2, 0, 2, 1, 0, 1, 2, 2, 1, 2, 0, 0, 1, 0, 2, 0, 2, 1, 0, 2,
       0, 0, 2, 2, 2, 1, 2, 1, 1, 2, 2, 3, 0, 0, 0, 0, 2, 2, 1, 2, 2, 0,
       0, 1, 2, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 0, 0, 0, 0,
       0, 0, 0, 2, 2, 1, 2, 1, 2, 0, 1, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 1,
       2, 1, 1, 1, 0, 0, 0, 2, 2, 0, 0, 1, 2, 0, 1, 1, 2, 0, 1, 1, 1, 2,
       0, 2, 0, 0, 2, 1, 0, 3, 0, 1, 1, 0, 1, 0, 3, 0, 1, 2, 2, 2, 2, 2,
       0, 2, 0, 0, 2, 0, 1, 0, 2, 1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2,
       2, 2, 2, 2, 0, 1, 0, 1, 2, 0, 2, 1, 0, 0, 1, 2, 1])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 10, 'max_features': 2, 'n_estimators': 12}}, 'score': 0.8928571428571429, 'conf_matrix': array([[93, 10],
       [ 5, 32]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=10, max_features=2, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=12, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,
       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,
       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0])}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 0.26344245504149816, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.8285714285714286, 'conf_matrix': array([[87, 13],
       [11, 29]], dtype=int64), 'pickle_file': LogisticRegression(C=0.24487538323136024, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='newton-cg', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1,
       0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,
       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,
       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 1, 0, 1, 0, 0])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 9, 'max_features': 5, 'n_estimators': 2}}, 'score': 0.8242424242424242, 'conf_matrix': array([[99, 22],
       [ 7, 37]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=9, max_features=5, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=2, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,
       0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,
       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 0.6543472798531172, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.8, 'conf_matrix': array([[94, 21],
       [12, 38]], dtype=int64), 'pickle_file': LogisticRegression(C=10.98529355409727, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,
       1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,
       0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'param': {'criterion': 'mse', 'max_depth': 11, 'max_features': 4, 'n_estimators': 1}}, 'score': 79.37200436305515, 'residual': <Figure size 640x480 with 1 Axes>, 'pickle_file': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=11,
           max_features=4, max_leaf_nodes=None, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=1, n_jobs=None, oob_score=False, random_state=None,
           verbose=0, warm_start=False), 'y_pred': array([ 1.64      ,  0.        ,  0.        ,  5.51090909, 12.1       ,
        0.        ,  1.01      ,  0.        ,  0.        ,  5.51090909,
        0.        ,  8.12      ,  2.29222222,  0.676     , 16.        ,
        0.205     ,  1.19714286, 11.53      , 12.1       ,  2.29222222,
        1.01      ,  2.29222222,  2.93      , 10.08      ,  0.        ,
        7.69666667,  0.        ,  0.        ,  5.51090909,  0.        ,
       13.06      ,  5.51090909,  0.        ,  0.        ,  0.        ,
        0.        ,  1.88      ,  0.        ,  0.        ,  1.19714286,
        7.69666667,  0.        ,  0.        ,  6.96      ,  0.        ,
        1.76      ,  1.19714286,  0.        ,  0.        ,  0.        ,
        0.        ,  0.        ,  2.29222222,  2.29222222, 10.08      ,
        1.64      , 13.06      ,  0.71      ,  1.64      ,  0.184     ,
        0.        ,  1.19714286,  0.        ,  0.        ,  5.51090909,
        2.29222222,  0.        ,  7.48      ,  1.19714286])}

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.base.LinearRegression'>, 'param': {'normalize': 'False'}}, 'score': 117.18691012581452, 'residual': <Figure size 640x480 with 1 Axes>, 'pickle_file': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
         normalize='False'), 'y_pred': array([1.73850674, 1.30381465, 0.94325886, 3.5066819 , 2.853557  ,
       2.78201135, 2.00449466, 2.99875282, 1.10274943, 2.53964844,
       0.89847625, 2.59076145, 2.27341553, 2.39984548, 2.027918  ,
       3.48400047, 2.2704601 , 2.01302932, 2.0606008 , 1.92599331,
       1.65883152, 1.82567024, 2.96192654, 2.0953438 , 1.75374616,
       1.9999324 , 0.8529166 , 1.16220128, 2.40431696, 1.02157678,
       2.06803868, 2.64074858, 3.25516108, 0.96746985, 2.4947504 ,
       2.17052345, 3.19243083, 2.43672174, 2.69439771, 1.86164846,
       1.79860838, 1.77475471, 2.3015886 , 2.65362971, 2.88856396,
       2.84613724, 2.3428738 , 2.58396682, 1.86720987, 2.5257413 ,
       3.89897471, 1.90230433, 2.57273267, 1.49167918, 2.32414604,
       2.28337657, 1.69187113, 1.37891616, 2.46175381, 2.85929386,
       1.56472503, 3.10540837, 1.05794768, 0.99090028, 2.47131599,
       2.0202277 , 1.77820626, 2.033094  , 2.45229984])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 11, 'max_features': 3, 'n_estimators': 15}}, 'score': 0.8363636363636363, 'conf_matrix': array([[93, 22],
       [ 5, 45]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=11, max_features=3, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,
       0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,
       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0,
       0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1])}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 9.025400228689978, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.7878787878787878, 'conf_matrix': array([[87, 24],
       [11, 43]], dtype=int64), 'pickle_file': LogisticRegression(C=8996934129.63731, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,
       0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,
       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,
       0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'param': {'criterion': 'mae', 'max_depth': 10, 'max_features': 2, 'n_estimators': 9}}, 'score': 10.786289737444628, 'residual': <Figure size 640x480 with 1 Axes>, 'pickle_file': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,
           max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=9, n_jobs=None, oob_score=False, random_state=None,
           verbose=0, warm_start=False), 'y_pred': array([2.66821208, 0.37582786, 2.70479611, 1.84373708, 1.81558695,
       1.95869138, 3.10825397, 1.69920973, 0.025     , 1.76905537,
       4.59027778, 0.4625    , 1.82111111, 1.13310564, 1.59748972,
       1.61556175, 1.00392236, 0.2880977 , 1.1877723 , 1.25978398,
       4.37873016, 3.73560185, 3.52037037, 0.80340354, 3.49714286,
       0.19744367, 0.59416119, 2.71409914, 1.17429293, 0.20571212,
       2.02438059, 0.65977694, 2.37067851, 3.673685  , 2.85299236,
       3.40666667, 4.75379082, 2.07637723, 3.41592593, 1.22889666,
       1.27356654, 5.1365062 , 2.94825066, 1.17300872, 0.30011461,
       3.8       , 0.45269841, 1.28499379, 1.11812945, 1.44218412,
       4.31676546, 4.5       , 0.55273868, 1.06578006, 2.45888889,
       3.69414316, 1.17835167, 0.66082786, 0.32527778, 1.07671336,
       4.46982834, 0.3605    , 2.50273155, 3.31635594, 3.92479611,
       0.98016119, 1.53665242, 0.26388889])}

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.base.LinearRegression'>, 'param': {'normalize': 'False'}}, 'score': 11.621816878041837, 'residual': <Figure size 640x480 with 1 Axes>, 'pickle_file': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
         normalize='False'), 'y_pred': array([2.03382122, 1.50146382, 3.15356925, 1.88595211, 2.33029934,
       2.97454263, 0.59170936, 3.03655713, 1.71062233, 2.41495231,
       2.06791673, 1.32194877, 0.86909824, 1.34874167, 2.40691046,
       2.80997639, 2.11711788, 1.29938747, 2.16791506, 2.51074277,
       1.89096989, 1.9414048 , 3.35299529, 1.96002143, 0.89111034,
       0.81330778, 1.31549043, 2.44536856, 1.69164214, 1.8489818 ,
       1.71472538, 3.15409005, 2.84706174, 1.64953901, 2.12097639,
       1.37646353, 2.15552691, 1.47697545, 2.36220197, 1.47879547,
       1.40168918, 2.51419606, 2.87890628, 1.98666158, 1.69304917,
       1.6124709 , 1.4756424 , 2.60736668, 2.74612148, 2.10287475,
       3.16433197, 2.82078697, 1.46541012, 2.16108329, 2.56690691,
       2.75400619, 1.95120255, 1.34980658, 2.54373296, 2.83006447,
       2.92294222, 1.64214834, 2.9084266 , 2.34555755, 2.16155466,
       1.96471723, 1.57338518, 1.8441529 ])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'param': {'criterion': 'mae', 'max_depth': 6, 'max_features': 1, 'n_estimators': 16}}, 'score': 993.8244311418705, 'residual': <Figure size 640x480 with 1 Axes>, 'pickle_file': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=6,
           max_features=1, max_leaf_nodes=None, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=16, n_jobs=None, oob_score=False,
           random_state=None, verbose=0, warm_start=False), 'y_pred': array([ 487.39822389,  148.64435134, 2019.59864903, 1454.7169843 ,
       1469.8575937 , 2177.15156309, 1914.30865826, 1014.144354  ,
       1281.85085986, 1257.24176455,  305.98013001,  629.39055345,
        843.50059831, 1879.64568495,  322.91995752, 2150.08554882,
       1595.67758458, 1942.90498473,  200.19177134,  988.94184775,
       1801.90516868, 1123.81189339,  622.85004478,  577.28189344,
       1155.95632788,  319.17677158, 1119.9476602 ,  500.25552256,
       2198.40551211,  416.26157571, 1602.87256291, 2110.89991674,
        909.65648129,  440.68267581, 1199.24300405,  737.84872761,
       1116.74637242, 1224.0995866 , 1565.43127258, 2039.47817183,
       1812.46490028, 1602.87256291, 2039.47817183, 1942.90498473,
       1942.90498473,  144.87913218,  218.5762199 ,  144.87913218,
       1475.27326334, 2144.71779574, 1759.16412216,  500.25552256,
       1807.34054978, 1029.92222408, 1262.9381918 , 1055.64503225,
        893.5287787 , 1879.64568495,  500.25552256, 1016.59363037,
       2177.15156309, 1874.32538668,  451.94615086, 1883.41724745,
        943.49684287,  277.15264035,  248.82974632,  305.98013001,
        671.26498944,  664.74100792, 2039.47817183, 1807.34054978,
       1916.53024917, 2129.50358358,  500.25552256, 2177.15156309,
        909.65648129, 1318.5783215 , 1926.20167642, 2203.57319891,
       2198.40551211, 1435.96379118, 1431.22064639, 1088.87281729,
       1778.15742303, 1262.9381918 ,  758.82574833,  195.02883786,
       1078.6064818 , 1635.70148747, 1965.6961952 , 2096.86643156,
       1879.64568495, 1805.26133855,  970.77286877,  954.39001859,
       1692.85840253,  162.68830628, 1389.80230513,  557.29483268,
        943.49684287, 2110.89991674, 1281.85085986,  935.18091908,
       1155.95632788, 1088.87281729, 1565.43127258, 1445.114679  ,
       1427.85988707,  305.98013001, 1078.6064818 , 1692.85840253,
        690.39842767, 1942.90498473, 1807.34054978, 1746.97548953,
       1926.20167642, 1454.7169843 , 1224.0995866 ,  934.25800241,
        939.09062117,  355.08516518, 1429.01390493, 1281.85085986,
       1119.9476602 ,  590.58065591, 1265.8788168 , 1520.69333169,
        438.38044729, 1484.31083066,  221.05799074, 1883.41724745,
       1916.53024917, 2047.55205458, 2129.50358358, 1732.96964998,
        901.20234062, 1523.4276004 , 1224.0995866 , 1638.72803276,
        771.49047448, 1942.90498473, 1200.63040283, 1521.9588504 ,
       1321.02511637,  657.94572787, 2142.54720038, 1199.24300405,
       1281.85085986,  311.58073812,  119.9434292 ,  240.53921811,
        450.36594576,  964.51200986, 1805.26133855, 1155.95632788,
        889.01994103, 1591.21349415,  500.25552256, 2218.69387855,
        934.25800241, 1746.97548953,  707.92330867,  833.77616963,
       1140.04843976, 1523.4276004 , 1284.95781238, 1055.64503225,
       1017.84918593,  579.67633789, 1843.00166523, 1642.99258181,
       1876.24129577,  289.00108217, 1055.64503225, 1707.4787486 ,
        329.42971408,  558.73680406, 1778.15742303,  962.59548888,
       2144.71779574, 2198.40551211,  487.39822389, 2203.57319891,
       1224.0995866 , 1078.06059364,  633.62139477, 1078.6064818 ,
        544.83463357, 1656.70551262, 1345.02083711, 1454.7169843 ,
       1484.31083066, 2240.21783114,  384.8770393 , 2144.71779574,
        451.94615086, 1142.74933261, 1427.85988707, 1116.74637242,
        404.69719962, 1942.90498473, 1983.32117951, 1909.7790154 ,
       2110.89991674, 1692.85840253, 1429.01390493, 1029.92222408,
        144.87913218, 1281.85085986, 1328.05472491,  579.67633789,
       2134.08575224, 1645.51536111, 1523.4276004 , 1551.54439505,
       1257.24176455, 1914.30865826, 1694.84017336, 1376.86013678,
        500.25552256,  970.77286877,  660.5030125 , 2110.89991674,
       1116.74637242,  549.94403121, 1265.8788168 , 1786.22891875,
       1454.7169843 , 1942.90498473, 1033.16024492, 1565.43127258,
       1525.41964677,  889.01994103,  805.40564402, 1078.6064818 ,
       2123.237532  ,  557.29483268, 1843.00166523,  500.25552256,
       1006.74356035, 2047.55205458, 1375.53461595,  557.29483268,
       2039.47817183,  579.67633789, 1281.85085986, 1281.85085986,
        353.47344133,  810.53209407, 1369.80670171,  768.45086789,
        200.19177134, 1523.4276004 ,  362.95701969,  273.82746619,
        322.91995752,  557.29483268,  500.25552256,  362.95701969,
       2198.40551211,  311.58073812,  768.45086789, 1220.56802452,
        843.50059831,  438.38044729,  311.58073812,  660.5030125 ,
       1427.85988707, 1027.72373271, 1694.84017336,  239.772674  ,
        373.65736063,  451.94615086, 1224.0995866 , 1547.88665696,
       1473.63487048,  606.30737781, 1532.32621543,  843.50059831,
       1431.22064639,  606.30737781, 1591.21349415, 1999.35595241,
        843.50059831, 1694.84017336, 1389.80230513,  889.01994103,
       1759.16412216, 1723.01350603,  353.47344133,  988.94184775,
        660.5030125 , 1281.85085986,  451.94615086, 2192.97375451,
       1199.24300405, 2047.55205458,  937.75638204,  162.68830628,
        579.67633789,  843.50059831, 1101.46576026,  305.98013001,
        778.18663849, 1078.6064818 , 1199.24300405, 1707.4787486 ,
        200.19177134,  438.38044729,  577.28189344,  768.45086789,
        858.69988247, 1429.01390493,  627.61620145,  824.69318234,
        144.87913218, 1565.43127258,  970.77286877, 1088.87281729,
       1649.12511908,  311.58073812, 1367.37788678,  934.25800241,
       2240.21783114, 1751.5816214 ,  871.88536017,  872.69438794,
       1723.01350603,  758.82574833,  935.18091908,  897.65648808,
        671.26498944, 1318.22511637,  970.77286877,  162.68830628,
       1389.80230513,  660.5030125 , 1484.31083066,  218.5762199 ,
       1484.31083066, 2049.42600918,  655.5478112 ,  935.18091908,
       1037.45762132,  438.38044729, 1262.9381918 ,  871.88536017,
        771.49047448, 1133.11470557,  325.26210495,  418.28749544,
       1387.69201101, 1321.02511637, 1284.95781238, 1459.40080718,
        450.36594576,  362.95701969, 1592.72477234,  557.29483268,
       1883.41724745,  974.85038102,  889.01994103, 1121.96814339,
       1187.1040982 , 2177.15156309, 1375.53461595, 1445.114679  ,
       2056.7097213 , 1645.51536111,  998.58815776,  708.91986039,
        322.91995752,  305.98013001, 2043.51745862, 2224.49398359,
        577.28189344,  943.49684287,  195.02883786, 1044.88338221,
       1980.18364032,  805.40564402, 2177.15156309, 1876.24129577,
       1197.27609799, 2092.49707459, 1843.00166523,  273.82746619,
       1182.60183662, 1521.9588504 , 1518.15037985, 1756.42275702,
       1321.89142384,  289.00108217, 2183.83393265,  239.772674  ,
        805.40564402,  500.25552256, 1881.54568152,  805.40564402,
        871.88536017,  579.67633789, 1389.80230513,  353.47344133,
        195.02883786, 1427.85988707, 1345.02083711, 1650.44200504,
        362.95701969,  239.772674  , 1650.44200504, 2183.83393265,
        674.13418587,  266.20480956, 1004.65606035, 1834.37891237,
       2096.86643156, 2137.82408578,  822.25333859, 1867.70219189,
       1197.27609799, 1807.34054978, 1690.78949227])}

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.base.LinearRegression'>, 'param': {'normalize': 'False'}}, 'score': 926.0226542201231, 'residual': <Figure size 640x480 with 1 Axes>, 'pickle_file': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
         normalize='True'), 'y_pred': array([ 485.13570711,  154.67181817, 2016.28505924, 1461.50628809,
       1468.51612816, 2177.51138081, 1904.12761814, 1010.87371226,
       1274.24341769, 1249.20827459,  299.87564816,  633.34375428,
        835.62771054, 1890.107938  ,  336.92765995, 2162.49029495,
       1603.70590091, 1944.1838471 ,  206.74491582,  995.8526264 ,
       1798.98001711, 1131.04239915,  640.35359435,  573.25941083,
       1153.07332508,  326.91360271, 1125.0339648 ,  502.15960442,
       2202.54652392,  412.03308925, 1614.72136388, 2107.41298013,
        907.72892268,  434.06401518, 1186.11971397,  734.48573241,
       1121.02834191, 1230.18156583, 1560.64545478, 2031.3061451 ,
       1821.01094304, 1615.7227696 , 2025.29771075, 1957.20212152,
       1955.19931007,  147.6619781 ,  216.75897306,  149.66478954,
       1476.52737396, 2159.48607778, 1758.92378815,  500.15679297,
       1812.99969725, 1026.89620384, 1258.22092611, 1053.93415839,
        892.70783682, 1889.10653228,  508.16803877, 1019.88636377,
       2175.50856937, 1858.06295483,  454.09212967, 1879.09247504,
        940.77531157,  278.84612795,  255.8137963 ,  297.87283671,
        683.41404048,  672.39857752, 2032.30755082, 1808.99407435,
       1909.13464676, 2132.44812323,  517.18069028, 2178.51278654,
        908.7303284 , 1317.30386383, 1928.16135552, 2223.57604412,
       2207.55355254, 1437.47255072, 1436.47114499, 1091.98757591,
       1776.94909118, 1256.21811466,  748.50541255,  198.73367002,
       1078.96930149, 1625.73682684, 1965.21336731, 2094.39470572,
       1891.10934373, 1803.98704573,  979.83013481,  953.79358598,
       1680.81414167,  171.69571547, 1394.41210458,  551.2284849 ,
        945.78234019, 2110.4171973 , 1283.25606921,  921.74860281,
       1162.08597659, 1088.98335874, 1565.6524834 , 1451.49223085,
       1429.46130492,  298.87424243, 1076.96649005, 1679.81273595,
        690.42388055, 1947.18806428, 1807.99266863, 1738.89567367,
       1923.1543269 , 1460.50488237, 1221.16891431,  917.74297992,
        933.7654715 ,  361.96280305, 1413.43881334, 1287.2616921 ,
       1127.03677625,  598.29455393, 1263.22795473, 1499.55970561,
        421.04574077, 1485.54002547,  234.78427609, 1875.08685214,
       1907.13183531, 2049.33144813, 2131.44671751, 1728.88161643,
        904.7247055 , 1506.56954568, 1219.16610287, 1626.73823257,
        774.54196137, 1946.18665855, 1200.13939411, 1534.60890595,
       1310.29402376,  649.36624586, 2151.47483199, 1192.12814832,
       1270.23779479,  310.89111112,  140.65213803,  243.79692761,
        436.06682663,  961.80483178, 1802.98564001, 1158.0803537 ,
        889.70361964, 1575.66654064,  492.14554718, 2228.58307274,
        913.73735702, 1733.88864505,  711.45340076,  827.61646475,
       1145.06207928, 1514.58079147, 1293.27012645, 1052.93275267,
       1014.87933515,  589.28190242, 1838.03484035, 1629.74244974,
       1863.06998345,  289.86159092, 1056.93837556, 1702.8450676 ,
        340.93328284,  567.25097649, 1767.93643966,  957.79920888,
       2154.47904916, 2199.54230674,  484.13430139, 2218.5690155 ,
       1225.17453721, 1065.95102708,  645.36062297, 1075.96508432,
        530.1989647 , 1670.80008443, 1359.36290424, 1457.5006652 ,
       1491.54845982, 2244.60556433,  386.99794615, 2157.48326633,
        459.09915829, 1146.06348501, 1427.45849348, 1108.01006749,
        407.02606063, 1954.19790434, 1988.24569896, 1900.12199524,
       2108.41438585, 1683.81835884, 1409.43319044, 1031.90323246,
        151.66760099, 1278.24904059, 1339.33478976,  591.28471387,
       2134.45093468, 1641.75931843, 1521.59063154, 1553.63561471,
       1247.20546314, 1901.12340097, 1693.83241608, 1379.39101872,
        522.1877189 ,  974.82310619,  662.38452028, 2109.41579158,
       1120.02693618,  534.20458759, 1261.22514328, 1783.95893125,
       1455.49785375, 1951.19368717, 1033.90604391, 1559.64404906,
       1542.62015175,  886.69940247,  800.5785102 , 1077.96789577,
       2122.43406599,  554.23270207, 1835.03062318,  512.17366166,
       1007.86949508, 2050.33285386, 1376.38680155,  545.22005056,
       2022.29349358,  585.27627952, 1290.26590928, 1280.25185204,
        358.95858588,  813.59678461, 1364.36993286,  766.53071558,
        209.74913299, 1510.57516857,  365.96842595,  274.84050506,
        335.92625422,  564.24675932,  519.18350173,  366.96983167,
       2209.55636399,  306.88548823,  756.51665834, 1210.15345135,
        837.63052199,  430.05839229,  313.89532829,  654.37327448,
       1426.45708775, 1024.89339239, 1692.83101036,  251.8081734 ,
        382.99232326,  452.08931822, 1218.16469714, 1551.63280326,
       1474.52456251,  605.304394  , 1547.62718037,  832.62349337,
       1435.46973927,  601.29877111, 1585.68059788, 2001.26397338,
        834.62630482, 1691.82960463, 1399.4191332 ,  883.6951853 ,
       1757.92238242, 1723.8745878 ,  355.95436871, 1000.85965502,
        652.37046304, 1268.23498335,  466.10899836, 2195.53668385,
       1185.11830825, 2045.32582524,  932.76406578,  174.69993265,
        588.28049669,  847.64457923, 1099.9988217 ,  302.87986533,
        786.55883006, 1071.95946143, 1199.13798838, 1706.8506905 ,
        207.74632154,  432.06120374,  571.25659938,  761.52368696,
        863.66707082, 1411.43600189,  624.33110276,  823.61084185,
        152.66900672, 1567.65529485,  964.80904895, 1085.97914156,
       1652.77478139,  312.89392257, 1360.36430996,  916.74157419,
       2247.6097815 , 1753.91675953,  869.67550516,  874.68253378,
       1722.87318208,  746.5026011 ,  926.75563143,  899.71767688,
        681.41122903, 1301.28137224,  981.83294626,  166.68868685,
       1389.40507596,  660.38170883, 1484.53861975,  232.78146464,
       1482.5358083 , 2061.34831682,  651.36905731,  925.75422571,
       1041.9172897 ,  431.05979801, 1254.21530321,  871.67831661,
        778.54758427, 1134.04661632,  338.9304714 ,  414.0359007 ,
       1386.40085879, 1312.29683521, 1296.27434362, 1464.51050527,
        439.07104381,  369.97404884, 1597.69746657,  548.22426773,
       1876.08825787,  987.8413806 ,  888.70221392, 1129.0395877 ,
       1180.11127963, 2180.51559799, 1372.38117865, 1454.49644803,
       2065.35393972, 1650.77196995, 1001.86106074,  713.4562122 ,
        333.92344278,  301.87845961, 2043.32301379, 2235.59291281,
        568.25238221,  947.78515164,  192.72523568, 1045.9229126 ,
       1983.23867034,  811.59397316, 2183.51981516, 1860.06576628,
       1183.1154968 , 2085.3820542 , 1831.02500028,  269.83347643,
       1176.10565673, 1532.6060945 , 1497.55689416, 1755.91957098,
       1327.31792107,  287.85877947, 2188.52684378,  254.81239057,
        806.58694454,  518.18209601, 1872.08263497,  795.57148158,
        868.67409944,  594.28893104, 1401.42194465,  359.9599916 ,
        190.72242423, 1425.45568203, 1351.35165845, 1658.78321574,
        364.96702022,  253.81098485, 1663.79024436, 2192.53246668,
        688.4210691 ,  258.81801347, 1003.86387219, 1827.01937739,
       2095.39611144, 2139.4579633 ,  821.60803041, 1853.05592621,
       1182.11409108, 1818.00672587, 1677.8099245 ])}

At Step: Modelling regression 
Sequence executed:
Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'param': {'criterion': 'mse', 'max_depth': 7, 'max_features': 1, 'n_estimators': 11}}, 'score': 3.867991294096821, 'residual': <Figure size 640x480 with 1 Axes>, 'pickle_file': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=7,
           max_features=1, max_leaf_nodes=None, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=11, n_jobs=None, oob_score=False,
           random_state=None, verbose=0, warm_start=False), 'y_pred': array([1392.73740359, 1257.49322495, 2146.96546509, 1383.06036663,
       1420.09886719,  887.29614679, 1197.18169549, 2232.5016135 ,
        448.90006786, 1247.00601326,  847.3689054 , 1045.89921608,
        884.8455349 ,  884.8455349 ,  617.03161278, 1389.6462719 ,
       1519.69059895, 1346.94893332, 1911.03228012,  846.52657908,
       1333.25059394,  664.67014983,  617.84728022, 2086.57093587,
       1523.19934021, 1630.96499111,  283.47253928, 1772.43714025,
        763.75320916, 1054.4798558 ,  546.46572118,  202.98496294,
       1693.57173772, 1461.01219875, 2193.27409708,  395.68142136,
        468.89549954, 1062.35897531, 1426.45777984, 1324.58586432,
        685.27007084, 1933.72023867,  763.49255091,  209.50756867,
        350.50796287, 1047.46782477, 1133.5456046 , 1899.03929836,
       1627.16280867,  764.73636425,  395.68142136,  958.9850947 ,
       1495.06166058, 1344.53775937, 2041.65325968,  239.16778089,
       1660.0841994 ,  626.43263375,  972.06431554, 1656.34177516,
       1114.79734139, 1058.0847509 , 2235.07004785, 1466.65566336,
        159.66386187,  440.50730005,  842.78343333, 1426.45777984,
       2043.20257784, 1009.74049842,  712.91500964, 2093.0587752 ,
        546.46572118, 1048.96602102,  148.88544439,  577.38509907,
       1214.97654739, 1089.72758208, 2132.60469276, 1864.32548582,
        972.31539779,  358.49301072, 1654.00121042, 1660.0841994 ,
        546.46572118, 2132.60469276, 1872.89320651,  833.7408532 ,
       2086.57093587, 1873.90215968, 1520.46038335, 1660.0841994 ,
        931.97330154, 1428.3251117 ,  288.85053321,  350.50796287,
        550.09992032, 2131.72247475, 1704.47969635,  617.03161278,
       1227.25756343, 1634.9952096 ,  151.47061196, 1633.74203427,
        589.82780954,  343.65818421, 1556.29409324, 1333.25059394,
       1257.59609576, 1158.12725915, 1776.55907349,  767.58724788,
       2146.96546509, 1746.47645406, 1931.35582862,  712.91500964,
       1220.6846197 , 1742.79463013,  455.08349177, 1261.14050115,
       1751.27022219, 1464.02570525, 1654.00121042,  412.11944444,
        584.78082909, 1136.96551802, 1812.77084986, 1017.71538885,
        884.36167361, 2193.44581778, 1979.08965804,  936.45815002,
        159.66386187,  988.75874219, 1214.97654739,  350.50796287,
        985.59856903,  903.61028362,  352.34299104,  671.21865133,
        887.29614679, 1444.71082451,  559.74865927, 1591.80798639,
        666.18089363,  763.71805596,  623.63634724,  617.03161278,
       1290.06319966,  209.50756867,  206.65014936, 1391.70571246,
       1058.62223288, 1522.51920688, 1654.00121042,  704.5576087 ,
       1562.72066881, 1965.44714737, 1744.24439664,  747.67676829,
       2189.68823849,  847.51359206, 2175.26134674, 1185.16027039,
       1276.13013398, 2051.87881389,  496.30562984,  395.62638889,
       2056.39743626, 1742.79463013,  413.40025253, 1087.25304518,
        764.76252336, 1567.76897799, 1932.97694663, 1444.71082451,
       1837.42103308, 1837.42103308, 1324.58586432, 1012.81291767,
        546.46572118,  159.66386187, 1446.57824875, 1186.981126  ,
       1821.57960068, 1002.0525268 , 1599.32878259, 1088.10636996,
        704.5576087 ,  317.33165616, 1605.38101631,  226.58801685,
       2122.82828283,  992.60442984,  748.45250593, 1753.96205308,
        568.1612637 , 2124.54917606, 1281.03164914,  903.61028362,
       1333.25059394, 2151.35495146, 1608.07798601, 1522.03800155,
       1815.1592337 ,  587.08941495, 2189.68823849, 1009.8432207 ,
       1635.82597883,  675.38251673, 1650.76311518, 1636.64405096,
       1697.83254377,  194.57206883, 1186.26381127, 1047.46782477,
        209.50756867, 2100.80011336, 1561.14447203,  283.79858516,
        815.1861289 ,  902.85154706,  413.40025253, 1259.27791395,
        617.03161278,  317.33165616,  930.86615868,  969.74613372,
       1572.53759038,  395.62638889, 1967.39866252, 1772.43714025,
       2121.87962963,  584.78082909, 1197.07492998,  209.50756867,
        631.26756198, 2184.42204766, 1350.63327675,  936.45815002,
       1283.09259955,  958.9850947 , 1979.08965804, 1290.06319966,
        955.56590278, 1004.69829063, 1112.55258615, 2195.06220896,
        842.78343333,  709.00898554,  305.29859504,  153.71175293,
       1324.58586432,  366.74503994,  846.52657908, 1346.25204508,
        550.45749607,  617.84728022, 1428.3251117 ,  395.68142136,
       1593.9570357 , 1935.52617135, 1601.39098761, 1185.16027039,
       2195.06220896,  675.38251673,  190.15367056, 1389.6462719 ,
        930.86615868, 1825.59430656, 1654.00121042, 2047.68827484,
        995.04201357, 1490.64499391, 1391.70571246,  712.91500964,
        209.50756867, 2075.30655634,  286.99045675, 1052.55693011,
       1876.50829455,  154.10048209,  395.68142136,  828.3425848 ,
       1754.12424317, 1376.39265314,  583.27876298,  290.30356508,
       1593.9570357 ,  835.71425471, 1261.14050115, 1054.4798558 ,
        317.33165616, 1567.76897799, 1873.90215968, 1701.74488143,
       1810.74963774, 1705.86058391, 1391.70571246,  209.50756867,
       1795.00657212, 1158.12725915,  496.30562984,  496.30562984,
       1223.92383539, 2176.98162646, 1202.15240932, 2115.02443553,
       1314.19020263, 2146.96546509,  931.97330154,  209.50756867,
       2232.88281841, 1062.35897531, 1992.99600202,  590.81770853,
        214.80807372, 1876.50829455, 1114.79734139, 1176.79598796,
       1979.08965804, 1331.17625448, 2005.07738884, 1446.57824875,
       1612.03919813,  288.85053321,  399.9854798 , 2086.57093587,
        850.41842921,  498.02112698, 1405.69907467,  190.15367056,
        287.18386655, 2243.67967651,  190.15367056, 2146.96546509,
       1873.90215968,  407.33156566,  988.75874219, 1772.43714025,
       1583.77276338,  606.82896066,  153.71175293, 1523.19934021,
        159.66386187, 1910.98726875,  617.84728022,  760.15119157,
        452.7957555 ,  455.79020237,  871.78862088,  770.59964457,
        709.00898554, 1684.06061752, 1185.16027039,  287.18386655,
       1561.14447203, 2229.23715069,  159.66386187,  617.84728022,
       1589.39322452, 1935.52617135, 1567.76897799, 1049.12662708,
       2193.44581778, 1524.54304756,  474.35405138, 1654.00121042,
        350.50796287, 2049.79548056,  395.62638889,  709.46366931,
        586.07780954,  209.50756867, 1436.99139445, 1728.14189229,
       2082.25654193, 1992.99600202,  842.78343333, 1158.12725915,
       1910.26991513, 2146.96546509, 2239.43435372,  546.46572118,
       1282.81926596, 1043.61974003, 1112.55258615, 1391.70571246,
       1833.74193089, 2231.23746377,  159.66386187, 1392.73740359,
       2124.54917606,  440.50730005,  194.57206883, 1938.89069322,
        793.21440087, 1837.42103308,  548.27062739,  548.27062739,
       1850.88471588, 1801.09315566,  581.10467797,  287.18386655,
       1314.19020263,  317.33165616, 1717.33994424,  197.84184451,
       1593.9570357 , 2038.70261032,  564.28398022, 1109.37449179,
       2161.38958244,  584.78082909, 1202.15240932, 1772.43714025,
       1193.97059114,  502.93704633, 2189.68823849, 1866.83674123,
       2193.44581778,  911.15718117,  559.74865927])}

At Step: Modelling regression 
Sequence executed:
Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.base.LinearRegression'>, 'param': {'normalize': 'True'}}, 'score': 3.5651357822800733, 'residual': <Figure size 640x480 with 1 Axes>, 'pickle_file': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
         normalize='True'), 'y_pred': array([1382.20407438, 1240.11631375, 2148.67748738, 1404.2176711 ,
       1426.23126782,  885.8975302 , 1208.0965367 , 2249.73990867,
        459.6342483 , 1239.11569572,  857.88022528, 1075.01433836,
        887.89876626,  888.89938429,  646.7498204 , 1402.21643503,
       1507.28132846, 1346.18182521, 1914.53286774,  837.86786463,
       1332.17317275,  663.76032695,  614.73004335, 2100.64782181,
       1509.28256453, 1627.35549238,  267.51558603, 1770.44387104,
        761.82089415, 1057.00321378,  541.68492697,  216.48406637,
       1709.40617105, 1463.25413502, 2199.70900704,  386.58913191,
        471.64166469, 1067.0093941 , 1423.22941372, 1323.16761046,
        688.77577777, 1956.55882511,  778.83140071,  232.49395489,
        342.56193848, 1041.99394329, 1142.05574655, 1902.52545135,
       1623.35302025,  747.81224169,  382.58665978,  948.93646625,
       1494.27329404, 1355.1873875 , 2056.62062838,  246.50260735,
       1653.37156122,  619.73313352,  970.95006297, 1659.37526942,
       1117.04029573, 1055.00197771, 2243.73620048, 1476.26216945,
        166.45316473,  424.61261715,  835.86662857, 1422.22879569,
       2040.61073985, 1007.97293018,  730.80173514, 2083.63731526,
        538.68307287, 1030.98714493,  151.44389425,  590.71521057,
       1215.10086293, 1084.01990066, 2125.66327263, 1890.51803496,
        979.95562526,  354.56935487, 1671.38268581, 1654.37217926,
        536.68183681, 2122.66141853, 1883.51370873,  827.8616843 ,
       2098.64658575, 1882.5130907 , 1533.29739731, 1656.37341532,
        925.9222515 , 1417.22570552,  283.52547455,  351.56750077,
        533.67998271, 2106.65153001, 1705.40369892,  642.74734827,
       1212.09900883, 1639.36290877,  145.44018605, 1631.35796451,
        604.72386303,  335.55761225, 1552.30913993, 1330.17193669,
       1244.11878588, 1155.06378097, 1778.4488153 ,  776.83016464,
       2146.67625131, 1732.4203858 , 1948.55388085,  729.80111711,
       1235.11322359, 1751.43212842,  454.63115813, 1258.12743834,
       1745.42842023, 1469.25784322, 1672.38330384,  404.6002565 ,
        599.72077286, 1136.05203835, 1808.46735628, 1019.98034657,
        867.88640561, 2206.71333327, 1973.56933167,  920.91916134,
        169.45501883,  997.96674985, 1220.1039531 ,  347.56502864,
        999.96798592,  911.91359905,  355.5699729 ,  665.76156302,
        886.89814823, 1432.23497601,  563.69852369, 1590.33262517,
        654.75476466,  779.83201874,  632.74116794,  644.74858433,
       1273.13670883,  238.49766308,  215.48344833, 1398.2139629 ,
       1069.01063017, 1531.29616124, 1669.38144975,  721.79617285,
       1560.31408419, 1967.56562347, 1731.41976777,  744.8103876 ,
       2192.70468081,  841.87033676, 2174.69355623, 1201.09221048,
       1300.15339571, 2044.61321198,  504.66205976,  399.59716634,
       2065.62619067, 1752.43274646,  408.60272863, 1095.02669902,
        768.82522038, 1566.31779239, 1943.55079069, 1433.23559405,
       1829.48033497, 1828.47971694, 1322.16699242, 1012.97602034,
        543.68616304,  176.45934506, 1437.23806618, 1206.09530064,
       1821.47539071,  988.96118756, 1588.3313891 , 1079.01681049,
        722.79679088,  305.53907127, 1612.34622189,  244.50137128,
       2113.65585624,  991.96304166,  735.8048253 , 1737.42347597,
        547.68863517, 2129.66574476, 1293.14906948,  909.91236298,
       1338.17688095, 2137.67068902, 1608.34374976, 1497.27514813,
       1804.46488415,  603.72324499, 2193.70529885, 1017.9791105 ,
       1646.367235  ,  678.76959744, 1663.37774155, 1637.3616727 ,
       1697.39875466,  207.47850407, 1184.08170392, 1040.99332525,
        236.49642702, 2103.64967591, 1548.3066678 ,  279.52300242,
        794.84128923,  904.90927282,  410.6039647 , 1243.11816785,
        640.7461122 ,  306.5396893 ,  931.9259597 ,  978.95500723,
       1574.32273665,  397.59593027, 1963.56315134, 1761.43830875,
       2117.65832837,  600.7213909 , 1179.07861376,  224.48901063,
        627.73807778, 2185.70035458, 1349.1836793 ,  922.9203974 ,
       1289.14659735,  947.93584822, 1975.57056773, 1271.13547276,
        949.93708429, 1011.97540231, 1119.0415318 , 2203.71147917,
        833.8653925 ,  696.78072203,  292.53103685,  160.44945654,
       1320.16575636,  369.57862536,  839.8691007 , 1359.18985963,
        527.67627451,  618.73251548, 1415.22446946,  384.58789585,
       1579.32582681, 1933.54461036, 1622.35240221, 1202.09282851,
       2202.71086114,  679.77021547,  202.47541391, 1401.215817  ,
        932.92657773, 1818.47353661, 1668.38083171, 2063.6249546 ,
       1004.97107608, 1487.26896781, 1397.21334487,  728.80049907,
        237.49704505, 2076.63298903,  271.51805816, 1028.98590886,
       1863.50134808,  144.43956802,  383.58727782,  825.86044824,
       1744.42780219, 1360.19047766,  593.71706467,  325.55143192,
       1578.32520878,  831.86415643, 1257.1268203 , 1060.00506787,
        301.53659914, 1565.31717435, 1876.5093825 , 1698.39937269,
       1810.46859235, 1699.39999073, 1390.20901864,  240.49889915,
       1790.4562317 , 1158.06563507,  512.66700403,  509.66514993,
       1228.10889736, 2170.6910841 , 1174.07552359, 2104.65029394,
       1316.16328423, 2151.67934148,  926.92286953,  226.49024669,
       2233.73002015, 1064.00754001, 1985.57674806,  610.72757122,
        242.50013521, 1865.50258414, 1110.03596951, 1169.07243343,
       1972.56871363, 1326.16946455, 2000.58601855, 1444.2423924 ,
       1614.34745795,  284.52609259,  392.59284011, 2096.64534968,
        850.87589905,  487.65155321, 1408.22014323,  201.47479588,
        285.52671062, 2226.72569392,  199.47355981, 2144.67501525,
       1881.51247266,  402.59902044,  995.96551379, 1759.43707268,
       1598.33756943,  611.72818926,  161.45007457, 1514.28565469,
        178.46058113, 1921.53719397,  612.72880729,  752.81533186,
        464.63733846,  435.61941551,  874.89073184,  769.82583841,
        699.78257613, 1682.38948417, 1205.09468261,  286.52732865,
       1550.30790386, 2251.74114474,  173.45749096,  616.73127942,
       1576.32397271, 1928.5415202 , 1567.31841042, 1025.98405477,
       2212.71704147, 1524.29183502,  482.64846305, 1670.38206778,
        344.56317454, 2049.61630215,  395.59469421,  725.79864498,
        609.72695319,  241.49951718, 1448.24486454, 1713.40864318,
       2094.64411362, 1990.57983822,  836.8672466 , 1157.06501704,
       1894.52050709, 2145.67563328, 2228.72692999,  539.68369091,
       1268.13361866, 1023.9828187 , 1127.04647606, 1392.21025471,
       1847.49145956, 2232.72940212,  171.4562549 , 1380.20283832,
       2130.66636279,  420.61014502,  208.47912211, 1958.56006118,
        810.85117775, 1826.47848087,  530.67812861,  528.67689255,
       1851.49393169, 1793.45808579,  580.70903024,  288.52856472,
       1318.16452029,  314.54463356, 1720.41296941,  210.48035817,
       1577.32459074, 2055.62001034,  560.69666959, 1099.02917115,
       2162.68613983,  596.71891877, 1173.07490556, 1760.43769072,
       1171.0736695 ,  500.65958763, 2195.70653491, 1856.49702185,
       2214.71827753,  914.91545314,  561.69728762])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'param': {'criterion': 'mse', 'max_depth': 1, 'max_features': 2, 'n_estimators': 15}}, 'score': 126.92682350646984, 'residual': <Figure size 640x480 with 1 Axes>, 'pickle_file': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=1,
           max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=None, oob_score=False,
           random_state=None, verbose=0, warm_start=False), 'y_pred': array([1.98527413, 2.25928624, 2.8486484 , 2.17475317, 2.17475317,
       2.17475317, 2.25928624, 2.20741394, 2.20741394, 2.70920225,
       2.72579815, 2.76411532, 2.20741394, 2.67654147, 2.8936469 ,
       2.17475317, 2.79677609, 2.20741394, 2.17475317, 2.76411532,
       2.17475317, 2.67654147, 2.17475317, 2.17475317, 2.20741394,
       2.17475317, 2.20741394, 2.76411532, 2.20741394, 2.72841378,
       2.80680422, 2.22662547, 2.20741394, 2.89209513, 2.64312286,
       2.20741394, 2.20741394, 2.20741394, 2.17475317, 2.20741394,
       2.67654147, 2.67654147, 2.81598762, 2.22662547, 2.17475317,
       2.20741394, 2.20741394, 2.79677609, 2.86098613, 2.0698072 ,
       2.20741394, 2.20741394, 2.0179349 , 2.79677609, 2.20741394,
       2.17475317, 2.22662547, 2.17475317, 2.22662547, 2.70920225,
       2.17475317, 2.17475317, 2.31932888, 2.17475317, 2.25928624,
       2.8936469 , 2.22662547, 2.65579465, 2.20741394, 2.20741394,
       2.17475317, 2.17475317, 2.17475317, 2.70920225, 2.17475317,
       2.59125056, 2.0179349 , 2.25928624, 2.20741394, 2.70920225,
       2.79677609, 2.25928624, 2.20741394, 2.10377522, 2.20741394,
       2.20741394, 2.59125056, 2.20741394, 2.17475317])}

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.base.LinearRegression'>, 'param': {'normalize': 'False'}}, 'score': 135.96990478901628, 'residual': <Figure size 640x480 with 1 Axes>, 'pickle_file': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
         normalize='False'), 'y_pred': array([ 2.14860712,  2.26468328,  2.80101512,  2.47305185,  2.1592201 ,
        2.69330231,  2.2424076 ,  2.6736803 ,  1.9625026 ,  2.00234728,
        2.54459341,  2.60876115,  1.8556088 ,  2.32898112,  3.11434021,
        2.53073403,  2.45521026,  2.21156636,  2.05675956,  2.67181457,
        2.49568762,  1.9030044 ,  2.07238288,  2.26707132,  2.55147356,
        2.49568762,  2.04103985,  2.71236752,  2.19279731,  2.352716  ,
       -1.78015342,  2.24838865,  2.15955076,  3.05155373,  0.44443047,
        2.48503657,  2.02676992,  1.65404101,  2.39012805,  2.07084672,
        2.130853  ,  2.63670121,  2.93079084,  2.06911596,  1.98253522,
        2.80136221,  2.13191136,  2.29359861,  3.17847015,  2.3179778 ,
        1.86864653,  2.00002019,  1.93424588,  2.37082914,  1.81381501,
        2.10427604,  2.66791305,  2.12546013,  2.65249729,  2.07343453,
        2.32473407,  2.08427478,  2.54179913,  2.45063555,  2.24495761,
        3.10224294,  2.6900354 ,  3.2644967 ,  2.14447346,  2.04405249,
        2.65360345,  1.81859192,  2.17068496,  2.69592682,  2.57823108,
       -3.44096651,  2.24901808,  2.2265778 ,  1.64352413,  2.39066628,
        2.68990907,  2.47088108,  2.27026348,  1.76912224,  1.80164   ,
        1.87930402,  0.31666218,  1.73399887,  2.39747412])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 16, 'max_features': 6, 'n_estimators': 11}}, 'score': 0.8541666666666666, 'conf_matrix': array([[84, 13],
       [ 8, 39]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=16, max_features=4, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=18, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1,
       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,
       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,
       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,
       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1])}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 0.22159554149622437, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.7777777777777778, 'conf_matrix': array([[79, 19],
       [13, 33]], dtype=int64), 'pickle_file': LogisticRegression(C=0.5014180294448091, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,
       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,
       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1,
       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'param': {'criterion': 'mae', 'max_depth': 6, 'max_features': 2, 'n_estimators': 9}}, 'score': 985.8138538418667, 'residual': <Figure size 640x480 with 1 Axes>, 'pickle_file': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=6,
           max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=9, n_jobs=None, oob_score=False, random_state=None,
           verbose=0, warm_start=False), 'y_pred': array([ 972.15393282, 1185.19956203,  209.5742215 , 1716.98111659,
       1316.13368758, 2199.23748647, 1450.01152982,  665.91984758,
        571.4469375 ,  206.47189307,  504.91550859,  345.30412841,
       1710.68587849, 1603.15643144,  804.26535891, 1930.96510065,
        376.70055741, 1066.10168284,  859.81407485,  851.09211626,
       1745.91254821, 1144.53248355,  415.92447272,  200.02461502,
       1518.17367988,  136.88099067, 1545.74519596, 1144.53248355,
        619.54960821, 1975.25446447, 1979.26140891, 1745.91254821,
       1936.42648594,  502.08773081, 1320.28152007, 1275.97653377,
       1772.89632991, 1879.06593762,  280.59439967, 2132.40832694,
        958.13705814, 1710.68587849,  914.44970679, 1710.68587849,
        863.4982285 ,  575.20619675, 1144.53248355,  452.34807943,
       1810.00694462,  348.19153086, 1225.92600875,  689.64652906,
        646.66322306,  948.48650237, 1111.59360998, 2132.40832694,
        452.34807943, 2164.13901334,  810.30492289,  766.25716311,
        310.36492495, 2203.00843433,  984.35801433,  685.37734047,
       1185.19956203, 2123.3274734 ,  662.24704816, 1589.36259808,
        910.57391732, 1934.60045419, 2183.42358937, 1111.41522566,
       1518.17367988,  411.26168202,  696.86270944, 2008.77155549,
        429.52326323, 1363.43159689, 1804.42798987, 1697.26053018,
        795.82433153, 2049.91026258, 1982.96362649, 1745.91254821,
        504.91550859, 1605.77439681,  815.35647215, 2224.77959163,
        938.38889234, 1804.42798987, 2224.77959163,  376.70055741,
        859.81407485,  863.4982285 ,  452.34807943, 2132.40832694,
        200.02461502, 1185.19956203, 1066.10168284,  161.4996227 ,
       1252.34076673,  429.52326323,  779.95670293,  924.83869928,
       1007.47964009, 1975.25446447, 1763.66808201,  209.5742215 ,
        763.63174223,  452.34807943,  348.19153086, 1036.95065981,
       1509.10629355, 1066.10168284,  543.41535595, 2046.88164305,
       1520.70085379, 1518.17367988,  665.91984758,  310.36492495,
        976.62123441, 1390.26345198,  950.74508823, 1869.99931505,
        964.02330153,  411.26168202, 1930.96510065, 1275.97653377,
       1144.53248355, 1197.89185185, 1869.99931505, 2046.88164305,
       1381.78567768,  766.25716311, 1697.26053018,  348.19153086,
        157.51956572, 1781.51388322,  543.41535595,  571.4469375 ,
       1723.31976624,  938.38889234, 1007.47964009,  176.33979344,
       1007.47964009, 2012.42561927, 2107.7402825 , 1453.46708537,
        206.47189307, 2094.09172352, 1564.1894614 ,  795.82433153,
       2224.77959163, 2136.19450647,  234.7067511 , 1585.51974829,
       1394.7030655 ,  938.38889234, 1643.22285599,  452.34807943,
        543.41535595, 1643.22285599, 1875.79393185, 1536.47526435,
       2147.34311537, 1684.56550632, 1052.74047683, 2221.47212481,
        757.52640819, 1772.89632991, 1252.34076673, 2199.23748647,
       1956.18823089, 1349.04187207,  282.18725682, 1869.99931505,
       1185.19956203, 2227.60747834, 2005.13298588,  946.8808907 ,
        200.02461502,  411.26168202,  313.64708869,  622.77663812,
       1450.01152982, 1716.98111659,  948.48650237,  924.83869928,
        619.54960821, 2199.23748647,  348.19153086, 1803.52226667,
        282.18725682, 2043.2892729 , 1643.22285599,  571.4469375 ,
        421.0506376 , 1869.99931505, 1403.48648301, 1975.25446447,
       2176.8661022 ,  563.53938556, 2246.23424221,  415.92447272,
       1647.2231218 , 1697.26053018, 1660.82417482, 1453.46708537,
        856.5079088 ,  429.52326323, 1185.19956203,  678.96903531,
       1807.01661421, 1975.25446447,  161.4996227 ,  504.91550859,
       1223.71109647, 1908.62859941,  313.64708869,  563.53938556,
       1869.99931505, 1520.70085379, 1275.97653377, 1341.71504281,
       2136.19450647,  980.06716034, 1384.96206657, 1316.13368758,
        728.88886299, 1078.69554901,  817.99839559, 2180.69062952,
       1410.45817292, 1928.27491306,  856.5079088 ,  296.82143526,
        886.59799177,  563.53938556, 1036.95065981, 1364.20812153,
       2132.40832694, 2136.19450647, 1403.48648301,  754.61699878,
       1975.25446447, 1520.70085379, 1324.31428955,  845.88469405,
       2005.13298588, 1441.3101475 ,  313.64708869, 2046.88164305,
       1066.10168284,  452.34807943, 1073.35831378, 1108.30326116,
       1807.01661421,  585.77435436, 2224.77959163, 1007.47964009,
       1565.31067352,  421.0506376 , 2134.24642218, 1936.42648594,
       1223.71109647,  704.63751426, 1450.01152982, 2224.77959163,
        170.41164529,  376.70055741, 1845.75677802,  984.35801433,
        946.8808907 ,  795.82433153, 1792.86162498,  231.25455472,
       1351.08118332,  502.08773081,  766.25716311,  779.95670293,
       1111.59360998,  938.38889234,  543.41535595, 1589.36259808,
       1078.69554901,  209.5742215 , 1394.7030655 , 1647.2231218 ,
       1803.52226667,  429.52326323,  455.48360132, 1225.92600875,
       1697.26053018,  678.96903531, 1848.68534944,  856.5079088 ,
       2043.2892729 , 2176.8661022 , 1845.75677802, 1636.67800237,
       2168.64377524,  940.48167012,  161.4996227 ,  575.20619675,
        435.51853901,  914.44970679, 2134.24642218,  710.62384583,
       1460.51992652,  310.36492495,  499.23372565, 2046.88164305,
        704.63751426,  154.11744932, 2246.23424221, 1520.70085379,
        345.30412841, 2129.63795657,  543.41535595, 1807.01661421,
       1043.86999532,  563.53938556,  646.66322306, 2077.52850635,
       1328.48641257, 1643.22285599, 1643.22285599, 2176.8661022 ,
       1565.31067352, 1066.10168284, 2183.42358937,  757.52640819,
        136.88099067,  795.82433153,  609.0463926 , 1807.01661421,
       1349.04187207, 1807.01661421,  726.13076114, 1716.98111659,
        502.08773081, 1225.92600875, 1875.79393185,  499.23372565,
       1124.80164922, 1524.30322005, 1988.71239975,  581.93573002,
       1981.48955242, 1869.99931505,  341.45556806, 1144.53248355,
       1869.99931505, 1394.7030655 , 1975.25446447, 1803.52226667,
       1697.26053018, 1390.26345198,  348.19153086,  452.34807943,
        191.7776861 , 1807.01661421,  296.82143526, 2060.69759629,
        502.08773081, 1807.01661421, 2199.23748647, 1755.47788578,
        485.51011793, 1745.91254821,  886.59799177, 1875.79393185,
       1930.96510065, 1144.53248355, 1324.31428955,  950.74508823,
       2199.23748647,  282.18725682, 1623.149031  , 1966.24995166,
       1879.06593762, 2002.66328891, 1078.69554901,  665.91984758,
       1680.83402484, 1036.95065981,  530.06443529, 1520.70085379,
        856.5079088 ,  455.48360132, 1639.43698104, 2086.92334465,
       1966.24995166,  599.10802743, 1394.7030655 , 2176.8661022 ,
        835.26451505,  976.62123441, 1450.01152982, 1185.19956203,
       1745.91254821,  662.24704816,  280.59439967,  463.78403813,
       1975.25446447,  599.10802743,  662.24704816, 2002.66328891,
        914.44970679, 1599.58824962, 1716.98111659,  206.47189307,
       1185.19956203, 1845.75677802,  609.0463926 , 1515.43668076,
       2070.86502947,  859.81407485,  405.98596186, 1451.7980877 ,
       1643.22285599, 1956.18823089, 1491.69314672])}

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.base.LinearRegression'>, 'param': {'normalize': 'True'}}, 'score': 905.968244802149, 'residual': <Figure size 640x480 with 1 Axes>, 'pickle_file': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
         normalize='False'), 'y_pred': array([ 961.03624896, 1189.25457189,  224.33148721, 1716.75920428,
       1321.38096938, 2210.23127974, 1450.50449419,  670.75855751,
        578.67046229,  213.32095409,  506.60151821,  348.45022424,
       1699.74292582, 1605.65291548,  814.89644568, 1940.97369699,
        376.47703583, 1061.13200463,  859.93953573,  840.92134215,
       1733.77548274, 1149.21626962,  405.50480498,  198.30659074,
       1506.55811737,  141.25201   , 1547.59737719, 1151.21818473,
        623.71355234, 1978.00912658, 1982.01295681, 1744.78601587,
       1949.982315  ,  493.58906997, 1306.36660602, 1291.35224267,
       1767.80803967, 1881.91720114,  259.3650017 , 2123.14797231,
        953.0285885 , 1706.74962871,  908.98645601, 1700.74388337,
        877.95677175,  583.67525007, 1146.21339695,  454.55172526,
       1830.86836575,  363.4645876 , 1231.29478927,  695.78249643,
        646.73557615,  939.01518271, 1122.19041559, 2124.14892986,
        463.56034327, 2165.18818969,  816.89836079,  774.85814341,
        298.40234641, 2218.2389402 ,  985.05923032,  691.7786662 ,
       1190.25552945, 2104.12977873,  666.75472728, 1595.64333992,
        898.97688044, 1941.97465454, 2188.21021349, 1100.16934934,
       1521.57248072,  397.49714452,  708.79494466, 2016.04551374,
        424.52299856, 1361.41927164, 1826.86453552, 1694.73813803,
        793.87633698, 2061.08860379, 1989.01965971, 1741.7831432 ,
        509.60439088, 1621.66823639,  821.90314857, 2234.2542611 ,
        934.01039493, 1828.86645063, 2229.24947332,  380.48086606,
        857.93762061,  875.95485664,  446.5440648 , 2127.15180253,
        191.29988784, 1194.25935967, 1055.12625929,  166.27594892,
       1250.31298285,  423.522041  ,  785.86867653,  914.99220135,
       1005.07838145, 1967.99955102, 1754.79559144,  229.33627499,
        763.84761028,  455.55268281,  357.45884225, 1020.0927448 ,
       1493.54566913, 1050.1214715 ,  538.63216002, 2048.07615555,
       1532.58301384, 1522.57343828,  677.76526041,  295.39947374,
        978.05252742, 1385.44225301,  945.02092805, 1859.89613489,
        956.03146117,  401.50097475, 1915.94975807, 1289.35032756,
       1148.21531206, 1203.26797768, 1854.89134711, 2044.07232533,
       1374.43171988,  767.85144051, 1695.73909559,  356.4578847 ,
        158.26828847, 1777.81761524,  540.63407513,  568.66088672,
       1724.76686473,  930.0065647 , 1003.07646634,  182.29126983,
       1006.07933901, 2017.0464713 , 2102.12786362, 1456.51023953,
        209.31712386, 2099.12499095, 1555.60503765,  791.87442187,
       2233.25330355, 2145.16903856,  249.35542613, 1586.63472191,
       1401.45757391,  920.99794669, 1648.69409042,  434.53257412,
        543.6369478 , 1657.70270843, 1886.92198892, 1544.59450452,
       2163.18627458, 1680.72473224, 1044.11572616, 2225.24564309,
        748.83324693, 1760.80133678, 1252.31489796, 2198.21978906,
       1957.98997545, 1353.41161119,  268.37361971, 1862.89900756,
       1193.25840212, 2226.24660065, 2013.04264107,  948.02380072,
        196.30467562,  400.50001719,  323.42628533,  627.71738257,
       1446.50066397, 1714.75728917,  941.01709782,  912.99028623,
        626.71642501, 2206.22744952,  367.46841782, 1799.83868149,
        266.37170459, 2029.05796198, 1658.70366599,  576.66854718,
        410.50959276, 1872.90858313, 1407.46331925, 1973.0043388 ,
       2185.20734082,  558.65131116, 2248.2676669 ,  404.50384742,
       1671.71611423, 1691.73526536, 1674.7189869 , 1457.51119709,
        850.93091772,  425.52395611, 1171.23733587,  680.76813308,
       1807.84634194, 1972.00338124,  167.27690648,  504.59960309,
       1219.28329859, 1900.93539472,  305.40904931,  566.65897161,
       1858.89517733, 1538.58875918, 1265.3273462 , 1342.40107807,
       2148.17191123,  966.04103674, 1375.43267744, 1320.38001182,
        732.81792602, 1088.15785866,  823.90506369, 2187.20925594,
       1413.46906459, 1912.9468854 ,  848.9290026 ,  287.39181328,
        887.96634732,  549.64269314, 1028.10040526, 1371.42884721,
       2132.15659032, 2146.16999611, 1408.46427681,  741.82654404,
       1969.00050857, 1531.58205629, 1338.39724784,  836.91751192,
       2011.04072596, 1433.48821573,  310.41383709, 2056.08381601,
       1064.1348773 ,  442.54023458, 1083.15307088, 1099.16839178,
       1805.84442683,  592.68386808, 2230.25043088, 1007.08029657,
       1556.6059952 ,  413.51246543, 2138.16233566, 1946.97944233,
       1216.28042592,  717.80356267, 1453.50736686, 2236.25617622,
        181.29031227,  382.48278117, 1838.8760262 ,  982.05635765,
        947.02284316,  796.87920965, 1790.83006348,  239.34585056,
       1358.41639897,  496.59194264,  777.86101608,  784.86771897,
       1124.1923307 ,  931.00752226,  535.62928735, 1598.64621259,
       1087.1569011 ,  225.33244477, 1392.4489559 , 1667.712284  ,
       1793.83293615,  420.51916833,  467.56417349, 1230.29383171,
       1693.73718048,  682.77004819, 1844.88177154,  852.93283283,
       2023.05221664, 2178.20063793, 1840.87794131, 1629.67589685,
       2169.19201992,  937.0132676 ,  160.27020358,  584.67620763,
        430.5287439 ,  902.98071067, 2136.16042055,  725.81122313,
       1472.52556044,  301.40521908,  490.5861973 , 2052.07998578,
        713.79973245,  153.26350068, 2247.26670934, 1530.58109873,
        344.44639402, 2111.13648163,  537.63120246, 1822.86070529,
       1041.11285349,  552.64556582,  647.7365337 , 2080.10679737,
       1339.3982054 , 1663.70845377, 1649.69504798, 2183.20542571,
       1564.61365566, 1065.13583486, 2189.21117105,  752.83707716,
        144.25488267,  795.8782521 ,  610.7011041 , 1812.85112972,
       1352.41065363, 1823.86166285,  730.81601091, 1717.76016184,
        492.58811241, 1222.28617126, 1885.92103137,  489.58523974,
       1132.19999116, 1541.59163185, 1997.02732016,  589.68099541,
       1986.01678704, 1852.88943199,  336.43873356, 1152.21914229,
       1869.90571046, 1397.45374369, 1964.99667835, 1791.83102103,
       1696.74005315, 1381.43842278,  362.46363004,  445.54310725,
        183.29222739, 1811.85017217,  288.39277084, 2068.09530669,
        495.59098508, 1819.85783262, 2201.22266173, 1752.79367632,
        477.57374906, 1748.78984609,  884.96347465, 1889.92486159,
       1918.95263074, 1138.2057365 , 1334.39341761,  944.01997049,
       2217.23798264,  274.37936505, 1624.67110906, 1960.99284812,
       1884.92007381, 2006.03593817, 1084.15402843,  675.76334529,
       1679.72377468, 1029.10136281,  524.61875423, 1533.5839714 ,
        853.93379039,  466.56321594, 1633.67972707, 2084.1106276 ,
       1963.99572079,  600.69152854, 1390.44704079, 2186.20829838,
        828.90985147,  977.05156986, 1448.50257908, 1198.2631899 ,
       1737.77931297,  665.75376972,  265.37074704,  468.56513105,
       1980.0110417 ,  602.69344365,  667.75568484, 1999.02923527,
        900.97879555, 1601.64908526, 1712.75537405,  215.3228692 ,
       1172.23829342, 1835.87315353,  614.70493433, 1496.5485418 ,
       2076.10296714,  863.94336595,  391.49139918, 1464.51789999,
       1654.69983576, 1956.98901789, 1489.5418389 ])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 10, 'max_features': 2, 'n_estimators': 12}}, 'score': 0.8714285714285714, 'conf_matrix': array([[87, 13],
       [ 5, 35]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=10, max_features=2, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=12, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,
       0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,
       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,
       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,
       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0])}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 1.2329639290190333, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.7785714285714286, 'conf_matrix': array([[76, 15],
       [16, 33]], dtype=int64), 'pickle_file': LogisticRegression(C=1.4414815887773176, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,
       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,
       1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,
       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1,
       1, 0, 0, 0, 0, 0, 1, 1])}

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 17, 'max_features': 519, 'n_estimators': 8}}, 'score': 0.9348837209302325, 'conf_matrix': array([[84,  7,  1,  0],
       [ 3, 34,  2,  0],
       [ 1,  0, 76,  0],
       [ 0,  0,  0,  7]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=19, max_features=648, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=18, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([2, 2, 0, 2, 1, 2, 2, 0, 0, 0, 0, 2, 3, 0, 2, 0, 2, 2, 1, 1, 0, 0,
       2, 0, 1, 2, 1, 2, 0, 0, 2, 1, 3, 1, 3, 2, 0, 2, 1, 0, 2, 0, 1, 0,
       2, 2, 1, 2, 1, 1, 2, 0, 3, 0, 0, 0, 2, 0, 2, 0, 1, 0, 2, 0, 2, 0,
       2, 2, 0, 0, 1, 0, 2, 1, 2, 0, 1, 0, 2, 0, 3, 2, 2, 1, 0, 0, 2, 1,
       1, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 2, 0, 0, 1,
       0, 2, 0, 1, 2, 0, 0, 0, 1, 0, 2, 0, 1, 1, 2, 0, 2, 3, 0, 2, 2, 2,
       3, 0, 0, 0, 2, 2, 0, 0, 0, 2, 2, 0, 0, 2, 0, 1, 2, 1, 0, 1, 0, 1,
       0, 1, 1, 2, 0, 0, 0, 2, 1, 2, 2, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 2,
       0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 1, 0, 2, 2, 0, 2, 0, 2, 0,
       0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 0, 2, 1])}

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 4.862135629891862, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.9627906976744186, 'conf_matrix': array([[86,  6,  0,  0],
       [ 1, 35,  0,  0],
       [ 1,  0, 79,  0],
       [ 0,  0,  0,  7]], dtype=int64), 'pickle_file': LogisticRegression(C=4.9270374169771864, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='newton-cg', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 1, 2, 3, 0, 0, 0, 2, 2, 1, 1, 0, 0,
       2, 0, 1, 2, 1, 2, 0, 0, 2, 1, 3, 1, 3, 2, 0, 2, 1, 0, 2, 0, 1, 0,
       2, 2, 1, 2, 1, 1, 2, 0, 3, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0,
       2, 2, 0, 0, 1, 0, 2, 1, 2, 0, 1, 0, 2, 0, 3, 2, 2, 1, 0, 0, 2, 1,
       1, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 2, 0, 0, 1,
       0, 2, 0, 1, 2, 0, 0, 0, 1, 0, 2, 0, 1, 1, 2, 0, 2, 3, 0, 2, 2, 2,
       3, 0, 0, 0, 2, 2, 0, 0, 0, 2, 2, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2,
       0, 0, 1, 2, 0, 0, 1, 2, 1, 2, 2, 0, 0, 0, 2, 1, 0, 0, 1, 0, 1, 2,
       0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 0, 2, 2, 0, 2, 0, 2, 0,
       0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 0, 2, 1])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 10, 'max_features': 4, 'n_estimators': 19}}, 'score': 0.8611111111111112, 'conf_matrix': array([[86,  7],
       [13, 38]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=10, max_features=4, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=19, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,
       1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,
       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,
       1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 0.09691542939947027, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.8125, 'conf_matrix': array([[85, 13],
       [14, 32]], dtype=int64), 'pickle_file': LogisticRegression(C=0.16293102481263544, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,
       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,
       1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,
       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0])}

