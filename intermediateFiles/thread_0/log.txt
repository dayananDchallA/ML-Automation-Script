At Step: colIdentification 
Sequence executed:


At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Feature Reduction 
Sequence executed:
Null Handling with mean,  Feature Reduction with pearson,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Feature Reduction with pearson,  Outlier Handling with capping,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Feature Reduction with pearson,  Outlier Handling with capping,  Encoding with one-hot,

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Feature Reduction with pearson,  Outlier Handling with capping,  Encoding with one-hot,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestRegressor'>, 'param': {'criterion': 'mse', 'max_depth': 6, 'max_features': 1, 'n_estimators': 14}}, 'score': 974.115296733125, 'residual': <module 'matplotlib.pyplot' from 'C:\\Users\\SindhuKarnati\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py'>, 'pickle_file': RandomForestRegressor(max_depth=6, max_features=1, n_estimators=14), 'y_pred': array([ 279.78812178,  279.78812178, 2139.22987191, 1448.66564621,
        977.17869777, 1697.07479202, 1661.61176378, 1171.05808314,
        556.23330277,  299.26827653, 1906.6188031 ,  427.92471692,
        949.50290729,  452.4299437 , 1059.33653905,  778.4689399 ,
       1765.02987377,  551.75844375,  661.17693564, 1015.04349488,
       1852.99208405, 1208.30114325,  760.88746323,  681.66508619,
        964.56233783, 1425.82728988,  709.97316067,  985.19461893,
        626.82647727, 1375.40953695, 1824.30637238,  620.38842556,
        662.74437131, 1197.0074052 ,  381.03343772,  507.78722226,
        560.92782197,  165.5238859 , 1931.67696322, 2139.22987191,
        560.92782197, 1068.72556888,  164.67882034, 1754.7547698 ,
        367.20329616, 1227.35808488,  759.72079657,  400.91648703,
       1428.33869445,  870.73390919, 1902.41130838, 2098.43535103,
       1938.24018873,  681.66508619,  949.50290729, 1914.29971755,
       1279.51172332, 1009.10467352, 2084.66834434,  341.28361715,
       1870.22752367, 1784.19253322,  623.56520568,  895.8397594 ,
       1567.80374019, 2104.5006616 , 1177.90261361,  599.82433106,
       1571.33862391, 1278.51883525, 1754.7547698 , 1299.97117019,
       1211.77068799, 1030.62125663,  623.56520568, 2038.95902244,
       1643.49536287,  584.79161074, 1879.87251267, 1971.45193684,
        919.01630856,  964.56233783, 1197.0074052 ,  678.52081927,
        164.67882034, 1201.55702767,  236.49865973, 1466.95868902,
        352.93663149,  511.29930482,  760.88746323, 1852.99208405,
        987.31883662, 1230.00075649, 1644.90679144,  282.88330595,
       1848.92373671, 1691.68723533,  511.29930482, 2183.4096369 ,
       1518.56525178,  701.09805344, 1201.55702767, 1883.97045493,
        215.87209745, 1115.84456895, 1469.47150953,  703.09820133,
        599.82433106, 1313.01567696, 2040.49711768,  410.11045423,
        400.91648703, 1611.2242772 , 1807.73234792,  507.03007287,
       1012.09827471,  408.08605121,  236.49865973, 1754.7547698 ,
        478.34794282, 1520.64652376, 1068.72556888,  989.55976632,
        949.50290729, 2216.36180825, 1971.45193684, 1059.33653905,
        897.42633948, 1968.41006184, 1324.19761745,  278.04475443,
       1161.79136053,  166.66971924, 1914.29971755, 1657.70411967,
        478.34794282,  452.4299437 ,  705.95044222, 1715.33096251,
        926.94387713,  945.56689538, 1115.84456895, 1520.02669659,
       1313.01567696, 1275.65375589,  312.65960984, 2038.95902244,
       1999.3482825 , 1449.92915161, 1197.0074052 ,  197.02962749,
        320.22330345,  236.49865973,  623.56520568,  212.92445506,
        570.40087446, 1757.19308782, 1859.4112968 , 1577.35926752,
       1586.29614065, 1516.85477559,  759.72079657,  303.69669915,
       1852.99208405, 1611.2242772 ,  891.89113291, 1208.30114325,
       1899.9341713 ,  623.56520568, 1765.02987377, 1920.81214652,
       1289.8372294 , 2217.9860669 , 1928.35571395, 2081.98896733,
       1227.35808488, 1999.3482825 , 2190.68652259, 1691.68723533,
        935.97077182, 2120.91457265, 2208.27431964, 2193.33832342,
       1715.33096251, 1073.36911284, 2131.81341754,  408.08605121,
        299.26827653, 1571.33862391, 1765.02987377, 1792.74489644,
        208.40870053,  357.94662072,  214.66138316, 1824.30637238,
        357.94662072,  212.92445506,  864.7340561 ,  584.79161074,
       1588.91509168, 1043.98682529,  874.16570268, 2084.66834434,
        166.66971924, 1754.7547698 ,  530.83139123, 1773.93924373,
        623.56520568,  949.50290729, 2026.70098445,  874.16570268,
        864.7340561 , 1161.79136053, 1886.03364863, 1774.83720292,
       1588.91509168, 2139.22987191, 1009.10467352, 1466.95868902,
        212.92445506, 1889.86606573, 1430.395471  , 1313.01567696,
        397.33919361,  338.90119957, 1983.16343616, 1774.83720292,
       1199.32513919,  847.21130819, 1951.3692394 , 1387.64227247,
        506.59549294,  478.34794282,  807.94793326,  513.66605152,
       1792.74489644,  236.49865973, 2217.9860669 ,  847.21130819,
        198.73244134, 1257.91409671, 1279.51172332,  427.92471692,
       1931.67696322,  584.79161074, 1207.04624597,  397.33919361,
        556.23330277,  452.4299437 ,  949.50290729, 1774.83720292,
       2217.9860669 ,  372.9531113 ,  506.4528996 , 1636.94736698,
        891.89113291, 1870.22752367,  705.95044222,  584.79161074,
        312.65960984, 1643.49536287, 1314.09059932, 1709.40337801,
        945.56689538, 1448.66564621,  400.91648703, 1774.83720292,
        408.08605121, 1203.03249664,  807.94793326,  352.93663149,
       1889.86606573, 1879.87251267, 1197.0074052 ,  845.12583604,
       1999.3482825 , 1266.02800309,  351.13113429, 1279.51172332,
       1981.04340815,  354.33799204,  844.97321295,  452.4299437 ,
       2081.98896733, 1257.91409671,  312.65960984,  236.49865973,
       2081.64372923, 1522.12753692,  584.79161074,  845.12583604,
        666.21167656,  556.23330277, 1466.95868902,  197.02962749,
       1577.35926752,  513.66605152, 2216.36180825, 2104.5006616 ,
        845.12583604, 1350.57768819, 1471.67961393, 1478.53353515,
       1607.2226308 , 1657.70411967,  989.55976632, 1807.73234792,
       1999.3482825 , 1316.45558531, 2051.18465433, 2083.14372923,
       1378.46645087,  889.8316091 ,  199.73424509, 2140.60994652,
       1266.02800309,  559.44482877,  579.67905122,  623.56520568,
       1940.2664613 , 1920.81214652, 1573.94973502, 1324.19761745,
       1699.98304325, 1971.45193684,  760.88746323, 1774.83720292,
       2099.85085057, 1324.19761745, 2120.91457265, 1657.70411967,
        301.40160987, 1278.51883525, 1938.24018873, 1115.84456895,
       1018.08894943, 1287.62764102,  681.66508619,  164.67882034,
       1043.98682529, 1338.4936593 ,  372.9531113 ,  506.59549294,
       1177.90261361, 1260.13714811,  937.26362897, 1059.33653905,
       1792.74489644, 1914.29971755, 1694.71943487,  560.92782197,
        559.44482877, 1644.90679144,  279.78812178, 1115.84456895,
       1514.41071046, 2042.51260219,  759.72079657,  312.65960984,
       2190.68652259,  491.0589258 , 1324.19761745, 1879.87251267,
        664.80884255, 1375.40953695,  897.42633948, 2188.67661942,
       1477.19911956,  844.97321295, 1313.01567696, 1754.7547698 ,
        164.67882034, 1852.99208405,  197.02962749,  534.96164333,
       1100.54683872,  897.42633948,  864.7340561 ,  989.55976632,
       1462.10486347, 1938.24018873, 1571.33862391, 1264.22264595,
        953.50869017, 1279.51172332, 2216.36180825,  312.65960984,
       1520.64652376, 1277.47518446,  579.67905122, 1553.63764005,
        709.97316067,  701.09805344,  534.96164333,  559.44482877,
       2049.67787778,  579.67905122, 1657.70411967,  402.40999352,
       1115.84456895, 2147.62405393, 1518.56525178,  974.52667621,
        559.01588256, 1197.0074052 ,  681.66508619, 1940.2664613 ,
       1944.93973136, 1577.35926752, 1338.4936593 ,  705.95044222,
       1522.12753692, 1483.08183447, 2178.49591261,  352.93663149,
       2217.9860669 , 2046.89960142,  427.92471692, 1059.33653905,
       2180.13911196,  709.97316067, 1754.7547698 ])}

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Feature Reduction with pearson,  Outlier Handling with capping,  Encoding with one-hot,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._base.LinearRegression'>, 'param': {'normalize': 'True'}}, 'score': 864.4519147529426, 'residual': <module 'matplotlib.pyplot' from 'C:\\Users\\SindhuKarnati\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py'>, 'pickle_file': LinearRegression(normalize='False'), 'y_pred': array([ 264.57350587,  266.57390381, 2141.94697012, 1453.81007965,
        985.7169623 , 1692.85763317, 1677.85464864, 1166.75297564,
        534.62722742,  295.5796739 , 1904.89981454,  420.60454499,
        937.7074118 ,  453.61111095, 1077.73526742,  785.67716856,
       1754.86996923,  530.62643154,  654.65110366, 1017.7233293 ,
       1836.88628467, 1212.7621282 ,  768.67378609,  679.65607788,
        957.71139118, 1410.801524  ,  722.66463353,  986.71716127,
        646.64951191, 1370.79356525, 1826.88429498,  610.64234904,
        656.6515016 , 1185.75675604,  384.59738211,  501.62066145,
        553.63100782,  164.553609  , 1934.9057836 , 2137.94617425,
        551.63060989, 1083.73646123,  160.66283501, 1751.86937233,
        373.59519346, 1225.76471479,  758.67179641,  394.5993718 ,
       1418.80311575,  869.69388193, 1900.89901866, 2088.93642478,
       1944.90777329,  677.65567994,  939.70780974, 1909.90080938,
       1279.7754591 , 1003.72054374, 2081.935032  ,  337.58803058,
       1857.89046301, 1777.87454551,  627.64573151,  900.70004996,
       1549.82918065, 2100.9388124 , 1171.75397048,  606.64155316,
       1552.82977756, 1270.77366838, 1732.86559192, 1302.78003538,
       1214.76252613, 1020.72392621,  611.64254801, 2029.92468563,
       1648.84887855,  585.63737482, 1869.89285063, 1969.9127475 ,
        914.70283552,  964.71278396, 1182.75615914,  674.65508304,
        160.66283501, 1199.7595416 ,  240.56873062, 1467.81286522,
        354.59141305,  497.61986558,  773.67478094, 1837.88648364,
        991.71815611, 1227.76511273, 1652.84967443,  282.5770873 ,
       1829.88489189, 1683.85584246,  496.61966661, 2188.95632165,
       1512.82181881,  691.6584655 , 1198.75934264, 1877.89444238,
        233.56733784, 1117.74322617, 1475.81445697,  698.65985828,
        601.64055832, 1304.78043332, 2036.92607841,  407.60195839,
        398.60016767, 1619.84310846, 1804.87991767,  519.62424289,
       1007.72133961,  402.60096355,  239.56853165, 1738.86678573,
        473.61509033, 1538.82699199, 1078.73546639,  996.71915096,
        944.70880459, 2222.96308659, 1977.91433925, 1072.73427258,
        911.70223862, 1962.91135472, 1326.78481063,  279.5764904 ,
       1158.75138389,  177.55619559, 1911.90120732, 1671.85345483,
        478.61608517,  466.61369755,  702.66065416, 1716.86240842,
        918.7036314 ,  935.70701387, 1101.74004267, 1515.82241571,
       1306.78083126, 1263.7722756 ,  314.5834543 , 2022.92329285,
       2001.9191145 , 1446.80868687, 1184.75655707,  198.56037393,
        326.58584193,  254.57151618,  616.64354285,  215.5637564 ,
        567.63379338, 1752.8695713 , 1848.88867229, 1568.83296106,
       1572.83375693, 1504.82022706,  765.67318919,  301.58086771,
       1833.88568776, 1617.84271052,  897.69945306, 1211.76192923,
       1894.89782485,  620.64433873, 1755.8701682 , 1917.90240113,
       1299.77943847, 2229.85445748, 1922.90339598, 2079.93463406,
       1223.76431685, 2011.92110419, 2196.9579134 , 1686.85643936,
        921.70422831, 2108.94040415, 2216.96189277, 2202.95910721,
       1710.86121461, 1084.7366602 , 2129.9445825 ,  401.60076458,
        299.58046977, 1555.83037446, 1753.86977026, 1785.87613726,
        207.56216465,  363.59320377,  218.56435331, 1822.88349911,
        361.59280583,  214.56355743,  859.69189225,  590.63836966,
       1590.83733837, 1040.72790558,  877.69547368, 2083.93542994,
        178.55639456, 1748.86877542,  525.6254367 , 1766.87235686,
        628.64593048,  950.7099984 , 2021.92309388,  875.69507574,
        861.69229018, 1155.75078698, 1887.89643207, 1771.8733517 ,
       1587.83674146, 2136.94597528, 1006.72114064, 1463.81206934,
        213.56335846, 1892.89742691, 1426.8047075 , 1310.78162713,
        389.59837696,  335.58763265, 1993.91752275, 1773.87374964,
       1197.75914367,  836.68731597, 1961.91115575, 1403.80013122,
        507.62185526,  480.61648311,  809.68194381,  491.61867176,
       1779.87494345,  236.56793474, 2229.85445748,  838.6877139 ,
        201.56097084, 1242.76809726, 1285.77665291,  421.60474395,
       1931.90518669,  584.63717585, 1204.76053645,  388.59817799,
        535.62742639,  446.60971817,  938.70761077, 1775.87414758,
       2229.85445748,  376.59579036,  487.61787589, 1627.84470021,
        895.69905512, 1858.89066198,  708.66184797,  580.63637998,
        311.5828574 , 1637.8466899 , 1318.78321888, 1700.85922492,
        933.70661593, 1452.80988069,  397.59996871, 1769.87295376,
        400.60056561, 1201.75993954,  810.68214278,  347.59002027,
       1891.89722795, 1871.89324857, 1186.75695501,  833.68671906,
       2013.92150213, 1259.77147973,  342.58902543, 1275.77466323,
       1981.91513513,  357.59200996,  847.68950462,  451.61071302,
       2077.93423612, 1243.76829623,  308.58226049,  247.5701234 ,
       2068.93244541, 1518.82301262,  582.63677792,  834.68691803,
        669.65408819,  536.62762536, 1465.81246728,  196.559976  ,
       1567.83276209,  493.6190697 , 2223.96328555, 2093.93741962,
        830.68612215, 1357.79097866, 1477.8148549 , 1482.81584975,
       1612.84171568, 1675.85425071,  993.71855405, 1805.88011664,
       2010.92090522, 1325.78461166, 2048.92846603, 2071.93304231,
       1378.795157  ,  887.69746337,  204.56156775, 2144.94756703,
       1257.77108179,  559.63220164,  573.6349872 ,  614.64314491,
       1958.91055885, 1915.90200319, 1556.83057343, 1329.78540754,
       1695.85823008, 1970.91294647,  770.67418403, 1767.87255583,
       2092.93722065, 1334.78640238, 2107.94020519, 1672.8536538 ,
        292.57907699, 1269.77346941, 1941.90717638, 1113.7424303 ,
       1015.72293136, 1296.77884157,  689.65806757,  160.66283501,
       1037.72730867, 1345.78859103,  375.59559139,  506.62165629,
       1169.75357254, 1245.76869416,  927.70542212, 1069.73367567,
       1782.87554036, 1910.90100835, 1687.85663833,  554.63120679,
        564.63319648, 1656.8504703 ,  275.57569452, 1111.74203236,
       1495.81843634, 2039.92667531,  759.67199538,  310.58265843,
       2199.95851031,  486.61767692, 1333.78620341, 1873.89364651,
        664.65309335, 1366.79276938,  912.70243759, 2191.95691856,
       1480.81545181,  853.69069843, 1307.78103022, 1744.86797955,
        160.66283501, 1841.88727951,  200.56077187,  527.62583464,
       1092.73825195,  904.70084584,  858.69169328,  995.71895199,
       1459.81127347, 1945.90797226, 1554.83017549, 1254.77048488,
        951.71019737, 1284.77645394, 2225.96368349,  318.58425018,
       1536.82659406, 1264.77247457,  579.63618101, 1544.82818581,
        721.66443456,  696.65946035,  526.62563567,  563.63299751,
       2052.92926191,  575.63538513, 1674.85405174,  399.60036664,
       1110.74183339, 2157.95015362, 1514.82221675,  983.71656436,
        545.62941607, 1181.75596017,  680.65627685, 1955.90996194,
       1959.91075782, 1565.83236415, 1344.78839207,  711.66244488,
       1528.82500231, 1487.81684459, 2170.95274021,  351.59081615,
       2229.85445748, 2043.92747119,  425.60553983, 1066.73307877,
       2176.95393403,  717.66363869, 1750.86917336])}

At Step: Outlier Handling 
Sequence executed:
  Outlier Handling with removing,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with one-hot,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with one-hot,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 15, 'max_features': 4, 'n_estimators': 7}}, 'score': 0.8142857142857143, 'conf_matrix': array([[93, 22],
       [ 4, 21]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=15, max_features=4,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=7,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,
       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with one-hot,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.667056343401222, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.8357142857142857, 'conf_matrix': array([[88, 14],
       [ 9, 29]], dtype=int64), 'pickle_file': LogisticRegression(C=0.5845645325229636, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,
       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,
       0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0], dtype=int64)}

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 18, 'max_features': 4, 'n_estimators': 6}}, 'score': 0.8228855721393035, 'conf_matrix': array([[ 78,  19,   5],
       [ 50, 247,  11],
       [ 45,  48, 502]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=18, max_features=4,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=6,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([2, 0, 2, ..., 0, 1, 2])}

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.12139771911352203, 'penalty': 'l2', 'solver': 'saga'}}, 'score': 0.9522388059701492, 'conf_matrix': array([[159,  13,   7],
       [ 13, 294,   7],
       [  1,   7, 504]], dtype=int64), 'pickle_file': LogisticRegression(C=0.12037178940976204, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='sag', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 2, ..., 0, 1, 2])}

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with imputezero,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 11, 'max_features': 4, 'n_estimators': 10}}, 'score': 0.8357142857142857, 'conf_matrix': array([[72, 14],
       [ 9, 45]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=7, max_features=4,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=6,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,
       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,
       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,
       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1,
       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,
       1, 0, 0, 1, 1, 1, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.16371719274487778, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.7571428571428571, 'conf_matrix': array([[71, 24],
       [10, 35]], dtype=int64), 'pickle_file': LogisticRegression(C=0.1427264135444902, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,
       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,
       0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,
       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,
       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 1, 1, 0, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with imputezero,

At Step: Outlier Handling 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 17, 'max_features': 1, 'n_estimators': 19}}, 'score': 0.8580645161290322, 'conf_matrix': array([[98, 17],
       [ 5, 35]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=17, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=19,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,
       1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,
       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,
       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.7439780936876438, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.8387096774193549, 'conf_matrix': array([[96, 18],
       [ 7, 34]], dtype=int64), 'pickle_file': LogisticRegression(C=0.7812831260282708, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,
       1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,
       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,
       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,
       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,
       1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with imputezero,

At Step: Outlier Handling 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 4, 'max_features': 1, 'n_estimators': 13}}, 'score': 0.8202247191011236, 'conf_matrix': array([[101,  24],
       [  8,  45]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=5, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=18,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,
       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,
       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,
       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,
       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.05310701205369617, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.797752808988764, 'conf_matrix': array([[99, 26],
       [10, 43]], dtype=int64), 'pickle_file': LogisticRegression(C=0.04568340229264816, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,
       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0,
       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,
       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,
       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,
       0, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 8, 'max_features': 2, 'n_estimators': 18}}, 'score': 0.8214285714285714, 'conf_matrix': array([[76, 18],
       [ 7, 39]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=11, max_features=2,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=13,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,
       1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,
       1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 1, 1, 1, 1, 0, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 4.76251276844848, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.8285714285714286, 'conf_matrix': array([[74, 15],
       [ 9, 42]], dtype=int64), 'pickle_file': LogisticRegression(C=862.0083615988101, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,
       1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,
       1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 1, 1, 0, 1, 1, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 6, 'max_features': 2, 'n_estimators': 6}}, 'score': 0.8642857142857143, 'conf_matrix': array([[83, 14],
       [ 5, 38]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=6, max_features=2,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=6,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,
       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,
       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.6006745619646621, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.7857142857142857, 'conf_matrix': array([[77, 19],
       [11, 33]], dtype=int64), 'pickle_file': LogisticRegression(C=0.9898739712140293, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,
       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,
       1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,
       1, 0, 0, 0, 1, 0, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 6, 'max_features': 3, 'n_estimators': 15}}, 'score': 0.8642857142857143, 'conf_matrix': array([[90, 10],
       [ 9, 31]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=8, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=12,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,
       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,
       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 1, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.32402968937815524, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.8142857142857143, 'conf_matrix': array([[85, 12],
       [14, 29]], dtype=int64), 'pickle_file': LogisticRegression(C=0.27681755290541615, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,
       1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,
       1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,
       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,
       1, 0, 1, 0, 1, 0, 1, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 13, 'max_features': 2, 'n_estimators': 11}}, 'score': 0.8571428571428571, 'conf_matrix': array([[87, 17],
       [ 3, 33]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=13, max_features=2,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=11,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.7388060400741512, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.8071428571428572, 'conf_matrix': array([[81, 18],
       [ 9, 32]], dtype=int64), 'pickle_file': LogisticRegression(C=0.5663179306332855, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,
       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,
       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 3, 'max_features': 7, 'n_estimators': 18}}, 'score': 0.8472222222222222, 'conf_matrix': array([[90, 16],
       [ 6, 32]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=3, max_features=7,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=18,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,
       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,
       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,
       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 1.1060602887314528, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.8194444444444444, 'conf_matrix': array([[85, 15],
       [11, 33]], dtype=int64), 'pickle_file': LogisticRegression(C=1.1060602887314528, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,
       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,
       1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,
       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,
       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 8, 'max_features': 5, 'n_estimators': 13}}, 'score': 0.875, 'conf_matrix': array([[95, 14],
       [ 4, 31]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=8, max_features=5,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=13,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,
       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,
       0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 68.93881076118305, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.8263888888888888, 'conf_matrix': array([[85, 11],
       [14, 34]], dtype=int64), 'pickle_file': LogisticRegression(C=68.93881076118305, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,
       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,
       0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,
       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,
       1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with imputezero,

At Step: Outlier Handling 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 6, 'max_features': 4, 'n_estimators': 8}}, 'score': 0.8709677419354839, 'conf_matrix': array([[94,  9],
       [11, 41]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=6, max_features=4,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=8,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0,
       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,
       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,
       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,
       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,
       1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,
       1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.572502815465443, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.8129032258064516, 'conf_matrix': array([[92, 16],
       [13, 34]], dtype=int64), 'pickle_file': LogisticRegression(C=0.3024003814110007, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='sag', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,
       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1,
       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,
       1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with imputezero,

At Step: Outlier Handling 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 5, 'max_features': 4, 'n_estimators': 14}}, 'score': 0.7935483870967742, 'conf_matrix': array([[94, 26],
       [ 6, 29]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=5, max_features=4,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=14,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,
       1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,
       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 2.6851847764576413, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.7870967741935484, 'conf_matrix': array([[92, 25],
       [ 8, 30]], dtype=int64), 'pickle_file': LogisticRegression(C=23.096137870719573, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,
       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,
       1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1,
       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,
       0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 10, 'max_features': 1, 'n_estimators': 16}}, 'score': 0.8516129032258064, 'conf_matrix': array([[95, 14],
       [ 9, 37]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=8, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=15,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,
       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,
       1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.08839942402396557, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.8129032258064516, 'conf_matrix': array([[94, 19],
       [10, 32]], dtype=int64), 'pickle_file': LogisticRegression(C=0.08633268164649702, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,
       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,
       1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1,
       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,
       0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'n_estimators': 7}}, 'score': 0.8071428571428572, 'conf_matrix': array([[82,  9],
       [18, 31]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=4, max_features=2,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=7,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,
       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,
       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,
       0, 0, 1, 0, 1, 0, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.13059658047092124, 'penalty': 'l2', 'solver': 'sag'}}, 'score': 0.8071428571428572, 'conf_matrix': array([[88, 15],
       [12, 25]], dtype=int64), 'pickle_file': LogisticRegression(C=0.12699370216498726, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='sag', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,
       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,
       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 6, 'max_features': 4, 'n_estimators': 17}}, 'score': 0.8451612903225807, 'conf_matrix': array([[83, 13],
       [11, 48]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=6, max_features=4,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=17,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0,
       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,
       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,
       0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 1.6162366086415738, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.7806451612903226, 'conf_matrix': array([[79, 19],
       [15, 42]], dtype=int64), 'pickle_file': LogisticRegression(C=43.2482553543789, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,
       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,
       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,
       1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 5, 'max_features': 3, 'n_estimators': 3}}, 'score': 0.85, 'conf_matrix': array([[88, 16],
       [ 5, 31]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=5, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=3,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,
       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,
       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.4625210830514644, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.7642857142857142, 'conf_matrix': array([[77, 17],
       [16, 30]], dtype=int64), 'pickle_file': LogisticRegression(C=0.3639800534386642, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 11, 'max_features': 1, 'n_estimators': 19}}, 'score': 0.8357142857142857, 'conf_matrix': array([[89, 14],
       [ 9, 28]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=11, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=19,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       1, 0, 1, 1, 0, 0, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.06431055002480249, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.7928571428571428, 'conf_matrix': array([[87, 18],
       [11, 24]], dtype=int64), 'pickle_file': LogisticRegression(C=0.1390384882504391, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='sag', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,
       1, 0, 1, 1, 0, 0, 0, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 13, 'max_features': 3, 'n_estimators': 18}}, 'score': 0.8571428571428571, 'conf_matrix': array([[86, 10],
       [10, 34]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=13, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=18,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,
       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,
       1, 1, 0, 1, 1, 1, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 4.829715123425421, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.7571428571428571, 'conf_matrix': array([[77, 15],
       [19, 29]], dtype=int64), 'pickle_file': LogisticRegression(C=1668419.5792257932, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,
       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,
       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,
       1, 1, 0, 1, 1, 1, 1, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 15, 'max_features': 4, 'n_estimators': 19}}, 'score': 0.8541666666666666, 'conf_matrix': array([[81, 15],
       [ 6, 42]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=15, max_features=4,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=19,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,
       1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,
       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,
       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,
       1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 1.4689214041806864, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.75, 'conf_matrix': array([[73, 22],
       [14, 35]], dtype=int64), 'pickle_file': LogisticRegression(C=0.8755333326198143, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,
       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0,
       0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,
       1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 18, 'max_features': 3, 'n_estimators': 14}}, 'score': 0.8541666666666666, 'conf_matrix': array([[92, 13],
       [ 8, 31]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=18, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=14,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,
       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,
       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.45854041413392393, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.75, 'conf_matrix': array([[82, 18],
       [18, 26]], dtype=int64), 'pickle_file': LogisticRegression(C=89.19840350444775, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1,
       0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,
       1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,
       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 17, 'max_features': 3, 'n_estimators': 7}}, 'score': 0.8428571428571429, 'conf_matrix': array([[86, 16],
       [ 6, 32]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=18, max_features=2,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=14,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,
       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,
       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,
       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 1, 1, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.656156556615793, 'penalty': 'l2', 'solver': 'saga'}}, 'score': 0.7714285714285715, 'conf_matrix': array([[86, 26],
       [ 6, 22]], dtype=int64), 'pickle_file': LogisticRegression(C=2125282.2330909884, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='saga', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,
       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,
       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 6, 'max_features': 3, 'n_estimators': 7}}, 'score': 0.7928571428571428, 'conf_matrix': array([[84, 16],
       [13, 27]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=6, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=7,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 1, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 6.478270565284335, 'penalty': 'l2', 'solver': 'saga'}}, 'score': 0.7714285714285715, 'conf_matrix': array([[86, 21],
       [11, 22]], dtype=int64), 'pickle_file': LogisticRegression(C=1.096164911625252, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='saga', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,
       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 1, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 6, 'max_features': 2, 'n_estimators': 14}}, 'score': 0.8363636363636363, 'conf_matrix': array([[95, 20],
       [ 7, 43]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=2,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,
       1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,
       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,
       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,
       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,
       0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,
       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.6477440213661931, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.8242424242424242, 'conf_matrix': array([[93, 20],
       [ 9, 43]], dtype=int64), 'pickle_file': LogisticRegression(C=211.31366863155682, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,
       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,
       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0,
       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,
       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,
       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 5, 'max_features': 1, 'n_estimators': 9}}, 'score': 0.8064516129032258, 'conf_matrix': array([[91, 20],
       [10, 34]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=5, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=9,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,
       1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,
       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,
       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,
       1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.06089890624635348, 'penalty': 'l2', 'solver': 'sag'}}, 'score': 0.7806451612903226, 'conf_matrix': array([[97, 30],
       [ 4, 24]], dtype=int64), 'pickle_file': LogisticRegression(C=0.022145160633250054, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,
       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,
       1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 6, 'max_features': 2, 'n_estimators': 3}}, 'score': 0.8194444444444444, 'conf_matrix': array([[85, 12],
       [14, 33]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=6, max_features=2,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=3,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,
       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,
       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,
       0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 1.2508470958140614, 'penalty': 'l2', 'solver': 'sag'}}, 'score': 0.7777777777777778, 'conf_matrix': array([[79, 12],
       [20, 33]], dtype=int64), 'pickle_file': LogisticRegression(C=1.313225865825919, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='sag', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,
       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,
       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,
       0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 8, 'max_features': 3, 'n_estimators': 12}}, 'score': 0.8333333333333334, 'conf_matrix': array([[82,  9],
       [15, 38]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=8, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=12,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1,
       0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 1.1748697827226486, 'penalty': 'l2', 'solver': 'sag'}}, 'score': 0.7777777777777778, 'conf_matrix': array([[81, 16],
       [16, 31]], dtype=int64), 'pickle_file': LogisticRegression(C=1.1748697827226486, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='sag', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,
       0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 8, 'max_features': 3, 'n_estimators': 19}}, 'score': 0.7785714285714286, 'conf_matrix': array([[82, 21],
       [10, 27]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=5, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=8,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,
       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.8037938906082899, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.7642857142857142, 'conf_matrix': array([[75, 16],
       [17, 32]], dtype=int64), 'pickle_file': LogisticRegression(C=0.21750243693129861, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,
       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0,
       1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,
       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,
       0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,
       0, 0, 1, 0, 1, 0, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 5, 'max_features': 3, 'n_estimators': 11}}, 'score': 0.8071428571428572, 'conf_matrix': array([[81, 14],
       [13, 32]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=4, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=15,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1,
       0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,
       0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.25589204393317194, 'penalty': 'l2', 'solver': 'saga'}}, 'score': 0.7928571428571428, 'conf_matrix': array([[88, 23],
       [ 6, 23]], dtype=int64), 'pickle_file': LogisticRegression(C=0.8696834314807411, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='saga', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,
       0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 7, 'max_features': 1, 'n_estimators': 18}}, 'score': 0.8451612903225807, 'conf_matrix': array([[96, 15],
       [ 9, 35]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=7, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=18,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,
       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,
       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,
       0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 2.1086558500091135, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.7870967741935484, 'conf_matrix': array([[89, 17],
       [16, 33]], dtype=int64), 'pickle_file': LogisticRegression(C=14839.33237045672, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,
       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,
       1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,
       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0,
       0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 15, 'max_features': 3, 'n_estimators': 8}}, 'score': 0.7777777777777778, 'conf_matrix': array([[78, 11],
       [21, 34]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=15, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=8,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,
       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,
       0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,
       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,
       1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 2.001919523190494, 'penalty': 'l2', 'solver': 'sag'}}, 'score': 0.7083333333333334, 'conf_matrix': array([[70, 13],
       [29, 32]], dtype=int64), 'pickle_file': LogisticRegression(C=6.894578333453981, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='sag', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0,
       0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,
       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,
       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,
       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,
       1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 13, 'max_features': 4, 'n_estimators': 12}}, 'score': 0.7857142857142857, 'conf_matrix': array([[80, 21],
       [ 9, 30]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=19, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=14,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,
       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,
       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,
       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.11833312921383206, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.7428571428571429, 'conf_matrix': array([[78, 25],
       [11, 26]], dtype=int64), 'pickle_file': LogisticRegression(C=0.11526424970091752, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,
       0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,
       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1,
       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1], dtype=int64)}

At Step: textProcessing 
Sequence executed:
  Text Processing with BOW,

At Step: Modelling classification 
Sequence executed:
  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 18, 'max_features': 335, 'n_estimators': 13}}, 'score': 0.9333333333333333, 'conf_matrix': array([[136,  20,  16],
       [ 12, 295,  12],
       [  5,   2, 507]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=18, max_features=335,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=13,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array(['british', 'cajun_creole', 'cajun_creole', ..., 'cajun_creole',
       'chinese', 'chinese'], dtype=object)}

At Step: Modelling classification 
Sequence executed:
  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 3.207927032798479, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.9522388059701492, 'conf_matrix': array([[142,  13,  12],
       [ 11, 301,   9],
       [  0,   3, 514]], dtype=int64), 'pickle_file': LogisticRegression(C=3.568804154625533, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array(['british', 'cajun_creole', 'cajun_creole', ..., 'cajun_creole',
       'chinese', 'chinese'], dtype=object)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 14, 'max_features': 1, 'n_estimators': 17}}, 'score': 0.8181818181818182, 'conf_matrix': array([[78, 13],
       [17, 57]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=2, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=14,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,
       1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,
       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,
       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1,
       0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,
       1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,
       1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,
       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.07418116181919353, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.8242424242424242, 'conf_matrix': array([[79, 13],
       [16, 57]], dtype=int64), 'pickle_file': LogisticRegression(C=0.057128729150974306, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,
       1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,
       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,
       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1,
       0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,
       1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,
       1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,
       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 19, 'max_features': 3, 'n_estimators': 14}}, 'score': 0.8181818181818182, 'conf_matrix': array([[85, 23],
       [ 7, 50]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=19, max_features=3, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=14, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,
       1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,
       0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,
       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 0.45736414663848546, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.8, 'conf_matrix': array([[80, 21],
       [12, 52]], dtype=int64), 'pickle_file': LogisticRegression(C=1.8870234127010779, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,
       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,
       0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,
       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,
       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0], dtype=int64)}

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 18, 'max_features': 981, 'n_estimators': 7}}, 'score': 0.9353233830845771, 'conf_matrix': array([[134,  15,  13],
       [ 15, 280,   6],
       [  8,   8, 526]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=18, max_features=981, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=7, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([2, 2, 2, ..., 2, 1, 2])}

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 1.963185803517896, 'penalty': 'l2', 'solver': 'saga'}}, 'score': 0.9482587064676616, 'conf_matrix': array([[141,  11,   6],
       [ 12, 285,  12],
       [  4,   7, 527]], dtype=int64), 'pickle_file': LogisticRegression(C=1.8409484134097454, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='saga', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([2, 2, 2, ..., 2, 1, 2])}

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 16, 'max_features': 933, 'n_estimators': 18}}, 'score': 0.9263681592039801, 'conf_matrix': array([[131,  22,  13],
       [ 17, 278,   5],
       [  8,   9, 522]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=16, max_features=933, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=18, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([2, 2, 1, ..., 2, 2, 1])}

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 1.8800401720249413, 'penalty': 'l2', 'solver': 'sag'}}, 'score': 0.9502487562189055, 'conf_matrix': array([[140,  11,   7],
       [ 11, 289,   7],
       [  5,   9, 526]], dtype=int64), 'pickle_file': LogisticRegression(C=1.8621455041673936, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([2, 2, 1, ..., 2, 2, 2])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 8, 'max_features': 1, 'n_estimators': 10}}, 'score': 0.8194444444444444, 'conf_matrix': array([[87, 16],
       [10, 31]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=5, max_features=2, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,
       1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,
       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,
       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,
       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 0.20195899766622874, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.7847222222222222, 'conf_matrix': array([[88, 22],
       [ 9, 25]], dtype=int64), 'pickle_file': LogisticRegression(C=0.14364822507532055, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='newton-cg', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,
       1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0], dtype=int64)}

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 18, 'max_features': 1238, 'n_estimators': 9}}, 'score': 0.9412935323383085, 'conf_matrix': array([[157,  21,  12],
       [ 12, 262,   6],
       [  3,   5, 527]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=18, max_features=1238, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=9, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([1, 2, 2, ..., 1, 1, 0])}

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 0.3588229809089297, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.9572139303482587, 'conf_matrix': array([[160,  11,   7],
       [ 10, 268,   4],
       [  2,   9, 534]], dtype=int64), 'pickle_file': LogisticRegression(C=0.3266886935451164, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='newton-cg', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([1, 2, 2, ..., 1, 1, 0])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 15, 'max_features': 1, 'n_estimators': 5}}, 'score': 0.8156424581005587, 'conf_matrix': array([[100,  22],
       [ 11,  46]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=8, max_features=2, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=1, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1,
       0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,
       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0,
       0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,
       0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 3.3791394969891226, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.7932960893854749, 'conf_matrix': array([[94, 20],
       [17, 48]], dtype=int64), 'pickle_file': LogisticRegression(C=0.9024834796478255, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='newton-cg', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1,
       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1,
       0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,
       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0,
       0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,
       0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0], dtype=int64)}

At Step: Encoding 
Sequence executed:
  Encoding with one-hot,

At Step: Outlier Handling 
Sequence executed:
  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
  Outlier Handling with removing,  Encoding with one-hot,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 14, 'max_features': 688, 'n_estimators': 11}}, 'score': 0.9395348837209302, 'conf_matrix': array([[84,  5,  3,  0],
       [ 1, 47,  2,  0],
       [ 1,  1, 62,  0],
       [ 0,  0,  0,  9]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=18, max_features=573, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=8, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([2, 0, 0, 2, 0, 2, 2, 1, 0, 0, 0, 1, 0, 2, 0, 3, 1, 0, 2, 0, 0, 2,
       1, 2, 1, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 2, 1, 1, 0,
       2, 2, 1, 2, 0, 2, 0, 1, 1, 3, 0, 2, 1, 3, 0, 0, 2, 1, 2, 1, 2, 0,
       1, 2, 2, 2, 0, 0, 0, 1, 1, 1, 1, 0, 2, 2, 0, 1, 2, 2, 2, 2, 0, 0,
       2, 1, 0, 1, 1, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0,
       0, 0, 1, 2, 0, 2, 2, 2, 1, 0, 2, 2, 0, 3, 1, 1, 1, 0, 1, 2, 0, 0,
       2, 0, 1, 0, 1, 2, 0, 1, 2, 3, 0, 0, 2, 0, 0, 2, 1, 1, 1, 2, 2, 2,
       0, 0, 2, 0, 0, 3, 0, 2, 0, 2, 3, 0, 2, 0, 2, 0, 1, 1, 1, 1, 1, 2,
       0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 1, 3, 2, 2, 1, 0, 0, 0, 2, 1, 0, 0,
       2, 2, 0, 0, 0, 0, 1, 0, 2, 0, 3, 0, 1, 0, 0, 0, 0])}

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 0.711255149527642, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.9255813953488372, 'conf_matrix': array([[83,  6,  5,  0],
       [ 3, 45,  0,  0],
       [ 0,  2, 62,  0],
       [ 0,  0,  0,  9]], dtype=int64), 'pickle_file': LogisticRegression(C=1.1257141187883049, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([2, 0, 2, 0, 0, 2, 2, 1, 0, 0, 0, 1, 0, 0, 0, 3, 1, 0, 2, 0, 0, 2,
       1, 2, 0, 2, 1, 1, 1, 0, 1, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 1, 1, 0,
       2, 2, 0, 2, 0, 2, 0, 1, 1, 3, 0, 2, 1, 3, 0, 0, 2, 1, 2, 1, 2, 0,
       1, 2, 2, 2, 0, 0, 0, 1, 1, 1, 1, 0, 2, 2, 0, 1, 2, 2, 2, 2, 0, 0,
       2, 1, 0, 1, 1, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0,
       0, 0, 1, 2, 0, 2, 2, 2, 1, 0, 2, 2, 0, 3, 1, 1, 1, 0, 1, 2, 0, 0,
       2, 0, 1, 0, 1, 2, 0, 1, 2, 3, 0, 0, 2, 0, 1, 2, 1, 1, 1, 2, 2, 2,
       0, 0, 2, 0, 0, 3, 0, 2, 0, 2, 3, 0, 2, 0, 2, 0, 1, 1, 1, 1, 0, 2,
       0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 1, 3, 2, 2, 1, 0, 0, 0, 2, 1, 2, 0,
       2, 2, 0, 0, 0, 0, 2, 0, 2, 1, 3, 0, 1, 0, 0, 0, 0])}

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 18, 'max_features': 65, 'n_estimators': 19}}, 'score': 0.9255813953488372, 'conf_matrix': array([[87,  9,  3,  0],
       [ 1, 38,  1,  0],
       [ 2,  0, 65,  0],
       [ 0,  0,  0,  9]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=18, max_features=65, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=19, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([2, 2, 0, 2, 2, 2, 2, 0, 1, 2, 0, 1, 2, 2, 3, 2, 1, 1, 0, 0, 2, 2,
       3, 0, 2, 0, 1, 1, 0, 0, 2, 0, 1, 2, 2, 2, 0, 0, 0, 1, 2, 0, 3, 0,
       2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 0, 0, 3, 0, 0, 0, 2, 0, 2, 2, 0, 0,
       0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0,
       1, 0, 3, 2, 0, 2, 0, 0, 0, 1, 1, 1, 1, 1, 2, 0, 1, 2, 3, 1, 1, 0,
       0, 1, 1, 0, 2, 0, 0, 1, 0, 0, 0, 1, 3, 0, 0, 0, 0, 2, 2, 2, 0, 0,
       0, 0, 2, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 0, 0, 0, 1, 0, 1, 3, 0, 1,
       1, 2, 0, 2, 2, 2, 0, 0, 3, 0, 1, 2, 2, 0, 1, 0, 1, 0, 0, 0, 1, 0,
       2, 0, 2, 2, 0, 2, 2, 2, 0, 0, 2, 0, 1, 2, 0, 2, 1, 1, 1, 1, 0, 2,
       1, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 2])}

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 3.2019246007862354, 'penalty': 'l2', 'solver': 'sag'}}, 'score': 0.9162790697674419, 'conf_matrix': array([[85, 10,  3,  0],
       [ 5, 37,  0,  0],
       [ 0,  0, 66,  0],
       [ 0,  0,  0,  9]], dtype=int64), 'pickle_file': LogisticRegression(C=807.9150608519338, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([2, 2, 0, 2, 2, 2, 2, 0, 1, 2, 0, 1, 2, 2, 3, 2, 0, 1, 0, 0, 2, 2,
       3, 0, 2, 1, 1, 1, 1, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 1, 2, 0, 3, 0,
       2, 2, 2, 2, 2, 1, 1, 2, 0, 1, 0, 0, 3, 0, 0, 0, 2, 0, 2, 2, 0, 0,
       0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 2, 0, 0, 2, 0,
       1, 0, 3, 2, 0, 2, 0, 0, 0, 1, 1, 1, 1, 1, 2, 0, 1, 2, 3, 1, 1, 0,
       0, 1, 1, 0, 2, 0, 1, 1, 0, 0, 0, 1, 3, 0, 0, 0, 0, 2, 2, 2, 0, 0,
       1, 0, 2, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 3, 0, 1,
       1, 2, 0, 2, 2, 2, 0, 0, 3, 0, 1, 2, 2, 0, 1, 0, 1, 0, 0, 0, 1, 2,
       2, 0, 2, 2, 0, 2, 2, 2, 0, 0, 2, 0, 1, 2, 0, 0, 1, 1, 1, 1, 0, 2,
       1, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 2])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 13, 'max_features': 3, 'n_estimators': 9}}, 'score': 0.8263888888888888, 'conf_matrix': array([[91, 14],
       [11, 28]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=13, max_features=3, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=9, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1,
       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,
       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,
       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0])}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 0.15558991836824737, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.7847222222222222, 'conf_matrix': array([[89, 18],
       [13, 24]], dtype=int64), 'pickle_file': LogisticRegression(C=0.2946583626120247, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1,
       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,
       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,
       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'param': {'criterion': 'mae', 'max_depth': 6, 'max_features': 2, 'n_estimators': 10}}, 'score': 931.0789955041542, 'residual': <matplotlib.axes._subplots.AxesSubplot object at 0x000001CAA1737F48>, 'pickle_file': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=6,
           max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=10, n_jobs=None, oob_score=False,
           random_state=None, verbose=0, warm_start=False), 'y_pred': array([1200.06785221,  347.5744365 ,  366.85142166,  203.60196694,
       1510.85967334, 2204.56318828, 1649.67942061, 1606.27744163,
       1161.97389731, 1316.79994439,  584.19855068, 1989.70055166,
       1376.16420291, 2151.93278545,  287.35718117, 1422.71546676,
       2127.25994526, 1037.36471035,  627.36900269,  759.27311813,
        512.67889499, 1347.69803451, 1121.21660767, 1252.39346893,
       1989.70055166,  384.79346426, 1816.21253932,  704.08463819,
        760.75553571,  969.79959533,  946.66943894,  504.39636132,
       2161.69103848,  864.20521639,  759.27311813,  453.42475502,
       1989.70055166, 1197.50685221, 1933.50014529,  848.63161447,
       1989.70055166,  757.74139179,  512.67889499,  969.79959533,
       1373.82694801,  584.19855068, 1933.50014529, 1516.72389293,
       2043.59673755, 1393.90164633,  549.94314518,  317.45694176,
       1373.82694801,  351.89524989,  969.79959533,  734.31912179,
       1121.21660767, 1848.56163566,  199.59159657,  960.91500037,
        966.25472354, 1447.54058451, 2036.21104196, 1878.92196243,
       1670.08055208, 1315.37267166,  388.96779582, 1878.92196243,
       1139.77378004,  317.45694176, 1670.08055208,  629.87519089,
        206.31440713,  843.31247572,  663.02378318, 1549.30871487,
        989.77471509, 1447.54058451, 1652.23358727, 1742.50663821,
       1011.35353216,  963.39395965, 2135.77562666,  808.91393862,
       1349.02542379, 1848.56163566, 1599.8252112 , 2135.77562666,
       1254.3635988 , 2045.56989772,  518.04427961,  518.04427961,
       1315.37267166,  704.08463819,  305.61987806, 1121.21660767,
        317.45694176, 1185.92952302, 2127.25994526, 2043.59673755,
       2139.49261383,  243.83440919, 1987.81897046,  326.85305608,
        629.47566936, 1989.70055166,  636.68739868, 1644.92374809,
        969.79959533,  584.19855068, 1568.04605894,  748.35708998,
       1220.45616158,  206.31440713,  502.41719465,  206.31440713,
        251.42104713, 1276.92096768, 1933.50014529, 1194.56411028,
       2131.36073891,  347.5744365 , 1632.89151686,  760.75553571,
       1933.50014529, 1132.6645721 , 2139.49261383,  751.41542332,
       1276.92096768, 1606.27744163,  439.86481748, 1021.51781787,
       2131.36073891,  287.35718117, 2204.56318828, 1077.62347557,
       1925.36252383, 1777.3992082 ,  808.65938262,  851.76532488,
       2080.0464257 , 1537.43847788,  897.26683308, 2091.19422053,
       1987.81897046, 1227.65430261, 1816.21253932,  577.08805698,
       1280.95213651, 2036.21104196, 1390.86769407,  160.58282248,
        703.63092873, 1777.3992082 ,  140.52383185, 1925.36252383,
        282.85483634, 1593.35008044,  629.47566936, 1220.45616158,
       1422.71546676, 1152.85020046,  848.63161447,  748.35708998,
        936.58769392, 2204.56318828, 1813.6661625 , 2244.45715075,
       1514.92250162, 1606.27744163, 1041.64693707,  663.02378318,
       2194.86181465, 1997.24621947, 1315.37267166,  627.67942369,
        156.85637803,  577.08805698, 1813.6661625 , 1813.6661625 ,
       1041.64693707,  759.27311813, 1194.56411028,  552.99540999,
        234.76051131, 1037.36471035, 1985.03563713, 1738.28825623,
       1373.82694801,  707.27497635, 1238.5823625 ,  287.35718117,
       1347.69803451, 1692.19223578, 2102.00229413,  812.49177113,
       2168.15103848, 1742.50663821, 1065.74823666, 1276.92096768,
       1881.827766  ,  347.5744365 , 2135.77562666, 1549.30871487,
        689.46016122,  480.41335997, 1688.39315532, 1777.3992082 ,
       1640.89419285, 1045.78811354, 2093.00240235, 1413.30856388,
        455.6113465 ,  704.08463819, 1460.08851607, 1121.21660767,
        812.49177113, 1224.00949492,  584.19855068,  584.19855068,
       1514.92250162, 1390.86769407,  943.70450388,  679.27250016,
       1989.70055166, 2225.40944587, 1599.8252112 , 2093.00240235,
       1390.86769407, 1194.56411028, 1347.69803451,  902.91704953,
        584.19855068,  206.31440713, 1510.85967334,  946.66943894,
       1422.71546676, 1816.21253932, 1989.70055166,  140.52383185,
       1005.0357584 ,  508.67816239, 1129.35010616,  803.75517807,
       1881.827766  ,  956.81265433, 1599.8252112 , 1707.80681862,
       1461.29870869,  629.47566936,  502.41719465, 2046.40740421,
       1373.82694801, 1510.85967334, 1047.51312662,  577.08805698,
       1794.38932919,  512.67889499,  653.03463173,  808.65938262,
        388.96779582, 1373.82694801, 1933.50014529, 1599.8252112 ,
       1347.69803451,  869.07148817, 1077.62347557, 1194.56411028,
       1816.40996651, 1460.08851607, 1252.39346893,  851.76532488,
        384.79346426,  206.31440713,  848.63161447, 1917.26652499,
       1925.36252383, 1537.43847788,  869.07148817,  869.07148817,
        413.01031544, 2023.48065938, 1606.27744163,  663.02378318,
        966.25472354, 1985.03563713, 2139.49261383, 2043.59673755,
        317.45694176, 1858.12294838,  210.63135065, 1276.92096768,
       1373.82694801,  160.58282248,  627.67942369, 2236.126758  ,
       1777.3992082 , 1925.36252383, 1848.56163566,  906.95082731,
       1850.38941344, 1549.30871487,  653.03463173, 1504.43760191,
       2194.86181465,  763.19783077,  366.85142166, 1599.8252112 ,
       1848.56163566, 1495.69580437, 1722.51639517, 1003.29839576,
       1702.71681862,  453.42475502,  932.70838358, 2161.69103848,
       1987.81897046,  932.70838358, 1077.62347557,  359.34698443,
       2043.59673755,  707.27497635,  851.76532488,  632.17216058,
        518.04427961,  808.65938262,  203.60196694, 2184.26416476,
        963.39395965, 1922.57835716, 1037.36471035, 1077.62347557,
       1514.92250162,  703.63092873, 1422.71546676, 1280.95213651,
       1422.71546676, 1077.62347557, 1540.41347788, 1910.17037761,
        206.31440713, 2093.00240235, 2171.4090513 , 2178.4931865 ,
       1939.02102854,  549.94314518, 1848.56163566,  326.85305608,
       2199.79812418, 1447.54058451, 1093.36334865, 1373.82694801,
       2204.56318828, 1315.37267166, 1914.04486037,  966.25472354,
       1644.92374809, 1458.36851607, 1568.04605894,  932.70838358,
       1881.827766  , 1085.15012843, 1802.41440134, 1161.97389731,
       1881.827766  ,  897.26683308, 1180.24350293,  151.34417215,
        927.98252888, 1606.27744163, 1741.03836235, 1044.20496336,
       1194.56411028, 1809.25901965,  273.77666462, 1688.39315532,
        963.39395965,  717.17966137,  206.31440713, 1939.02102854,
        243.83440919,  869.07148817,  619.98807604, 2043.12794283,
       1549.30871487,  391.89171812,  151.34417215, 1933.50014529,
        206.31440713,  704.08463819,  617.01653133,  203.60196694,
       1165.54373858,  549.94314518,  504.39636132,  391.89171812,
        653.03463173, 1121.21660767,  317.45694176,  759.27311813,
       1227.65430261,  824.15613621, 2036.21104196,  663.02378318,
        518.04427961, 2045.56989772, 1427.50713343, 1813.12682503,
       1848.56163566,  206.31440713, 1939.02102854, 1517.96394975,
        881.11864138, 1280.95213651,  966.25472354,  287.35718117,
       1121.21660767,  946.66943894,  549.94314518, 1874.976056  ,
        504.39636132, 1777.3992082 , 1373.82694801])}

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.base.LinearRegression'>, 'param': {'normalize': 'False'}}, 'score': 831.7333284604344, 'residual': <matplotlib.axes._subplots.AxesSubplot object at 0x000001CAA1737F48>, 'pickle_file': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
         normalize='False'), 'y_pred': array([1208.69917778,  342.87344794,  366.89635837,  201.73884921,
       1504.98173966, 2222.66618856, 1652.12206601, 1604.07624516,
       1160.65335693, 1326.81182069,  603.12164419, 1988.44281193,
       1380.86336914, 2155.60223029,  267.80185287, 1418.89964398,
       2108.55736405, 1029.5283042 ,  645.16173743,  773.28392636,
        517.03954851, 1336.8213667 , 1109.60467228, 1250.73927102,
       1985.43994813,  379.90876818, 1802.26525615,  694.20851288,
        747.25910673,  987.48821096,  945.44811772,  496.01950189,
       2161.6079579 ,  863.36984044,  770.28106255,  448.97463564,
       1987.44185733, 1204.69535937, 1943.39985489,  837.34502082,
       1986.44090273,  745.25719753,  520.04241231,  985.48630176,
       1370.85382313,  598.11687119, 1942.39890029, 1527.00274089,
       2054.50581559, 1405.88723417,  536.05768593,  310.84290071,
       1365.84905013,  356.88681236,  986.48725636,  732.24478772,
       1125.6199459 , 1839.30057639,  190.7283486 ,  953.45575453,
        971.47293735, 1443.923509  , 2025.47813217, 1879.33876043,
       1670.13924882, 1310.79654708,  389.91831419, 1877.33685122,
       1148.64190172,  314.84671912, 1673.14211263,  623.14073621,
        222.75889583,  829.33738401,  672.18751166, 1552.02660591,
        998.49871157, 1440.9206452 , 1659.12874821, 1740.20607089,
       1019.5187582 ,  957.45957294, 2129.57741067,  816.3249742 ,
       1357.84141332, 1846.30725859, 1598.07051755, 2128.57645607,
       1255.74404402, 2046.49817879,  521.04336691,  524.04623072,
       1316.80227468,  692.20660368,  295.8285817 , 1103.59894468,
        321.85340132, 1176.66863055, 2107.55640945, 2055.5067702 ,
       2146.59363888,  252.78753386, 1974.42944752,  328.86008353,
        634.15123682, 1990.44472113,  646.16269203, 1649.1192022 ,
        983.48439256,  596.11496199, 1561.03519732,  738.25051532,
       1215.70585998,  205.74266761,  508.0309571 ,  208.74553141,
        257.79230686, 1273.76122684, 1940.39699108, 1191.68294956,
       2114.56309165,  344.87535714, 1624.09533718,  759.27056194,
       1948.40462789, 1141.63521951, 2147.59459348,  744.25624293,
       1286.77363665, 1600.07242676,  426.95363442, 1021.5206674 ,
       2113.56213705,  271.80567127, 2220.66427935, 1075.57221585,
       1926.38362667, 1760.22516291,  798.30779138,  849.35647603,
       2072.52299841, 1545.0199237 ,  889.39466007, 2096.54590883,
       1969.42467451, 1234.7239974 , 1814.27671136,  576.09586997,
       1295.78222806, 2027.48004137, 1396.87864276,  168.70734737,
        715.2285595 , 1789.25284634,  145.68539155, 1924.38171747,
        266.80089827, 1575.04856173,  635.15219142, 1212.70299618,
       1417.89868938, 1149.64285632,  835.34311162,  739.25146992,
        937.44048092, 2217.66141555, 1825.28721197, 2247.69005358,
       1519.99605868, 1616.08770037, 1031.53021341,  663.17892025,
       2200.64518734, 2009.46285855, 1304.79081947,  612.1302356 ,
        160.69971057,  574.09396077, 1822.28434817, 1824.28625737,
       1032.53116801,  769.28010795, 1189.68104036,  564.08441476,
        237.77321484, 1027.526395  , 1975.43040212, 1734.20034329,
       1361.84523173,  702.21614969, 1239.72877041,  282.81617188,
       1341.82613971, 1690.15834084, 2102.55163644,  826.33452021,
       2169.61559471, 1744.20988929, 1054.55216923, 1265.75359003,
       1885.34448803,  350.88108475, 2122.57072846, 1550.02469671,
        690.20469448,  478.00231907, 1680.14879483, 1766.23089052,
       1626.09724638, 1036.53498641, 2082.53254442, 1406.88818877,
        463.98895466,  696.21042208, 1457.93687342, 1127.6218551 ,
        824.33261101, 1226.7163606 ,  592.11114358,  599.11782579,
       1507.98460347, 1395.87768816,  938.44143552,  683.19801227,
       1981.43612972, 2226.67000696, 1588.06097154, 2088.53827203,
       1393.87577896, 1181.67340355, 1338.8232759 ,  911.41566129,
        594.11305278,  221.75794123, 1506.98364887,  944.44716312,
       1425.90632619, 1801.26430155, 1994.44853954,  144.68443695,
       1012.51207599,  515.03763931, 1134.62853731,  809.31829199,
       1881.34066963,  951.45384533, 1586.05906234, 1709.17647826,
       1474.95310163,  637.15410063,  503.0261841 , 2058.509634  ,
       1368.85191393, 1499.97696666, 1044.54262322,  583.10255217,
       1796.25952854,  516.03859391,  651.16746504,  794.30397298,
        387.91640499, 1367.85095933, 1945.40176409, 1593.06574455,
       1339.8242305 ,  875.38129566, 1064.56171524, 1183.67531275,
       1827.28912117, 1461.94069182, 1247.73640722,  854.36124904,
        381.91067738,  211.74839522,  830.33833861, 1908.36644385,
       1922.37980827, 1544.0189691 ,  865.37174965,  882.38797786,
        405.9335878 , 2017.47049536, 1613.08483657,  665.18082945,
        974.47580115, 1979.43422052, 2148.59554809, 2050.50199719,
        324.85626512, 1854.3148954 ,  234.77035104, 1287.77459125,
       1376.85955074,  177.71593878,  617.13500861, 2241.68432597,
       1781.24520953, 1916.37408066, 1840.30153099,  912.41661589,
       1849.3101224 , 1556.03042431,  654.17032884, 1494.97219365,
       2204.64900574,  779.28965396,  372.90208597, 1590.06288075,
       1843.30439479, 1493.97123905, 1715.18220587, 1001.50157538,
       1703.17075066,  438.96508963,  923.4271165 , 2163.6098671 ,
       1972.42753832,  934.43761711, 1083.57985266,  359.88967616,
       2051.50295179,  698.21233129,  853.36029443,  629.14646382,
        527.04909452,  800.30970058,  193.7312124 , 2191.63659593,
        959.46148214, 1915.37312606, 1030.52925881, 1073.57030665,
       1513.99033107,  706.21996809, 1413.89487098, 1299.78604647,
       1412.89391637, 1072.56935205, 1549.02374211, 1900.35880705,
        215.75221362, 2081.53158982, 2170.61654931, 2178.62418611,
       1957.4132193 ,  549.07009574, 1844.30534939,  331.86294733,
       2214.65855175, 1436.9168268 , 1089.58558026, 1360.84427712,
       2218.66237015, 1312.79845628, 1903.36167085,  968.47007355,
       1635.10583779, 1456.93591882, 1566.03997032,  926.42998031,
       1886.34544263, 1084.58080726, 1798.26143775, 1154.64762933,
       1882.34162423,  896.40134228, 1169.66194834,  154.69398296,
        921.4252073 , 1610.08197277, 1747.2127531 , 1041.53975942,
       1185.67722196, 1826.28816657,  263.79803447, 1684.15261324,
        964.46625514,  728.24096931,  218.75507742, 1958.4141739 ,
        248.78371545,  880.38606866,  611.129281  , 2038.49054198,
       1553.02756051,  395.92404179,  156.69589216, 1936.39317268,
        213.75030442,  697.21137668,  610.1283264 ,  194.732167  ,
       1165.65812994,  535.05673133,  491.01472889,  396.92499639,
        652.16841964, 1126.6209005 ,  312.84480991,  771.28201716,
       1233.7230428 ,  828.33642941, 2035.48767818,  664.17987485,
        525.04718532, 2043.49531498, 1426.90728079, 1799.26239235,
       1836.29771258,  220.75698662, 1956.4122647 , 1530.00560469,
        883.38893246, 1296.78318266,  972.47389195,  285.81903569,
       1114.60944529,  946.44907232,  546.06723194, 1864.32444141,
        492.01568349, 1773.23757272, 1366.85000473])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'param': {'criterion': 'mse', 'max_depth': 6, 'max_features': 1, 'n_estimators': 16}}, 'score': 955.2978977108863, 'residual': <matplotlib.axes._subplots.AxesSubplot object at 0x00000247EE3CAB88>, 'pickle_file': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=6,
           max_features=1, max_leaf_nodes=None, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=16, n_jobs=None, oob_score=False,
           random_state=None, verbose=0, warm_start=False), 'y_pred': array([ 503.62369954, 1277.54538692,  216.60554352,  625.68508642,
       1671.84244271, 2009.50232393, 1346.89845334,  505.33165409,
       1841.8806523 , 1517.70185293, 1807.91226393, 1059.17367739,
       1618.83767534, 1776.1694612 , 1664.04052813,  397.13688112,
       1279.77440262, 1012.52308672, 1456.15750391, 1398.6996064 ,
       1358.99502358,  698.04115442, 1433.15788471, 1982.26209792,
        444.70303541, 1987.06655926, 1424.86614942, 1256.98756631,
        767.03413472, 1088.00089252,  940.11964291, 1349.62437234,
       1774.56506559, 1914.54194563, 2009.50232393, 2185.10087896,
       1389.14739511, 1597.48271725,  762.52093738, 1982.26209792,
       1847.15188311, 1437.12595483, 1193.86505471,  444.70303541,
        652.03049522, 2201.75731109,  441.61158445, 1610.57752507,
       1836.32078508,  807.72524624, 1433.61933563,  526.69618233,
       1015.07580137, 2052.41559864, 1561.11217876, 1987.06655926,
       2036.52634049, 1433.61933563, 1841.8806523 , 1836.32078508,
       1696.17742347, 1507.7605061 , 1776.1694612 , 1310.6128181 ,
       1331.97888096,  354.71463489, 1841.8806523 ,  881.97140456,
        857.62514157, 2237.11283729,  762.52093738,  378.38660883,
        583.29576476,  317.82161747, 1562.51405074,  367.7514105 ,
       2098.54743767,  986.44188541,  662.21054771,  236.27495282,
       2100.29817296, 2127.43424684, 2201.75731109,  294.27123025,
       1254.86145149, 1519.54096738, 1696.17742347, 2201.75731109,
       1723.53383374,  556.72529674, 1331.97888096, 1138.67782355,
        854.99619136, 2231.61806089, 1168.75425786, 2100.29817296,
        767.03413472,  236.27495282, 1015.07580137, 1610.57752507,
       1174.23758766, 1664.04052813, 1184.77779812, 2093.51449149,
       1059.17367739, 1812.67357277, 1840.04434278, 1113.38248843,
        441.61158445,  698.04115442,  480.7148323 , 1694.0982568 ,
       1331.97888096, 1059.17367739, 1705.01577103,  623.62210688,
        347.86437372,  284.83482945, 1424.86614942,  807.72524624,
       1517.70185293, 1519.22887996,  355.54873815, 2176.94633674,
        698.04115442,  265.95677597,  546.15961558,  972.67681287,
        180.28219611, 2130.28812213,  608.85866316, 1610.57752507,
       2058.98756069, 1597.48271725,  556.72529674,  288.70514669,
        585.18160067,  577.75103286,  441.61158445, 1776.1694612 ,
        949.57251999, 1063.49187583, 1113.38248843,  397.13688112,
       1641.08819414, 1138.67782355, 1687.9128976 ,  482.49087397,
        978.34794828, 2141.28031549,  413.46606068,  193.88885179,
        216.60554352, 1193.86505471, 1204.25992118, 1946.68274314,
        849.50036323,  148.41916687, 2009.50232393, 1113.38248843,
       1191.88236476, 1776.1694612 ,  484.36140969, 1519.54096738,
       1450.22315785,  216.60554352, 1277.54538692, 1811.75702448,
       2036.52634049, 2031.01988342, 2201.75731109, 1946.68274314,
        216.60554352, 1696.17742347, 1102.35652456, 1812.67357277,
       1774.56506559,  585.18160067,  300.62032471, 1310.6128181 ,
       1256.98756631, 1310.6128181 ,  807.72524624, 1482.87526442,
       1736.24364747, 1189.23064062,  857.62514157, 2224.23335319,
        577.75103286, 1610.57752507,  355.73993251, 1216.1967985 ,
        972.67681287,  444.70303541, 1873.03422816,  972.67681287,
       2034.48494023, 1191.88236476,  767.03413472,  216.60554352,
       2133.57115304, 2145.40268239, 1106.09959687, 1015.07580137,
       1696.17742347, 1089.75875071, 1481.76198317,  902.83794702,
       1059.17367739, 1396.68426113,  972.67681287, 2127.43424684,
       1005.13441374,  441.61158445,  317.82161747,  940.11964291,
        546.15961558,  505.33165409, 1017.22811463, 1366.4891766 ,
       1716.17446625, 1753.20084882,  503.62369954, 1222.69335574,
        762.52093738, 1914.54194563,  603.89713043, 1214.22596517,
       1433.61933563, 1106.09959687,  857.62514157, 1664.04052813,
       1946.68274314,  234.7652306 ,  484.36140969, 1930.80511462,
        216.60554352,  920.93572519,  583.29576476,  207.98486182,
       1391.77626865,  603.89713043,  857.62514157,  972.67681287,
        698.04115442,  625.68508642,  400.58287185,  444.70303541,
       1597.48271725, 1690.88445209, 1610.57752507, 1113.38248843,
        837.53178594,  893.17388281, 1519.54096738,  288.70514669,
       2127.43424684, 2231.61806089,  148.41916687,  236.27495282,
       1426.67586422,  397.13688112, 1736.24364747,  444.70303541,
        952.17647832, 1946.68274314,  585.18160067, 1214.22596517,
       1059.17367739, 1776.1694612 , 1349.62437234,  893.17388281,
       1696.17742347, 1910.52183904,  236.27495282,  284.83482945,
       1922.42502979,  819.79896403,  625.68508642,  503.62369954,
        560.91738743, 1716.17446625, 2176.94633674,  623.62210688,
       1946.68274314,  986.44188541,  857.62514157,  413.46606068,
       1138.67782355,  277.79432019,  972.67681287, 1349.62437234,
       1099.21031921, 2127.43424684,  170.0747622 , 1310.6128181 ,
       2130.28812213,  625.68508642, 1604.64392646, 2231.61806089,
       1433.61933563,  845.72405701, 1113.38248843, 1873.03422816,
       1623.48934299,  347.86437372,  857.62514157, 1610.57752507,
        710.35380903, 1876.38461735,  476.81223203,  875.09333329,
        938.44656599,  298.95157471,  857.62514157,  762.52093738,
        211.74334396, 1433.15788471, 1716.17446625, 1869.42775238,
        174.59738101, 2011.59770792,  940.11964291, 1774.56506559,
       2093.51449149, 1841.8806523 , 1272.35236161, 1059.17367739,
        435.87052081, 1924.77094364,  560.91738743,  767.03413472,
       1847.15188311, 1543.42389627, 1984.53931567,  505.33165409,
       1138.67782355,  698.04115442, 1165.95294564, 1519.54096738,
       1793.52459586, 2001.01981924,  444.70303541,  891.99969023,
       1313.61538453, 2009.50232393, 1433.61933563, 1642.04059799,
       1222.69335574,  399.21556416, 2009.50232393, 1597.48271725,
       2034.98503614, 1366.4891766 , 1329.68295921, 1544.94202127,
        434.14933861,  854.99619136,  698.04115442,  399.21556416,
        311.76155418,  585.18160067, 1378.25884961, 2093.51449149,
       1480.92109775, 1984.53931567, 1036.67419601,  447.34333652,
        193.88885179,  560.91738743, 1774.56506559, 1424.86614942,
       1277.54538692, 2036.52634049, 1546.08711055, 1444.70261338,
       2022.93503033,  447.34333652, 1916.27914801, 1873.03422816,
        655.9623106 , 2130.28812213,  706.27290243,  932.18197372,
        148.41916687, 2105.26510004, 1205.69047674,  940.11964291,
       1723.53383374, 2176.94633674,  625.68508642,  972.67681287,
        366.04309072, 1211.12909017, 1214.22596517, 1435.03123029,
        286.96444901, 1389.14739511,  355.54873815,  441.61158445,
        317.82161747,  857.62514157, 1256.98756631,  444.70303541,
        216.60554352,  612.64898908,  818.86029216, 1717.37591714,
       1370.64334736, 1922.42502979,  845.72405701, 1222.69335574,
       1716.17446625,  577.75103286, 2201.75731109, 1522.89901534,
        399.21556416, 1597.48271725, 1873.03422816,  585.18160067,
        698.04115442, 1426.67586422, 1165.95294564])}

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.base.LinearRegression'>, 'param': {'normalize': 'False'}}, 'score': 858.3295962341517, 'residual': <matplotlib.axes._subplots.AxesSubplot object at 0x00000247EE3CAB88>, 'pickle_file': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
         normalize='False'), 'y_pred': array([ 517.49520864, 1272.91932086,  231.33455156,  639.56374068,
       1675.14513955, 2007.33163658, 1347.96145121,  495.4828504 ,
       1835.23501764, 1508.0513293 , 1802.21648028, 1053.79630023,
       1625.11705265, 1765.19569597, 1672.14345434,  382.419374  ,
       1299.93448779, 1012.77326897, 1467.02829804, 1405.99403202,
       1360.96875381,  697.59632149, 1456.02211892, 1979.31590791,
        451.45813393, 1988.32096356, 1421.00245809, 1246.90471567,
        779.64238401, 1078.81034368,  945.73563252, 1352.9642599 ,
       1787.20805421, 1906.27490104, 2011.33388353, 2185.43162595,
       1378.97886509, 1580.09177444,  758.63058751, 1972.31197575,
       1845.24063502, 1459.02380413, 1192.87438182,  450.45757219,
        653.57160501, 2201.44061376,  424.442967  , 1622.11536743,
       1826.22996199,  800.6541805 , 1444.01537806,  524.49914081,
       1018.7766394 , 2060.36140869, 1558.0794162 , 1990.32208703,
       2021.33950091, 1443.01481633, 1836.23557937, 1827.23052373,
       1689.15300388, 1497.04515018, 1764.19513424, 1317.94459907,
       1338.95639557,  351.40196013, 1830.23220895,  877.69743433,
        852.68339088, 2245.46533023,  764.63395794,  375.41544184,
        587.5345303 ,  322.38566972, 1565.08334837,  372.41375662,
       2095.38106953,  994.76315768,  669.58059282,  243.34129242,
       2101.38443995, 2119.39455124, 2195.43724333,  290.36769411,
       1243.90303046, 1523.05975537, 1695.15637431, 2199.43949028,
       1727.17434993,  552.51486947, 1335.95471036, 1145.84798013,
        844.67889698, 2237.46083633, 1168.8609001 , 2099.38331648,
        783.64463096,  251.34578632, 1019.77720113, 1604.10525615,
       1169.86146184, 1670.14233086, 1179.86707922, 2086.37601388,
       1059.79967066, 1818.22546809, 1828.23108547, 1114.83056625,
        416.4384731 ,  695.59519801,  481.47498607, 1680.14794824,
       1337.95583383, 1062.80135587, 1700.159183  ,  625.55587635,
        337.39409579,  261.3514037 , 1418.00077287,  793.65024834,
       1504.04908235, 1503.04852061,  357.40533055, 2168.4220764 ,
        714.60587103,  257.34915675,  533.50419645,  974.75192292,
        185.30871161, 2125.39792167,  615.55025897, 1617.11255874,
       2066.36477912, 1579.0912127 ,  551.51430773,  282.3632002 ,
        590.53621552,  575.52778945,  419.44015831, 1777.20243683,
        954.74068816, 1069.80528804, 1116.83168972,  384.42049748,
       1644.12772567, 1142.84629491, 1677.14626303,  478.47330086,
        986.75866378, 2139.405786  ,  407.43341746,  198.31601421,
        221.32893418, 1194.87550529, 1204.88112267, 1949.29905577,
        836.67440307,  147.28736557, 1999.32714267, 1106.82607234,
       1186.87101139, 1767.19681945,  475.47161564, 1521.05863189,
       1464.02661282,  215.32556375, 1270.91819738, 1812.22209766,
       2020.33893917, 2016.33669222, 2192.43555812, 1952.30074099,
        222.32949592, 1693.15525083, 1085.81427585, 1820.22659157,
       1786.20749247,  596.53958594,  296.37106453, 1310.9406669 ,
       1255.90977131, 1312.94179038,  791.64912486, 1486.03897106,
       1732.17715862, 1182.86876444,  857.68619957, 2220.45128678,
        578.52947466, 1621.1148057 ,  343.39746622, 1221.89067222,
        970.74967597,  433.44802264, 1865.25186978,  971.75023771,
       2018.3378157 , 1189.8726966 ,  777.64126053,  217.32668723,
       2132.40185383, 2149.41140338, 1095.81989323, 1014.77439244,
       1683.14963345, 1081.81202889, 1488.04009454,  910.71597169,
       1056.79798544, 1400.99122333,  979.75473161, 2109.38893386,
       1003.76821333,  417.43903484,  319.38398451,  942.73394731,
        535.50531992,  494.48228866, 1021.77832461, 1364.97100076,
       1721.1709795 , 1753.18895512,  518.49577038, 1231.8962896 ,
        756.62946403, 1909.27658625,  604.54407985, 1216.88786353,
       1446.01650154, 1097.8210167 ,  854.68451436, 1668.14120738,
       1954.30186446,  238.33848373,  477.47273912, 1932.28950623,
        224.33061939,  915.71878038,  588.53509204,  208.32163159,
       1393.98729116,  610.54745028,  851.68282914,  981.75585509,
        699.59744496,  633.56037025,  400.42948529,  440.45195481,
       1586.09514486, 1679.1473865 , 1610.10862658, 1101.82326365,
        827.66934743,  892.7058604 , 1515.05526146,  283.36376194,
       2113.39118081, 2236.46027459,  160.29466816,  246.34297763,
       1431.00807547,  380.41825053, 1730.17603514,  446.45532524,
        956.74181164, 1956.30298794,  599.54127116, 1214.88674005,
       1054.79686197, 1776.20187509, 1359.96819207,  899.70979257,
       1692.1546891 , 1899.27096887,  256.34859501,  264.35308892,
       1924.28501232,  820.66541527,  626.55643809,  505.48846778,
        563.52104859, 1715.16760907, 2165.42039119,  624.55531461,
       1951.30017925,  995.76371942,  848.68114393,  406.43285572,
       1136.84292449,  258.34971849,  980.75529335, 1355.96594512,
       1084.81371411, 2107.38781038,  174.30253249, 1303.93673474,
       2122.39623645,  632.55980851, 1600.1030092 , 2240.46252154,
       1441.01369285,  831.67159438, 1120.83393668, 1863.2507463 ,
       1627.11817612,  338.39465753,  858.68676131, 1607.10694136,
        728.61373537, 1882.26141932,  472.46993043,  874.69574912,
        936.73057688,  293.36937932,  846.68002045,  767.63564315,
        212.32387854, 1450.01874849, 1718.16929429, 1860.24906109,
        180.30590292, 2012.33444527,  937.73113862, 1788.20861595,
       2085.37545215, 1833.23389416, 1264.91482695, 1061.80079413,
        415.43791136, 1929.28782101,  557.51767816,  780.64294574,
       1848.24232023, 1545.07211361, 1984.3187166 ,  497.48397388,
       1144.84741839,  694.59463627, 1160.8564062 , 1518.05694668,
       1796.21310985, 1997.3260192 ,  448.45644872,  881.69968129,
       1323.9479695 , 2004.32995136, 1445.0159398 , 1640.12547872,
       1225.89291917,  391.42442965, 2001.32826615, 1585.09458313,
       2031.34511829, 1362.96987728, 1331.9524634 , 1548.07379882,
        411.43566441,  842.6777735 ,  712.60474756,  393.42555312,
        303.3749967 ,  592.53733899, 1377.97830335, 2092.37938431,
       1483.03728585, 1981.31703139, 1032.78450373,  464.46543652,
        192.31264378,  560.51936338, 1784.206369  , 1412.99796418,
       1284.92606172, 2019.33837744, 1549.07436056, 1462.02548935,
       2015.33613048,  461.46375131, 1911.27770973, 1867.25299325,
        654.57216675, 2124.39735993,  726.61261189,  920.72158907,
        149.28848904, 2103.38556343, 1206.88224615,  943.73450904,
       1726.17378819, 2172.42432336,  636.56205547,  975.75248466,
        366.4103862 , 1210.8844931 , 1215.88730179, 1457.02268066,
        277.36039151, 1381.9805503 ,  355.40420708,  431.44689917,
        310.37892887,  849.68170567, 1248.90583915,  452.45869567,
        228.33286635,  618.55194418,  818.66429179, 1714.16704733,
       1372.97549466, 1921.28332711,  830.67103265, 1229.89516612,
       1720.17041776,  583.53228335, 2203.44173723, 1536.06705796,
        388.42274443, 1588.09626834, 1870.25467847,  600.5418329 ,
        707.60193887, 1425.00470504, 1157.85472098])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'param': {'criterion': 'mse', 'max_depth': 6, 'max_features': 1, 'n_estimators': 14}}, 'score': 941.3077588719375, 'residual': <matplotlib.axes._subplots.AxesSubplot object at 0x000001F2B5619C48>, 'pickle_file': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=6,
           max_features=1, max_leaf_nodes=None, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=14, n_jobs=None, oob_score=False,
           random_state=None, verbose=0, warm_start=False), 'y_pred': array([1317.9131318 , 1905.7289184 ,  511.48511201, 1965.70439305,
        449.35559155, 1050.4329238 , 1748.93366528,  151.05234958,
        673.24673701, 2175.15118373,  691.55762149, 1845.56492725,
       1664.26373493, 1119.25095812, 2074.9470799 ,  582.73701797,
       2236.51683202,  349.80097915,  355.75834938,  850.61374015,
        355.75834938, 1702.96909913, 1377.6641272 ,  870.98281348,
       1188.21209498, 1188.21209498, 1273.01591483,  936.72450604,
       1980.58651567, 1481.53613174,  716.5896343 ,  574.5241583 ,
        634.45333111,  589.51128267,  852.19492241, 1845.56492725,
       1650.40792461, 1475.3530439 ,  850.61374015, 1133.46680518,
        967.63390168, 1400.22987637,  515.47253198,  252.85198316,
       1599.86323863, 1722.14763174, 1192.62613268,  208.38781383,
        187.00278886, 2117.31688607, 2095.83912238, 2046.16507001,
       1595.01200209,  613.60628747, 1271.63191775, 1192.62613268,
       1228.48657288,  850.61374015,  929.38486432, 1141.21026009,
        808.25492029,  449.35559155, 1845.56492725, 1772.8424682 ,
       1368.58489907, 1650.40792461, 1195.79295468,  969.86052506,
       1931.21269059, 2224.78189206, 1682.722028  , 1188.21209498,
        852.19492241, 1600.42147544,  449.35559155, 1842.28979497,
       1317.9131318 , 2236.51683202, 1748.93366528,  281.00266103,
       1192.62613268, 2095.83912238,  233.42653941, 1772.8424682 ,
       2202.09600574,  694.21635165, 1143.79325329,  929.38486432,
        543.90209736,  690.94563427,  929.38486432,  401.05832633,
        490.09978402, 1566.2536286 , 2236.51683202,  894.56737328,
       1395.24355366, 1435.5989435 , 1344.48647774, 1702.96909913,
        515.47253198, 1117.17493771,  309.45582926,  659.88082665,
       2199.03201765,  212.84787653, 2117.31688607,  852.19492241,
       1591.08255312, 1190.60629141,  483.75823885, 1883.68419482,
       1808.30100812, 1016.86072582,  760.69401821, 1344.48647774,
       1912.71319999, 1722.14763174, 1225.18232118,  412.38123658,
       1271.63191775,  659.88082665, 1772.8424682 ,  670.2022652 ,
       1449.42522374,  608.50558446,  691.55762149, 1277.13694373,
       1157.19229726, 1637.21714779,  967.63390168, 1368.58489907,
       2175.15118373, 1746.45652242, 1395.24355366, 2044.61546683,
       1475.3530439 ,  147.54569475, 1222.25217898,  894.56737328,
       2042.3159318 ,  691.55762149, 2044.61546683, 1342.6096193 ,
       2085.7643227 ,  686.77521302,  147.54569475, 2217.09097936,
       1451.83955015, 1810.74297998, 1435.5989435 , 1557.81658518,
       1882.29038275, 1637.21714779,  929.38486432,  540.19411474,
       1971.94802114,  909.85321904,  522.72844754, 1122.04157507,
        909.85321904,  808.25492029,  233.42653941, 2038.49404535,
        483.75823885,  515.47253198, 2224.78189206, 1746.45652242,
       1117.17493771,  626.37956165,  288.60294368, 1653.69384429,
       1905.7289184 ,  778.98381938, 1655.36628296,  621.47638095,
       2042.3159318 ,  613.60628747,  808.25492029, 2099.56531285,
       1650.40792461, 1424.21790175,  909.85321904,  963.80344533,
       1568.2545061 ,  826.43374503,  801.93112967,  929.38486432,
        281.00266103, 1937.97156444, 2139.30241283, 1042.59885354,
        850.61374015,  781.19300306, 2184.63989435, 1317.9131318 ,
       1518.65571697,  778.98381938,  233.42653941,  929.38486432,
        909.85321904,  270.65164689, 1892.94005486, 1791.30320135,
       1368.58489907, 1428.3757799 ,  314.97577431,  741.94377146,
       1746.45652242, 1600.42147544,  659.88082665,  330.5102322 ,
        870.98281348,  781.19300306, 2139.30241283,  766.79380776,
        951.92432914, 1722.14763174,  449.35559155, 1690.11468426,
        686.77521302, 1883.68419482,  506.33681587, 2139.30241283,
       1451.83955015, 1117.17493771, 1905.7289184 ,  766.79380776,
       1937.97156444,  658.23026764, 1772.8424682 ,  483.75823885,
       1271.63191775, 1225.18232118,  634.45333111, 1141.21026009,
        894.56737328,  957.81563441, 1157.19229726, 1937.97156444,
        778.98381938, 1141.21026009, 2175.15118373,  508.04860408,
       1564.07960263,  760.69401821, 2139.30241283, 1016.86072582,
       1222.25217898,  585.60844654, 1879.08451991,  585.60844654,
        309.45582926,  233.42653941,  147.54569475,  701.99154043,
        967.63390168, 2139.30241283,  550.38056661,  690.94563427,
       1458.65372866,  990.32449128,  457.20243148, 2180.03330594,
        157.73051177, 1650.40792461, 1446.06317732,  394.96826608,
        479.8933579 , 1810.74297998,  355.75834938, 1892.94005486,
       1746.45652242, 2199.03201765,  691.55762149, 1980.58651567,
       1319.30429342,  349.80097915,  355.75834938, 1690.11468426,
       1587.63475092,  511.48511201,  582.73701797, 1924.19875561,
       2236.51683202, 2095.83912238, 1098.2530437 ,  909.85321904,
       1862.61384708, 1323.50608351,  270.65164689,  212.84787653,
        483.75823885, 1323.50608351,  720.40812169,  870.98281348,
       1937.97156444, 1640.71986291, 2224.78189206,  433.65441436,
        171.62170875, 1057.37449909, 1959.34143009, 1042.59885354,
        314.97577431,  449.35559155,  850.61374015, 1746.45652242,
        634.45333111, 1882.29038275, 2074.9470799 , 2115.30498131,
       1971.94802114,  550.38056661, 2006.96480082, 1587.63475092,
       1344.48647774, 1854.47322035, 1344.48647774,  355.75834938,
       1941.40828246,  401.05832633, 1970.29316999,  543.90209736,
       1395.24355366, 1845.56492725,  872.76691659, 1057.37449909,
        781.19300306,  490.09978402,  929.38486432, 1262.84714669,
        858.82130865, 1269.67980736, 2002.08413188, 1772.8424682 ,
        613.60628747,  433.65441436, 1702.96909913, 1475.3530439 ,
       1883.68419482, 2224.78189206,  909.85321904, 2072.46340643,
        203.16683068, 1615.07002586, 1929.49191137, 1812.96107004,
       2042.3159318 , 2188.80247938,  394.96826608,  749.32334512,
       2006.96480082,  355.75834938, 2236.51683202,  688.59664159,
        192.97159505, 1697.26553588,  401.05832633,  707.79276022,
       1057.37449909,  340.82944291, 2116.10077406,  695.76094039,
        596.20309007, 1442.68836628, 2095.83912238,  433.65441436,
        401.05832633, 1098.2530437 ,  212.84787653, 1599.86323863,
        449.35559155,  314.97577431, 1722.14763174,  876.83946237,
        212.84787653,  967.63390168,  449.35559155, 1791.30320135,
       1650.40792461, 2042.3159318 ,  394.96826608, 1264.41020976,
       1650.40792461,  967.63390168, 1941.40828246, 1395.24355366,
       2212.82135969, 2139.30241283, 2006.96480082, 1517.70968522,
        766.79380776, 1155.00450611,  894.56737328,  865.7192397 ,
        585.60844654, 1791.30320135,  781.19300306,  314.97577431,
        574.5241583 , 1225.18232118, 1098.2530437 , 1599.86323863,
        171.62170875,  369.47588649, 1316.46194133, 1477.51538156,
        852.19492241,  159.87353698, 2224.78189206, 2004.89008426,
       1722.14763174, 1395.24355366, 2044.61546683, 1931.21269059,
       1424.21790175, 1057.37449909, 2042.3159318 ,  511.48511201,
        349.80097915, 2118.72406743, 1225.18232118])}

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.base.LinearRegression'>, 'param': {'normalize': 'True'}}, 'score': 858.0843846482097, 'residual': <matplotlib.axes._subplots.AxesSubplot object at 0x000001F2B5619C48>, 'pickle_file': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
         normalize='True'), 'y_pred': array([1322.12902959, 1904.155991  ,  507.09127434, 1961.15863156,
        447.08849481, 1046.11624376, 1752.14894954,  154.07492145,
        679.09924232, 2173.16845255,  715.10091003, 1851.15353576,
       1673.14528982, 1106.11902329, 2075.16391266,  579.09460977,
       2246.17183431,  339.08349166,  356.08427919,  834.10642276,
        357.08432552, 1707.14686489, 1381.13176279,  874.10827578,
       1184.12263667, 1182.12254402, 1283.12722289,  936.11114796,
       1983.15965072, 1488.13671961,  729.10155859,  570.09419284,
        639.0973893 ,  597.09544363,  845.10693234, 1850.15348943,
       1647.14408536, 1476.13616371,  835.10646909, 1135.12036673,
        966.11253772, 1409.1330599 ,  519.09183024,  258.0797393 ,
       1615.14260295, 1718.14737447, 1198.12328523,  213.07765465,
        194.07677447, 2107.16539507, 2093.16474652, 2052.16284717,
       1601.14195439,  613.09618484, 1279.12703759, 1203.12351686,
       1240.1252309 ,  842.10679337,  929.11082368, 1142.12069101,
        806.10512565,  456.08891174, 1846.15330413, 1763.14945912,
       1369.13120688, 1649.14417801, 1206.12365583,  984.11337158,
       1926.15701017, 2235.17132473, 1679.14556778, 1185.122683  ,
        854.10734927, 1609.14232499,  444.08835584, 1832.15265557,
       1325.12916856, 2245.17178799, 1753.14899586,  281.08080479,
       1201.12342421, 2099.16502447,  249.07932237, 1770.14978339,
       2214.1703519 ,  705.10044678, 1144.12078366,  920.11040675,
        533.0924788 ,  693.09989087,  925.11063838,  397.08617854,
        491.09053313, 1564.14024035, 2248.17192696,  891.10906332,
       1389.13213339, 1431.13407906, 1350.1303267 , 1704.14672591,
        517.09173759, 1111.11925492,  292.08131437,  661.09840846,
       2209.17012027,  222.07807158, 2108.1654414 ,  849.10711765,
       1599.14186174, 1194.12309993,  486.0903015 , 1881.15492552,
       1800.15117316, 1018.11494665,  745.1022998 , 1351.13037303,
       1908.15617631, 1717.14732814, 1237.12509192,  406.08659547,
       1275.12685229,  657.09822316, 1768.14969074,  678.09919599,
       1447.13482027,  611.09609219,  714.10086371, 1289.12750085,
       1151.12110793, 1628.14320518,  971.11276935, 1366.13106791,
       2184.16896213, 1745.14862526, 1408.13301358, 2062.16331043,
       1475.13611738,  148.0746435 , 1214.12402644,  892.10910964,
       2032.16192066,  713.10081738, 2057.1630788 , 1348.13023405,
       2080.16414429,  687.09961292,  149.07468982, 2221.17067618,
       1449.13491292, 1803.15131213, 1430.13403274, 1553.13973077,
       1878.15478654, 1626.14311253,  922.1104994 ,  524.09206187,
       1978.15941909,  899.10943392,  522.09196922, 1134.1203204 ,
        902.1095729 ,  808.1052183 ,  244.07909074, 2019.16131843,
        485.09025518,  516.09169127, 2226.1709078 , 1742.14848628,
       1121.11971817,  625.09674074,  287.08108274, 1654.14440964,
       1902.15589835,  775.10368956, 1666.14496555,  621.09655544,
       2033.16196699,  615.09627749,  810.10531095, 2085.16437591,
       1634.14348313, 1417.13343051,  906.1097582 ,  956.11207447,
       1572.14061095,  826.10605216,  797.10470872,  928.11077736,
        276.08057316, 1935.15742709, 2135.16669219, 1026.11531725,
        836.10651541,  789.10433812, 2193.16937906, 1321.12898326,
       1521.13824835,  779.10387486,  247.07922972,  921.11045308,
        905.10971187,  260.07983195, 1892.1554351 , 1785.15047828,
       1363.13092893, 1424.13375478,  325.08284311,  737.10192919,
       1746.14867158, 1607.14223234,  659.09831581,  330.08307473,
        876.10836843,  781.10396751, 2139.16687749,  765.10322631,
        944.11151856, 1719.1474208 ,  458.08900439, 1689.14603103,
        692.09984455, 1888.1552498 ,  494.09067211, 2150.16738707,
       1454.13514455, 1109.11916227, 1905.15603733,  767.10331896,
       1937.15751975,  653.09803786, 1765.14955177,  481.09006988,
       1269.12657434, 1228.12467499,  640.09743562, 1140.12059835,
        887.10887801,  948.11170387, 1155.12129324, 1940.15765872,
        780.10392119, 1136.12041305, 2183.16891581,  504.09113536,
       1568.14042565,  749.1024851 , 2145.16715544, 1011.11462237,
       1225.12453602,  586.09493405, 1862.15404534,  583.09479507,
        298.08159232,  241.07895177,  146.07455085,  719.10109534,
        979.11313996, 2140.16692381,  560.09372959,  700.10021515,
       1465.13565413,  996.11392749,  473.08969927, 2189.16919376,
        165.07543103, 1645.14399271, 1444.13468129,  385.08562263,
        474.0897456 , 1821.15214599,  352.08409389, 1891.15538877,
       1751.14890321, 2205.16993497,  716.10095636, 1988.15988234,
       1309.12842736,  340.08353799,  355.08423287, 1690.14607736,
       1581.14102788,  508.09132066,  580.0946561 , 1917.15659324,
       2243.17169534, 2096.16488549, 1096.11856003,  903.10961922,
       1856.15376738, 1330.12940019,  259.07978563,  232.07853484,
        482.0901162 , 1335.12963182,  730.10160492,  875.10832211,
       1939.1576124 , 1631.14334415, 2225.17086148,  423.087383  ,
        169.07561633, 1061.11693864, 1958.15849258, 1037.11582683,
        312.08224087,  467.08942132,  844.10688602, 1743.14853261,
        642.09752828, 1879.15483287, 2074.16386633, 2115.16576568,
       1975.15928011,  558.09363694, 2000.16043825, 1589.14139849,
       1356.13060465, 1853.15362841, 1353.13046568,  353.08414022,
       1950.15812198,  399.08627119, 1970.15904849,  531.09238615,
       1402.13273562, 1839.15297985,  879.10850741, 1052.11652171,
        785.10415282,  489.09044048,  918.1103141 , 1251.12574048,
        864.10781253, 1267.12648169, 2010.1609015 , 1772.14987604,
        612.09613851,  420.08724402, 1702.14663326, 1483.13648799,
       1880.15487919, 2228.17100045,  909.10989717, 2071.16372736,
        209.07746935, 1624.14301988, 1925.15696384, 1824.15228497,
       2022.16145741, 2197.16956436,  383.08552998,  744.10225347,
       1999.16039192,  358.08437185, 2244.17174166,  683.09942762,
        199.0770061 , 1698.14644796,  395.08608589,  724.10132696,
       1070.11735557,  335.08330636, 2116.165812  ,  702.1003078 ,
        606.09586056, 1437.13435702, 2094.16479284,  431.0877536 ,
        398.08622486, 1095.11851371,  235.07867381, 1620.14283457,
        455.08886542,  309.0821019 , 1721.14751345,  883.10869271,
        217.07783996,  963.11239875,  442.08826318, 1791.15075623,
       1637.14362211, 2034.16201331,  384.08557631, 1255.12592578,
       1638.14366843,  972.11281568, 1945.15789035, 1400.13264297,
       2218.1705372 , 2131.16650688, 2005.16066988, 1533.13880426,
        757.1028557 , 1149.12101528,  884.10873904,  867.1079515 ,
        581.09470242, 1787.15057093,  787.10424547,  307.08200925,
        571.09423917, 1235.12499927, 1098.11865269, 1618.14274192,
        178.07603326,  374.08511305, 1315.12870531, 1470.13588576,
        856.10744192,  167.07552368, 2223.17076883, 2014.16108681,
       1725.14769875, 1401.1326893 , 2060.16321778, 1927.15705649,
       1420.13356948, 1066.11717027, 2021.16141108,  510.09141332,
        336.08335269, 2119.16595098, 1229.12472132])}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'param': {'criterion': 'mae', 'max_depth': 6, 'max_features': 2, 'n_estimators': 16}}, 'score': 991.8533150353771, 'residual': <Figure size 640x480 with 1 Axes>, 'pickle_file': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=6,
           max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=16, n_jobs=None, oob_score=False,
           random_state=None, verbose=0, warm_start=False), 'y_pred': array([ 646.27289433,  126.09624892,  699.43079613, 2191.7138955 ,
       2156.20494791, 1704.18942301, 2256.49364898, 1537.25230057,
        810.89298432, 1222.44204634, 2038.58351082,  549.279393  ,
       1527.44346625,  769.62163686,  843.53059039, 1646.35813166,
       2237.22109295, 2131.51537895,  315.83345267, 1923.69766597,
        322.24212003, 1716.72157638, 1288.53526161,  456.22300655,
       1389.15116927, 2204.48507559, 1196.24311015, 1565.87987572,
       1995.2533451 ,  690.13307893, 1917.82459865,  512.43081313,
       1521.03898534, 1871.80390064, 1750.987895  , 1273.71308926,
       2091.60268057, 2145.35256556, 1275.39707364, 1351.17507874,
       1440.77690546, 1786.93962005, 1565.87987572, 2040.25563924,
        355.23721473,  208.69660363, 2200.8236475 , 1117.000545  ,
       1062.2301978 , 2040.04689465,  589.88993576, 1062.2301978 ,
        887.7047587 , 2040.04689465, 1426.80838086, 1122.47653538,
       1521.03898534, 2038.58351082,  973.68132153, 1159.33748427,
        646.27289433, 1659.73454829, 1592.57909772, 1878.98675034,
       2171.99903941,  550.67225014,  883.57127354, 1467.93510508,
        546.5887044 , 1635.88083924, 1426.80838086,  280.70441811,
        457.22647877, 2037.85147258, 1812.07125453,  764.4863348 ,
        764.4863348 ,  427.90415893, 1963.74310872,  700.79481128,
       1525.18390429,  221.02896026, 1151.16281492,  207.03707982,
       2256.49364898, 1044.18979605, 2038.58351082,  810.89298432,
       1118.14711711, 1275.39707364, 1182.71323667, 1521.03898534,
        584.51900779, 1543.1807426 ,  835.92286856, 1949.46373415,
       1351.17507874,  883.45275664, 1949.46373415,  673.98972754,
       1344.3817709 ,  983.91347668,  252.5456746 ,  969.57966923,
       1275.39707364,  881.84290816,  201.98164451, 1312.00904764,
        839.72055286, 1330.12753276,  355.23721473,  584.51900779,
        409.91243157,  843.53059039, 1004.87681863, 1618.74033899,
       2218.42769227,  700.79481128,  280.70441811, 1312.00904764,
        243.58236458, 1457.32541622,  769.62163686, 1834.6817747 ,
        537.4240452 , 2141.90596529, 2005.037212  , 1041.98119215,
        429.35515808,  810.89298432, 1646.35813166, 2171.99903941,
       2141.90596529,  646.27289433, 1028.78001961, 1565.87987572,
       1592.57909772, 1521.03898534, 1796.42515162,  427.90415893,
        247.58248713, 1389.15116927,  932.13589498, 1196.24311015,
       2128.71082209, 1440.77690546,  883.57127354,  971.30410105,
        843.53059039,  460.92481102, 1812.07125453,  350.11982858,
        980.02334425, 2245.78384212, 1389.15116927, 1011.40386111,
       1839.13829943, 1008.00281069, 2073.56650011, 1182.71323667,
        883.45275664,  971.30410105, 1097.9775149 , 1909.92401998,
       1516.88066898, 2200.8236475 ,  932.13589498, 1278.67589858,
        724.67482964, 1494.51863068, 1118.14711711, 1900.29167142,
       1993.3644036 , 2141.90596529, 1836.79187086, 1089.94338738,
       2194.27968498,  427.90415893,  724.67482964, 1163.83972509,
       1159.33748427, 1963.74310872, 1258.59431895, 1316.41442256,
        163.46444232, 1441.87392201, 2089.49665378, 1607.31799154,
       2056.62151477, 1031.82064461,  894.07312361,  504.07903273,
        327.05306966,  622.65304336, 1761.96336379, 1062.2301978 ,
        935.42929314,  507.63407933, 1716.72157638, 2171.99903941,
       1991.04735419,  745.32201791, 1182.71323667,  843.53059039,
       1777.05590156, 1885.08818597, 1713.28058687,  769.62163686,
       1523.21914026,  911.91467984, 2233.85262137, 2131.51537895,
       2145.35256556, 1648.24321608,  810.89298432, 2038.58351082,
        465.81572204, 1836.79187086, 1964.70248372,  765.98735579,
       1338.95596412, 1151.16281492,  208.8617593 ,  765.98735579,
        355.23721473,  429.35515808,  429.35515808,  584.51900779,
       1384.05745196, 1470.85385508,  456.22300655,  247.58248713,
        577.70961443, 1592.57909772,  806.67821835, 2251.92752344,
       2131.51537895, 1949.46373415,  935.42929314, 1220.03162968,
       2094.27410341, 1521.03898534, 1461.85429799, 1646.35813166,
       2249.23645201, 2145.35256556,  163.46444232,  763.14542571,
        544.90908937,  272.8949384 , 1690.09238796,  315.83345267,
       1995.2533451 , 2091.60268057, 1273.71308926,  812.29755421,
       2153.79432198, 1748.944145  ,  153.61915793, 1273.71308926,
       1565.87987572, 1836.79187086,  350.11982858,  160.37700568,
       1062.2301978 ,  504.07903273, 1949.46373415,  429.35515808,
        504.07903273, 1521.03898534, 2005.037212  , 1923.69766597,
       1690.09238796, 2200.8236475 , 1716.72157638,  156.17124127,
        763.14542571, 1646.35813166, 1992.40000143,  795.49071278,
        193.8343592 ,  504.73242325, 1192.18548426, 2171.99903941,
       1252.16516346,  610.65052634,  965.74041816,  247.58248713,
        302.79585934,  883.57127354, 1936.32106418,  839.72055286,
        163.46444232, 1523.21914026, 1869.6504422 ,  673.98972754,
        427.90415893, 1860.82295931, 1375.71395398,  699.43079613,
        615.84710909, 1869.6504422 , 1226.21160109, 1866.34412462,
       1613.19883359,  215.67369841, 1962.41937243,  503.0894494 ,
        806.67821835, 1777.05590156, 1273.71308926, 1523.21914026,
       2038.58351082,  315.83345267, 1441.87392201, 1827.92486039,
       1441.87392201,  207.03707982, 1993.3644036 ,  574.64113499,
       1305.02189304, 1830.16249197,  206.9789468 ,  562.16071988,
        207.03707982, 2256.49364898,  610.65052634,  924.50112828,
       2202.31482397,  550.67225014, 1166.21840156, 1777.05590156,
       1441.87392201, 1926.82270364, 1923.69766597,  843.53059039,
       1871.80390064,  932.13589498, 2089.49665378, 2171.99903941,
       2207.61542707,  843.53059039, 1267.9769477 ,  839.72055286,
       2200.8236475 ,  284.79489575, 1196.24311015, 1062.2301978 ,
       2200.8236475 , 1489.19158651,  315.83345267,  839.72055286,
        340.77930223, 1752.62494565, 1239.47650868, 1264.56622247,
       1031.82064461, 1521.03898534, 1491.40497936, 2040.04689465,
        504.73242325, 2037.85147258, 1196.24311015,  881.84290816,
        758.47607057, 2171.99903941, 1117.000545  ,  932.13589498,
       1222.44204634, 1222.44204634, 1276.39197457, 2052.27857999,
       1157.25597385,  207.03707982, 1543.1807426 , 1936.32106418,
       1009.65281069,  932.13589498, 1031.82064461, 1777.05590156,
        806.67821835,  694.72484802,  280.70441811,  587.14984317,
        907.54975408, 1871.80390064,  504.73242325,  163.46444232,
        207.03707982, 2200.8236475 , 2000.01676112, 1031.82064461,
        162.22483706, 2153.79432198, 2256.49364898, 1351.17507874,
        907.54975408,  350.11982858, 1426.80838086, 1011.40386111,
        971.30410105,  465.81572204, 1878.98675034,  924.50112828,
       1422.0360165 , 1004.87681863, 1062.2301978 , 1182.71323667,
        522.15962326, 1318.46068788, 1182.71323667, 2131.51537895,
        163.46444232,  574.64113499, 1646.35813166,  456.22300655,
        459.54999871, 1607.31799154,  294.15678164, 1537.25230057,
       1118.14711711, 1523.21914026,  709.89549007])}

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.base.LinearRegression'>, 'param': {'normalize': 'True'}}, 'score': 888.5032645177504, 'residual': <Figure size 640x480 with 1 Axes>, 'pickle_file': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
         normalize='False'), 'y_pred': array([ 648.3779349 ,  141.18635034,  697.39645097, 2193.9617577 ,
       2158.94853194, 1697.7743298 , 2247.98216315, 1551.71915949,
        807.43801764, 1216.59257008, 2030.90016345,  552.34165853,
       1543.71613646,  777.42668127,  855.45615582, 1644.75430222,
       2232.97649497, 2118.93341678,  310.25021186, 1909.85444011,
        328.25701368, 1717.78188737, 1294.62204463,  455.30500429,
       1387.65718736, 2213.96931527, 1196.5850125 , 1567.72520555,
       1997.88769345,  687.39267218, 1903.85217284,  516.3280549 ,
       1503.7010213 , 1865.83781344, 1750.79435737, 1270.61297554,
       2091.92321406, 2147.94437527, 1282.61751008, 1356.64547312,
       1436.67570342, 1788.80871677, 1557.72142676, 2061.91187769,
        368.27212883,  235.22187095, 2207.967048  , 1127.55893886,
       1045.5279528 , 2043.90507587,  596.3582852 , 1060.53362098,
        882.46635855, 2051.9080989 , 1410.66587857, 1131.56045038,
       1508.7029107 , 2026.89865193,  982.50414643, 1153.56876371,
        647.37755702, 1665.76223767, 1593.7350304 , 1882.84423738,
       2172.95382224,  556.34317005,  877.46446916, 1473.68968494,
        543.33825763, 1627.74787828, 1421.67003524,  275.2369861 ,
        443.30046974, 2056.9099883 , 1805.81514071,  748.41572279,
        749.41610066,  414.28951126, 1972.87824648,  704.39909612,
       1542.71575858,  238.22300458, 1138.56309553,  232.22073731,
       2246.98178528, 1044.52757492, 2025.89827405,  816.44141855,
       1119.55591583, 1281.6171322 , 1175.57707705, 1497.69875403,
        587.35488429, 1553.71991525,  831.44708673, 1954.87144466,
       1353.64433948,  868.46106825, 1950.86993314,  678.38927127,
       1341.63980493,  995.50905886,  254.22905064,  963.49696673,
       1279.61637645,  874.46333552,  204.2101567 , 1300.6243119 ,
        839.45010976, 1339.63904918,  362.26986156,  591.35639581,
        402.28497671,  845.45237703, 1005.51283765, 1624.74674464,
       2221.9723383 ,  708.40060763,  265.23320731, 1301.62468978,
        243.22489398, 1459.68439464,  778.42705915, 1827.82345405,
        529.33296732, 2137.94059648, 2016.89487314, 1042.52681916,
        423.29291217,  812.43990703, 1646.75505798, 2171.95344436,
       2138.94097436,  651.37906854, 1023.51963946, 1565.72444979,
       1587.73276313, 1500.69988767, 1794.81098404,  408.28724398,
        248.22678337, 1402.66285554,  933.48563037, 1195.58463462,
       2105.92850436, 1437.6760813 ,  880.46560279,  978.50263492,
        850.45426643,  474.31218399, 1814.81854162,  346.2638155 ,
        994.50868098, 2235.97762861, 1386.65680948, 1013.51586068,
       1845.83025586, 1007.5135934 , 2078.91830163, 1180.57896644,
        865.45993461,  965.49772249, 1090.54495735, 1900.8510392 ,
       1493.69724252, 2209.96780376,  932.48525249, 1291.62091099,
        733.4100546 , 1492.69686464, 1103.54986977, 1895.84914981,
       2008.89185011, 2132.93870709, 1838.82761071, 1084.54269007,
       2194.96213558,  416.29026701,  734.41043248, 1163.5725425 ,
       1160.57140886, 1979.88089163, 1249.60504008, 1314.6296022 ,
        164.19504155, 1451.6813716 , 2085.92094678, 1605.73956494,
       2070.9152786 , 1028.52152886,  890.46938158,  492.3189858 ,
        334.25928095,  630.37113308, 1756.79662465, 1062.53437674,
        941.4886534 ,  514.32729914, 1716.78150949, 2174.954578  ,
       1989.88467042,  739.41232188, 1179.57858856,  857.45691158,
       1774.80342647, 1891.84763829, 1700.77546343,  776.42630339,
       1536.71349131,  910.47693916, 2228.97498346, 2124.93568406,
       2144.94324163, 1652.75732525,  815.44104067, 2023.8975183 ,
        484.31596277, 1833.82572132, 1970.87749072,  764.42176885,
       1340.63942705, 1142.56460705,  218.21544701,  765.42214673,
        370.27288459,  421.29215641,  417.29064489,  592.35677369,
       1382.65529797, 1469.68817342,  459.3065158 ,  253.22867276,
        583.35337278, 1576.72860646,  797.43423885, 2239.97914012,
       2122.9349283 , 1956.87220041,  940.48827552, 1211.59068068,
       2095.92472557, 1517.70631161, 1466.68703979, 1642.75354646,
       2237.97838437, 2149.94513103,  178.20033185,  752.4172343 ,
        535.33523459,  257.23018428, 1689.77130677,  317.25285701,
       2000.88882708, 2090.92283618, 1268.61221978,  821.44330794,
       2156.94777618, 1734.78831131,  152.190507  , 1271.61335341,
       1560.7225604 , 1835.82647708,  352.26608277,  159.19315215,
       1048.52908644,  491.31860793, 1955.87182254,  425.29366792,
        494.31974156, 1513.70480009, 2019.89600678, 1911.85519587,
       1690.77168465, 2199.96402497, 1724.78453253,  147.18861761,
        750.41647854, 1635.75090131, 2011.89298375,  790.4315937 ,
        200.20864519,  509.32540975, 1187.58161159, 2168.95231073,
       1242.60239493,  604.36130823,  954.49356583,  251.22791701,
        295.24454368,  878.46484703, 1936.86464284,  834.44822037,
        167.19617518, 1527.7100904 , 1860.83592405,  677.38889339,
        411.28837762, 1853.83327889, 1364.64849615,  694.39531733,
        612.36433126, 1864.83743556, 1231.59823826, 1859.83554617,
       1622.74598888,  237.2226267 , 1966.8759792 ,  495.32011944,
        799.43499461, 1763.7992698 , 1267.6118419 , 1518.70668949,
       2034.90167496,  304.24794458, 1447.67986009, 1824.82232041,
       1446.67948221,  230.21998155, 2009.89222799,  572.34921611,
       1298.62355614, 1826.82307617,  206.21091246,  566.34694884,
        223.2173364 , 2249.98291891,  601.3601746 ,  913.47807279,
       2211.96855952,  559.34430369, 1165.57329826, 1771.80229283,
       1452.68174948, 1921.85897466, 1912.85557375,  849.45388855,
       1875.84159223,  931.48487461, 2088.92208042, 2179.95646739,
       2214.96969315,  844.45199915, 1263.61033038,  840.45048764,
       2198.96364709,  282.23963125, 1198.58576826, 1051.53022007,
       2202.96515861, 1487.69497524,  327.2566358 ,  837.449354  ,
        335.25965883, 1753.79549101, 1236.60012766, 1261.60957463,
       1025.52039522, 1514.70517797, 1488.69535312, 2045.90583163,
        506.32427611, 2052.90847678, 1199.58614614,  871.46220188,
        745.41458915, 2182.95760103, 1126.55856098,  934.48600825,
       1218.59332584, 1214.59181432, 1289.62015523, 2069.91490072,
       1145.56574068,  226.21847004, 1552.71953737, 1937.86502072,
       1012.5154828 ,  927.4833631 , 1032.52304037, 1769.80153707,
        793.43272733,  690.39380581,  273.23623034,  595.35790732,
        900.47316037, 1871.84008071,  505.32389823,  165.19541943,
        222.21695852, 2201.96478073, 2015.89449527, 1029.52190674,
        161.19390791, 2154.94702042, 2245.9814074 , 1355.64509524,
        898.47240461,  342.26230398, 1411.66625645, 1015.51661643,
        964.49734461,  475.31256186, 1884.84499314,  915.47882855,
       1408.66512281, 1003.51208189, 1059.5332431 , 1173.57632129,
        524.33107793, 1321.63224736, 1176.57745493, 2119.93379466,
        168.19655306,  575.35034975, 1648.75581373,  461.30727156,
        473.31180611, 1612.7422101 ,  288.24189852, 1550.71878161,
       1109.55213704, 1526.70971252,  715.40325278])}

