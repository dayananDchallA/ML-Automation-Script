At Step: colIdentification 
Sequence executed:


At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Feature Reduction 
Sequence executed:
Null Handling with mean,  Feature Reduction with pearson,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Feature Reduction with pearson,  Outlier Handling with capping,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Feature Reduction with pearson,  Outlier Handling with capping,  Encoding with one-hot,

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Feature Reduction with pearson,  Outlier Handling with capping,  Encoding with one-hot,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestRegressor'>, 'param': {'criterion': 'mse', 'max_depth': 6, 'max_features': 1, 'n_estimators': 14}}, 'score': 974.115296733125, 'residual': <module 'matplotlib.pyplot' from 'C:\\Users\\SindhuKarnati\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py'>, 'pickle_file': RandomForestRegressor(max_depth=6, max_features=1, n_estimators=14), 'y_pred': array([ 279.78812178,  279.78812178, 2139.22987191, 1448.66564621,
        977.17869777, 1697.07479202, 1661.61176378, 1171.05808314,
        556.23330277,  299.26827653, 1906.6188031 ,  427.92471692,
        949.50290729,  452.4299437 , 1059.33653905,  778.4689399 ,
       1765.02987377,  551.75844375,  661.17693564, 1015.04349488,
       1852.99208405, 1208.30114325,  760.88746323,  681.66508619,
        964.56233783, 1425.82728988,  709.97316067,  985.19461893,
        626.82647727, 1375.40953695, 1824.30637238,  620.38842556,
        662.74437131, 1197.0074052 ,  381.03343772,  507.78722226,
        560.92782197,  165.5238859 , 1931.67696322, 2139.22987191,
        560.92782197, 1068.72556888,  164.67882034, 1754.7547698 ,
        367.20329616, 1227.35808488,  759.72079657,  400.91648703,
       1428.33869445,  870.73390919, 1902.41130838, 2098.43535103,
       1938.24018873,  681.66508619,  949.50290729, 1914.29971755,
       1279.51172332, 1009.10467352, 2084.66834434,  341.28361715,
       1870.22752367, 1784.19253322,  623.56520568,  895.8397594 ,
       1567.80374019, 2104.5006616 , 1177.90261361,  599.82433106,
       1571.33862391, 1278.51883525, 1754.7547698 , 1299.97117019,
       1211.77068799, 1030.62125663,  623.56520568, 2038.95902244,
       1643.49536287,  584.79161074, 1879.87251267, 1971.45193684,
        919.01630856,  964.56233783, 1197.0074052 ,  678.52081927,
        164.67882034, 1201.55702767,  236.49865973, 1466.95868902,
        352.93663149,  511.29930482,  760.88746323, 1852.99208405,
        987.31883662, 1230.00075649, 1644.90679144,  282.88330595,
       1848.92373671, 1691.68723533,  511.29930482, 2183.4096369 ,
       1518.56525178,  701.09805344, 1201.55702767, 1883.97045493,
        215.87209745, 1115.84456895, 1469.47150953,  703.09820133,
        599.82433106, 1313.01567696, 2040.49711768,  410.11045423,
        400.91648703, 1611.2242772 , 1807.73234792,  507.03007287,
       1012.09827471,  408.08605121,  236.49865973, 1754.7547698 ,
        478.34794282, 1520.64652376, 1068.72556888,  989.55976632,
        949.50290729, 2216.36180825, 1971.45193684, 1059.33653905,
        897.42633948, 1968.41006184, 1324.19761745,  278.04475443,
       1161.79136053,  166.66971924, 1914.29971755, 1657.70411967,
        478.34794282,  452.4299437 ,  705.95044222, 1715.33096251,
        926.94387713,  945.56689538, 1115.84456895, 1520.02669659,
       1313.01567696, 1275.65375589,  312.65960984, 2038.95902244,
       1999.3482825 , 1449.92915161, 1197.0074052 ,  197.02962749,
        320.22330345,  236.49865973,  623.56520568,  212.92445506,
        570.40087446, 1757.19308782, 1859.4112968 , 1577.35926752,
       1586.29614065, 1516.85477559,  759.72079657,  303.69669915,
       1852.99208405, 1611.2242772 ,  891.89113291, 1208.30114325,
       1899.9341713 ,  623.56520568, 1765.02987377, 1920.81214652,
       1289.8372294 , 2217.9860669 , 1928.35571395, 2081.98896733,
       1227.35808488, 1999.3482825 , 2190.68652259, 1691.68723533,
        935.97077182, 2120.91457265, 2208.27431964, 2193.33832342,
       1715.33096251, 1073.36911284, 2131.81341754,  408.08605121,
        299.26827653, 1571.33862391, 1765.02987377, 1792.74489644,
        208.40870053,  357.94662072,  214.66138316, 1824.30637238,
        357.94662072,  212.92445506,  864.7340561 ,  584.79161074,
       1588.91509168, 1043.98682529,  874.16570268, 2084.66834434,
        166.66971924, 1754.7547698 ,  530.83139123, 1773.93924373,
        623.56520568,  949.50290729, 2026.70098445,  874.16570268,
        864.7340561 , 1161.79136053, 1886.03364863, 1774.83720292,
       1588.91509168, 2139.22987191, 1009.10467352, 1466.95868902,
        212.92445506, 1889.86606573, 1430.395471  , 1313.01567696,
        397.33919361,  338.90119957, 1983.16343616, 1774.83720292,
       1199.32513919,  847.21130819, 1951.3692394 , 1387.64227247,
        506.59549294,  478.34794282,  807.94793326,  513.66605152,
       1792.74489644,  236.49865973, 2217.9860669 ,  847.21130819,
        198.73244134, 1257.91409671, 1279.51172332,  427.92471692,
       1931.67696322,  584.79161074, 1207.04624597,  397.33919361,
        556.23330277,  452.4299437 ,  949.50290729, 1774.83720292,
       2217.9860669 ,  372.9531113 ,  506.4528996 , 1636.94736698,
        891.89113291, 1870.22752367,  705.95044222,  584.79161074,
        312.65960984, 1643.49536287, 1314.09059932, 1709.40337801,
        945.56689538, 1448.66564621,  400.91648703, 1774.83720292,
        408.08605121, 1203.03249664,  807.94793326,  352.93663149,
       1889.86606573, 1879.87251267, 1197.0074052 ,  845.12583604,
       1999.3482825 , 1266.02800309,  351.13113429, 1279.51172332,
       1981.04340815,  354.33799204,  844.97321295,  452.4299437 ,
       2081.98896733, 1257.91409671,  312.65960984,  236.49865973,
       2081.64372923, 1522.12753692,  584.79161074,  845.12583604,
        666.21167656,  556.23330277, 1466.95868902,  197.02962749,
       1577.35926752,  513.66605152, 2216.36180825, 2104.5006616 ,
        845.12583604, 1350.57768819, 1471.67961393, 1478.53353515,
       1607.2226308 , 1657.70411967,  989.55976632, 1807.73234792,
       1999.3482825 , 1316.45558531, 2051.18465433, 2083.14372923,
       1378.46645087,  889.8316091 ,  199.73424509, 2140.60994652,
       1266.02800309,  559.44482877,  579.67905122,  623.56520568,
       1940.2664613 , 1920.81214652, 1573.94973502, 1324.19761745,
       1699.98304325, 1971.45193684,  760.88746323, 1774.83720292,
       2099.85085057, 1324.19761745, 2120.91457265, 1657.70411967,
        301.40160987, 1278.51883525, 1938.24018873, 1115.84456895,
       1018.08894943, 1287.62764102,  681.66508619,  164.67882034,
       1043.98682529, 1338.4936593 ,  372.9531113 ,  506.59549294,
       1177.90261361, 1260.13714811,  937.26362897, 1059.33653905,
       1792.74489644, 1914.29971755, 1694.71943487,  560.92782197,
        559.44482877, 1644.90679144,  279.78812178, 1115.84456895,
       1514.41071046, 2042.51260219,  759.72079657,  312.65960984,
       2190.68652259,  491.0589258 , 1324.19761745, 1879.87251267,
        664.80884255, 1375.40953695,  897.42633948, 2188.67661942,
       1477.19911956,  844.97321295, 1313.01567696, 1754.7547698 ,
        164.67882034, 1852.99208405,  197.02962749,  534.96164333,
       1100.54683872,  897.42633948,  864.7340561 ,  989.55976632,
       1462.10486347, 1938.24018873, 1571.33862391, 1264.22264595,
        953.50869017, 1279.51172332, 2216.36180825,  312.65960984,
       1520.64652376, 1277.47518446,  579.67905122, 1553.63764005,
        709.97316067,  701.09805344,  534.96164333,  559.44482877,
       2049.67787778,  579.67905122, 1657.70411967,  402.40999352,
       1115.84456895, 2147.62405393, 1518.56525178,  974.52667621,
        559.01588256, 1197.0074052 ,  681.66508619, 1940.2664613 ,
       1944.93973136, 1577.35926752, 1338.4936593 ,  705.95044222,
       1522.12753692, 1483.08183447, 2178.49591261,  352.93663149,
       2217.9860669 , 2046.89960142,  427.92471692, 1059.33653905,
       2180.13911196,  709.97316067, 1754.7547698 ])}

At Step: Modelling regression 
Sequence executed:
Null Handling with mean,  Feature Reduction with pearson,  Outlier Handling with capping,  Encoding with one-hot,Building Regression Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._base.LinearRegression'>, 'param': {'normalize': 'True'}}, 'score': 864.4519147529426, 'residual': <module 'matplotlib.pyplot' from 'C:\\Users\\SindhuKarnati\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py'>, 'pickle_file': LinearRegression(normalize='False'), 'y_pred': array([ 264.57350587,  266.57390381, 2141.94697012, 1453.81007965,
        985.7169623 , 1692.85763317, 1677.85464864, 1166.75297564,
        534.62722742,  295.5796739 , 1904.89981454,  420.60454499,
        937.7074118 ,  453.61111095, 1077.73526742,  785.67716856,
       1754.86996923,  530.62643154,  654.65110366, 1017.7233293 ,
       1836.88628467, 1212.7621282 ,  768.67378609,  679.65607788,
        957.71139118, 1410.801524  ,  722.66463353,  986.71716127,
        646.64951191, 1370.79356525, 1826.88429498,  610.64234904,
        656.6515016 , 1185.75675604,  384.59738211,  501.62066145,
        553.63100782,  164.553609  , 1934.9057836 , 2137.94617425,
        551.63060989, 1083.73646123,  160.66283501, 1751.86937233,
        373.59519346, 1225.76471479,  758.67179641,  394.5993718 ,
       1418.80311575,  869.69388193, 1900.89901866, 2088.93642478,
       1944.90777329,  677.65567994,  939.70780974, 1909.90080938,
       1279.7754591 , 1003.72054374, 2081.935032  ,  337.58803058,
       1857.89046301, 1777.87454551,  627.64573151,  900.70004996,
       1549.82918065, 2100.9388124 , 1171.75397048,  606.64155316,
       1552.82977756, 1270.77366838, 1732.86559192, 1302.78003538,
       1214.76252613, 1020.72392621,  611.64254801, 2029.92468563,
       1648.84887855,  585.63737482, 1869.89285063, 1969.9127475 ,
        914.70283552,  964.71278396, 1182.75615914,  674.65508304,
        160.66283501, 1199.7595416 ,  240.56873062, 1467.81286522,
        354.59141305,  497.61986558,  773.67478094, 1837.88648364,
        991.71815611, 1227.76511273, 1652.84967443,  282.5770873 ,
       1829.88489189, 1683.85584246,  496.61966661, 2188.95632165,
       1512.82181881,  691.6584655 , 1198.75934264, 1877.89444238,
        233.56733784, 1117.74322617, 1475.81445697,  698.65985828,
        601.64055832, 1304.78043332, 2036.92607841,  407.60195839,
        398.60016767, 1619.84310846, 1804.87991767,  519.62424289,
       1007.72133961,  402.60096355,  239.56853165, 1738.86678573,
        473.61509033, 1538.82699199, 1078.73546639,  996.71915096,
        944.70880459, 2222.96308659, 1977.91433925, 1072.73427258,
        911.70223862, 1962.91135472, 1326.78481063,  279.5764904 ,
       1158.75138389,  177.55619559, 1911.90120732, 1671.85345483,
        478.61608517,  466.61369755,  702.66065416, 1716.86240842,
        918.7036314 ,  935.70701387, 1101.74004267, 1515.82241571,
       1306.78083126, 1263.7722756 ,  314.5834543 , 2022.92329285,
       2001.9191145 , 1446.80868687, 1184.75655707,  198.56037393,
        326.58584193,  254.57151618,  616.64354285,  215.5637564 ,
        567.63379338, 1752.8695713 , 1848.88867229, 1568.83296106,
       1572.83375693, 1504.82022706,  765.67318919,  301.58086771,
       1833.88568776, 1617.84271052,  897.69945306, 1211.76192923,
       1894.89782485,  620.64433873, 1755.8701682 , 1917.90240113,
       1299.77943847, 2229.85445748, 1922.90339598, 2079.93463406,
       1223.76431685, 2011.92110419, 2196.9579134 , 1686.85643936,
        921.70422831, 2108.94040415, 2216.96189277, 2202.95910721,
       1710.86121461, 1084.7366602 , 2129.9445825 ,  401.60076458,
        299.58046977, 1555.83037446, 1753.86977026, 1785.87613726,
        207.56216465,  363.59320377,  218.56435331, 1822.88349911,
        361.59280583,  214.56355743,  859.69189225,  590.63836966,
       1590.83733837, 1040.72790558,  877.69547368, 2083.93542994,
        178.55639456, 1748.86877542,  525.6254367 , 1766.87235686,
        628.64593048,  950.7099984 , 2021.92309388,  875.69507574,
        861.69229018, 1155.75078698, 1887.89643207, 1771.8733517 ,
       1587.83674146, 2136.94597528, 1006.72114064, 1463.81206934,
        213.56335846, 1892.89742691, 1426.8047075 , 1310.78162713,
        389.59837696,  335.58763265, 1993.91752275, 1773.87374964,
       1197.75914367,  836.68731597, 1961.91115575, 1403.80013122,
        507.62185526,  480.61648311,  809.68194381,  491.61867176,
       1779.87494345,  236.56793474, 2229.85445748,  838.6877139 ,
        201.56097084, 1242.76809726, 1285.77665291,  421.60474395,
       1931.90518669,  584.63717585, 1204.76053645,  388.59817799,
        535.62742639,  446.60971817,  938.70761077, 1775.87414758,
       2229.85445748,  376.59579036,  487.61787589, 1627.84470021,
        895.69905512, 1858.89066198,  708.66184797,  580.63637998,
        311.5828574 , 1637.8466899 , 1318.78321888, 1700.85922492,
        933.70661593, 1452.80988069,  397.59996871, 1769.87295376,
        400.60056561, 1201.75993954,  810.68214278,  347.59002027,
       1891.89722795, 1871.89324857, 1186.75695501,  833.68671906,
       2013.92150213, 1259.77147973,  342.58902543, 1275.77466323,
       1981.91513513,  357.59200996,  847.68950462,  451.61071302,
       2077.93423612, 1243.76829623,  308.58226049,  247.5701234 ,
       2068.93244541, 1518.82301262,  582.63677792,  834.68691803,
        669.65408819,  536.62762536, 1465.81246728,  196.559976  ,
       1567.83276209,  493.6190697 , 2223.96328555, 2093.93741962,
        830.68612215, 1357.79097866, 1477.8148549 , 1482.81584975,
       1612.84171568, 1675.85425071,  993.71855405, 1805.88011664,
       2010.92090522, 1325.78461166, 2048.92846603, 2071.93304231,
       1378.795157  ,  887.69746337,  204.56156775, 2144.94756703,
       1257.77108179,  559.63220164,  573.6349872 ,  614.64314491,
       1958.91055885, 1915.90200319, 1556.83057343, 1329.78540754,
       1695.85823008, 1970.91294647,  770.67418403, 1767.87255583,
       2092.93722065, 1334.78640238, 2107.94020519, 1672.8536538 ,
        292.57907699, 1269.77346941, 1941.90717638, 1113.7424303 ,
       1015.72293136, 1296.77884157,  689.65806757,  160.66283501,
       1037.72730867, 1345.78859103,  375.59559139,  506.62165629,
       1169.75357254, 1245.76869416,  927.70542212, 1069.73367567,
       1782.87554036, 1910.90100835, 1687.85663833,  554.63120679,
        564.63319648, 1656.8504703 ,  275.57569452, 1111.74203236,
       1495.81843634, 2039.92667531,  759.67199538,  310.58265843,
       2199.95851031,  486.61767692, 1333.78620341, 1873.89364651,
        664.65309335, 1366.79276938,  912.70243759, 2191.95691856,
       1480.81545181,  853.69069843, 1307.78103022, 1744.86797955,
        160.66283501, 1841.88727951,  200.56077187,  527.62583464,
       1092.73825195,  904.70084584,  858.69169328,  995.71895199,
       1459.81127347, 1945.90797226, 1554.83017549, 1254.77048488,
        951.71019737, 1284.77645394, 2225.96368349,  318.58425018,
       1536.82659406, 1264.77247457,  579.63618101, 1544.82818581,
        721.66443456,  696.65946035,  526.62563567,  563.63299751,
       2052.92926191,  575.63538513, 1674.85405174,  399.60036664,
       1110.74183339, 2157.95015362, 1514.82221675,  983.71656436,
        545.62941607, 1181.75596017,  680.65627685, 1955.90996194,
       1959.91075782, 1565.83236415, 1344.78839207,  711.66244488,
       1528.82500231, 1487.81684459, 2170.95274021,  351.59081615,
       2229.85445748, 2043.92747119,  425.60553983, 1066.73307877,
       2176.95393403,  717.66363869, 1750.86917336])}

At Step: Outlier Handling 
Sequence executed:
  Outlier Handling with removing,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with one-hot,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with one-hot,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 15, 'max_features': 4, 'n_estimators': 7}}, 'score': 0.8142857142857143, 'conf_matrix': array([[93, 22],
       [ 4, 21]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=15, max_features=4,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=7,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,
       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with one-hot,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.667056343401222, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.8357142857142857, 'conf_matrix': array([[88, 14],
       [ 9, 29]], dtype=int64), 'pickle_file': LogisticRegression(C=0.5845645325229636, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,
       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,
       0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0], dtype=int64)}

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 18, 'max_features': 4, 'n_estimators': 6}}, 'score': 0.8228855721393035, 'conf_matrix': array([[ 78,  19,   5],
       [ 50, 247,  11],
       [ 45,  48, 502]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=18, max_features=4,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=6,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([2, 0, 2, ..., 0, 1, 2])}

At Step: Modelling classification 
Sequence executed:
  Encoding with label,  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.12139771911352203, 'penalty': 'l2', 'solver': 'saga'}}, 'score': 0.9522388059701492, 'conf_matrix': array([[159,  13,   7],
       [ 13, 294,   7],
       [  1,   7, 504]], dtype=int64), 'pickle_file': LogisticRegression(C=0.12037178940976204, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='sag', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 2, ..., 0, 1, 2])}

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with imputezero,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 11, 'max_features': 4, 'n_estimators': 10}}, 'score': 0.8357142857142857, 'conf_matrix': array([[72, 14],
       [ 9, 45]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=7, max_features=4,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=6,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,
       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,
       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,
       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1,
       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,
       1, 0, 0, 1, 1, 1, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.16371719274487778, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.7571428571428571, 'conf_matrix': array([[71, 24],
       [10, 35]], dtype=int64), 'pickle_file': LogisticRegression(C=0.1427264135444902, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,
       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,
       0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,
       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,
       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 1, 1, 0, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with imputezero,

At Step: Outlier Handling 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 17, 'max_features': 1, 'n_estimators': 19}}, 'score': 0.8580645161290322, 'conf_matrix': array([[98, 17],
       [ 5, 35]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=17, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=19,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,
       1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,
       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,
       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.7439780936876438, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.8387096774193549, 'conf_matrix': array([[96, 18],
       [ 7, 34]], dtype=int64), 'pickle_file': LogisticRegression(C=0.7812831260282708, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,
       1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,
       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,
       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,
       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,
       1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with imputezero,

At Step: Outlier Handling 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 4, 'max_features': 1, 'n_estimators': 13}}, 'score': 0.8202247191011236, 'conf_matrix': array([[101,  24],
       [  8,  45]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=5, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=18,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,
       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,
       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,
       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,
       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.05310701205369617, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.797752808988764, 'conf_matrix': array([[99, 26],
       [10, 43]], dtype=int64), 'pickle_file': LogisticRegression(C=0.04568340229264816, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,
       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0,
       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,
       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,
       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,
       0, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 8, 'max_features': 2, 'n_estimators': 18}}, 'score': 0.8214285714285714, 'conf_matrix': array([[76, 18],
       [ 7, 39]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=11, max_features=2,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=13,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,
       1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,
       1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 1, 1, 1, 1, 0, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 4.76251276844848, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.8285714285714286, 'conf_matrix': array([[74, 15],
       [ 9, 42]], dtype=int64), 'pickle_file': LogisticRegression(C=862.0083615988101, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,
       1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,
       1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 1, 1, 0, 1, 1, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 6, 'max_features': 2, 'n_estimators': 6}}, 'score': 0.8642857142857143, 'conf_matrix': array([[83, 14],
       [ 5, 38]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=6, max_features=2,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=6,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,
       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,
       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.6006745619646621, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.7857142857142857, 'conf_matrix': array([[77, 19],
       [11, 33]], dtype=int64), 'pickle_file': LogisticRegression(C=0.9898739712140293, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,
       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,
       1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,
       1, 0, 0, 0, 1, 0, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 6, 'max_features': 3, 'n_estimators': 15}}, 'score': 0.8642857142857143, 'conf_matrix': array([[90, 10],
       [ 9, 31]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=8, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=12,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,
       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,
       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 1, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.32402968937815524, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.8142857142857143, 'conf_matrix': array([[85, 12],
       [14, 29]], dtype=int64), 'pickle_file': LogisticRegression(C=0.27681755290541615, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,
       1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,
       1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,
       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,
       1, 0, 1, 0, 1, 0, 1, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 13, 'max_features': 2, 'n_estimators': 11}}, 'score': 0.8571428571428571, 'conf_matrix': array([[87, 17],
       [ 3, 33]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=13, max_features=2,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=11,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.7388060400741512, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.8071428571428572, 'conf_matrix': array([[81, 18],
       [ 9, 32]], dtype=int64), 'pickle_file': LogisticRegression(C=0.5663179306332855, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,
       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,
       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 3, 'max_features': 7, 'n_estimators': 18}}, 'score': 0.8472222222222222, 'conf_matrix': array([[90, 16],
       [ 6, 32]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=3, max_features=7,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=18,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,
       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,
       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,
       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 1.1060602887314528, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.8194444444444444, 'conf_matrix': array([[85, 15],
       [11, 33]], dtype=int64), 'pickle_file': LogisticRegression(C=1.1060602887314528, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,
       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,
       1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,
       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,
       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 8, 'max_features': 5, 'n_estimators': 13}}, 'score': 0.875, 'conf_matrix': array([[95, 14],
       [ 4, 31]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=8, max_features=5,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=13,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,
       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,
       0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 68.93881076118305, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.8263888888888888, 'conf_matrix': array([[85, 11],
       [14, 34]], dtype=int64), 'pickle_file': LogisticRegression(C=68.93881076118305, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,
       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,
       0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,
       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,
       1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with imputezero,

At Step: Outlier Handling 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 6, 'max_features': 4, 'n_estimators': 8}}, 'score': 0.8709677419354839, 'conf_matrix': array([[94,  9],
       [11, 41]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=6, max_features=4,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=8,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0,
       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,
       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,
       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,
       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,
       1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,
       1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.572502815465443, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.8129032258064516, 'conf_matrix': array([[92, 16],
       [13, 34]], dtype=int64), 'pickle_file': LogisticRegression(C=0.3024003814110007, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='sag', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,
       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1,
       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,
       1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with imputezero,

At Step: Outlier Handling 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 5, 'max_features': 4, 'n_estimators': 14}}, 'score': 0.7935483870967742, 'conf_matrix': array([[94, 26],
       [ 6, 29]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=5, max_features=4,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=14,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,
       1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,
       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with imputezero,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 2.6851847764576413, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.7870967741935484, 'conf_matrix': array([[92, 25],
       [ 8, 30]], dtype=int64), 'pickle_file': LogisticRegression(C=23.096137870719573, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,
       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,
       1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1,
       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,
       0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 10, 'max_features': 1, 'n_estimators': 16}}, 'score': 0.8516129032258064, 'conf_matrix': array([[95, 14],
       [ 9, 37]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=8, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=15,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,
       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,
       1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.08839942402396557, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.8129032258064516, 'conf_matrix': array([[94, 19],
       [10, 32]], dtype=int64), 'pickle_file': LogisticRegression(C=0.08633268164649702, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,
       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,
       1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1,
       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,
       0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 4, 'max_features': 2, 'n_estimators': 7}}, 'score': 0.8071428571428572, 'conf_matrix': array([[82,  9],
       [18, 31]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=4, max_features=2,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=7,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,
       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,
       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,
       0, 0, 1, 0, 1, 0, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.13059658047092124, 'penalty': 'l2', 'solver': 'sag'}}, 'score': 0.8071428571428572, 'conf_matrix': array([[88, 15],
       [12, 25]], dtype=int64), 'pickle_file': LogisticRegression(C=0.12699370216498726, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='sag', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,
       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,
       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 6, 'max_features': 4, 'n_estimators': 17}}, 'score': 0.8451612903225807, 'conf_matrix': array([[83, 13],
       [11, 48]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=6, max_features=4,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=17,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0,
       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,
       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,
       0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 1.6162366086415738, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.7806451612903226, 'conf_matrix': array([[79, 19],
       [15, 42]], dtype=int64), 'pickle_file': LogisticRegression(C=43.2482553543789, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,
       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,
       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,
       1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 5, 'max_features': 3, 'n_estimators': 3}}, 'score': 0.85, 'conf_matrix': array([[88, 16],
       [ 5, 31]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=5, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=3,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,
       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,
       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.4625210830514644, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.7642857142857142, 'conf_matrix': array([[77, 17],
       [16, 30]], dtype=int64), 'pickle_file': LogisticRegression(C=0.3639800534386642, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 11, 'max_features': 1, 'n_estimators': 19}}, 'score': 0.8357142857142857, 'conf_matrix': array([[89, 14],
       [ 9, 28]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=11, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=19,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       1, 0, 1, 1, 0, 0, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.06431055002480249, 'penalty': 'l2', 'solver': 'lbfgs'}}, 'score': 0.7928571428571428, 'conf_matrix': array([[87, 18],
       [11, 24]], dtype=int64), 'pickle_file': LogisticRegression(C=0.1390384882504391, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='sag', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,
       1, 0, 1, 1, 0, 0, 0, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 13, 'max_features': 3, 'n_estimators': 18}}, 'score': 0.8571428571428571, 'conf_matrix': array([[86, 10],
       [10, 34]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=13, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=18,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,
       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,
       1, 1, 0, 1, 1, 1, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 4.829715123425421, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.7571428571428571, 'conf_matrix': array([[77, 15],
       [19, 29]], dtype=int64), 'pickle_file': LogisticRegression(C=1668419.5792257932, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,
       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,
       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,
       1, 1, 0, 1, 1, 1, 1, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 15, 'max_features': 4, 'n_estimators': 19}}, 'score': 0.8541666666666666, 'conf_matrix': array([[81, 15],
       [ 6, 42]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=15, max_features=4,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=19,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,
       1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,
       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,
       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,
       1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 1.4689214041806864, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.75, 'conf_matrix': array([[73, 22],
       [14, 35]], dtype=int64), 'pickle_file': LogisticRegression(C=0.8755333326198143, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,
       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0,
       0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,
       1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 18, 'max_features': 3, 'n_estimators': 14}}, 'score': 0.8541666666666666, 'conf_matrix': array([[92, 13],
       [ 8, 31]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=18, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=14,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,
       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,
       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.45854041413392393, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.75, 'conf_matrix': array([[82, 18],
       [18, 26]], dtype=int64), 'pickle_file': LogisticRegression(C=89.19840350444775, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1,
       0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,
       1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,
       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 17, 'max_features': 3, 'n_estimators': 7}}, 'score': 0.8428571428571429, 'conf_matrix': array([[86, 16],
       [ 6, 32]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=18, max_features=2,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=14,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,
       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,
       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,
       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 1, 1, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.656156556615793, 'penalty': 'l2', 'solver': 'saga'}}, 'score': 0.7714285714285715, 'conf_matrix': array([[86, 26],
       [ 6, 22]], dtype=int64), 'pickle_file': LogisticRegression(C=2125282.2330909884, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='saga', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,
       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,
       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 6, 'max_features': 3, 'n_estimators': 7}}, 'score': 0.7928571428571428, 'conf_matrix': array([[84, 16],
       [13, 27]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=6, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=7,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 1, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 6.478270565284335, 'penalty': 'l2', 'solver': 'saga'}}, 'score': 0.7714285714285715, 'conf_matrix': array([[86, 21],
       [11, 22]], dtype=int64), 'pickle_file': LogisticRegression(C=1.096164911625252, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='saga', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,
       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 1, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 6, 'max_features': 2, 'n_estimators': 14}}, 'score': 0.8363636363636363, 'conf_matrix': array([[95, 20],
       [ 7, 43]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=2,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,
       1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,
       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,
       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,
       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,
       0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,
       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.6477440213661931, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.8242424242424242, 'conf_matrix': array([[93, 20],
       [ 9, 43]], dtype=int64), 'pickle_file': LogisticRegression(C=211.31366863155682, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,
       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,
       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0,
       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,
       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,
       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 5, 'max_features': 1, 'n_estimators': 9}}, 'score': 0.8064516129032258, 'conf_matrix': array([[91, 20],
       [10, 34]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=5, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=9,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,
       1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,
       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,
       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,
       1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.06089890624635348, 'penalty': 'l2', 'solver': 'sag'}}, 'score': 0.7806451612903226, 'conf_matrix': array([[97, 30],
       [ 4, 24]], dtype=int64), 'pickle_file': LogisticRegression(C=0.022145160633250054, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,
       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,
       1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 6, 'max_features': 2, 'n_estimators': 3}}, 'score': 0.8194444444444444, 'conf_matrix': array([[85, 12],
       [14, 33]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=6, max_features=2,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=3,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,
       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,
       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,
       0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 1.2508470958140614, 'penalty': 'l2', 'solver': 'sag'}}, 'score': 0.7777777777777778, 'conf_matrix': array([[79, 12],
       [20, 33]], dtype=int64), 'pickle_file': LogisticRegression(C=1.313225865825919, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='sag', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,
       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,
       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,
       0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 8, 'max_features': 3, 'n_estimators': 12}}, 'score': 0.8333333333333334, 'conf_matrix': array([[82,  9],
       [15, 38]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=8, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=12,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1,
       0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 1.1748697827226486, 'penalty': 'l2', 'solver': 'sag'}}, 'score': 0.7777777777777778, 'conf_matrix': array([[81, 16],
       [16, 31]], dtype=int64), 'pickle_file': LogisticRegression(C=1.1748697827226486, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='sag', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,
       0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 8, 'max_features': 3, 'n_estimators': 19}}, 'score': 0.7785714285714286, 'conf_matrix': array([[82, 21],
       [10, 27]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=5, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=8,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,
       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0,
       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.8037938906082899, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.7642857142857142, 'conf_matrix': array([[75, 16],
       [17, 32]], dtype=int64), 'pickle_file': LogisticRegression(C=0.21750243693129861, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,
       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0,
       1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,
       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,
       0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,
       0, 0, 1, 0, 1, 0, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 5, 'max_features': 3, 'n_estimators': 11}}, 'score': 0.8071428571428572, 'conf_matrix': array([[81, 14],
       [13, 32]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=4, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=15,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1,
       0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,
       0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.25589204393317194, 'penalty': 'l2', 'solver': 'saga'}}, 'score': 0.7928571428571428, 'conf_matrix': array([[88, 23],
       [ 6, 23]], dtype=int64), 'pickle_file': LogisticRegression(C=0.8696834314807411, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='saga', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,
       0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'gini', 'max_depth': 7, 'max_features': 1, 'n_estimators': 18}}, 'score': 0.8451612903225807, 'conf_matrix': array([[96, 15],
       [ 9, 35]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=7, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=18,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,
       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,
       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,
       0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 2.1086558500091135, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.7870967741935484, 'conf_matrix': array([[89, 17],
       [16, 33]], dtype=int64), 'pickle_file': LogisticRegression(C=14839.33237045672, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,
       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,
       1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,
       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0,
       0], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 15, 'max_features': 3, 'n_estimators': 8}}, 'score': 0.7777777777777778, 'conf_matrix': array([[78, 11],
       [21, 34]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=15, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=8,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,
       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,
       0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,
       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,
       1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 2.001919523190494, 'penalty': 'l2', 'solver': 'sag'}}, 'score': 0.7083333333333334, 'conf_matrix': array([[70, 13],
       [29, 32]], dtype=int64), 'pickle_file': LogisticRegression(C=6.894578333453981, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='sag', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0,
       0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,
       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,
       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,
       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,
       1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 13, 'max_features': 4, 'n_estimators': 12}}, 'score': 0.7857142857142857, 'conf_matrix': array([[80, 21],
       [ 9, 30]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=19, max_features=1,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=14,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0,
       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,
       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,
       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,
       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.11833312921383206, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.7428571428571429, 'conf_matrix': array([[78, 25],
       [11, 26]], dtype=int64), 'pickle_file': LogisticRegression(C=0.11526424970091752, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,
       0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,
       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1,
       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1], dtype=int64)}

At Step: textProcessing 
Sequence executed:
  Text Processing with BOW,

At Step: Modelling classification 
Sequence executed:
  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 18, 'max_features': 335, 'n_estimators': 13}}, 'score': 0.9333333333333333, 'conf_matrix': array([[136,  20,  16],
       [ 12, 295,  12],
       [  5,   2, 507]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=18, max_features=335,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=13,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array(['british', 'cajun_creole', 'cajun_creole', ..., 'cajun_creole',
       'chinese', 'chinese'], dtype=object)}

At Step: Modelling classification 
Sequence executed:
  Text Processing with BOW,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 3.207927032798479, 'penalty': 'l2', 'solver': 'liblinear'}}, 'score': 0.9522388059701492, 'conf_matrix': array([[142,  13,  12],
       [ 11, 301,   9],
       [  0,   3, 514]], dtype=int64), 'pickle_file': LogisticRegression(C=3.568804154625533, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array(['british', 'cajun_creole', 'cajun_creole', ..., 'cajun_creole',
       'chinese', 'chinese'], dtype=object)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 14, 'max_features': 1, 'n_estimators': 17}}, 'score': 0.8181818181818182, 'conf_matrix': array([[78, 13],
       [17, 57]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=2, max_features=3,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=14,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False), 'y_pred': array([0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,
       1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,
       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,
       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1,
       0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,
       1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,
       1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,
       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'param': {'C': 0.07418116181919353, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.8242424242424242, 'conf_matrix': array([[79, 13],
       [16, 57]], dtype=int64), 'pickle_file': LogisticRegression(C=0.057128729150974306, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,
                   warm_start=False), 'y_pred': array([0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,
       1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,
       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,
       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1,
       0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,
       1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,
       1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,
       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1], dtype=int64)}

At Step: nullHandling 
Sequence executed:
Null Handling with mean,

At Step: Outlier Handling 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,

At Step: Encoding 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'param': {'criterion': 'entropy', 'max_depth': 19, 'max_features': 3, 'n_estimators': 14}}, 'score': 0.8181818181818182, 'conf_matrix': array([[85, 23],
       [ 7, 50]], dtype=int64), 'pickle_file': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=19, max_features=3, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=14, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'y_pred': array([1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,
       1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,
       0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,
       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0], dtype=int64)}

At Step: Modelling classification 
Sequence executed:
Null Handling with mean,  Outlier Handling with removing,  Encoding with label,Building Classification Model

{'Hyperparameter': {'model': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'param': {'C': 0.45736414663848546, 'penalty': 'l2', 'solver': 'newton-cg'}}, 'score': 0.8, 'conf_matrix': array([[80, 21],
       [12, 52]], dtype=int64), 'pickle_file': LogisticRegression(C=1.8870234127010779, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'y_pred': array([1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,
       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,
       0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,
       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,
       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0], dtype=int64)}

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

At Step: Encoding 
Sequence executed:
  Encoding with label,

At Step: textProcessing 
Sequence executed:
  Encoding with label,  Text Processing with BOW,

